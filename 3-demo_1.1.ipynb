{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0180afdc-9bc5-49fc-aecd-97163d0d5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23e77e7-9ac4-4b32-a6dd-4e27e2942622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcef99f-1d7f-4c73-bf72-6291d3932084",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a178ad07-5954-4786-978e-17006444e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nlp model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05279123-20ca-41b9-851d-d74eef43ec39",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b00017c-eb59-4e05-8626-c475d64e0af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"meta-data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df36fa5-73c4-47e3-962d-b7ab6b4f6d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   reviewer_id       100 non-null    int64 \n",
      " 1   review_time       100 non-null    object\n",
      " 2   rating            100 non-null    int64 \n",
      " 3   review            100 non-null    object\n",
      " 4   review_processed  100 non-null    object\n",
      " 5   aspect_sentiment  100 non-null    object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 5.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_processed</th>\n",
       "      <th>aspect_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>1</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>I had a normal transaction, but now I don't wa...</td>\n",
       "      <td>[{'term': 'food', 'class': 'negative', 'probab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>4</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>It's what it is as far as the food and atmosph...</td>\n",
       "      <td>[{'term': 'staff', 'class': 'positive', 'proba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>I made a mobile order got to the speaker and c...</td>\n",
       "      <td>[{'term': 'speaker', 'class': 'neutral', 'prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>5</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ÃÂ¯ÃÂ¿ÃÂ...</td>\n",
       "      <td>My mc. Crispy chicken sandwich was  customer s...</td>\n",
       "      <td>[{'term': 'service', 'class': 'positive', 'pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>1</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>I repeat my order three times in the drive thr...</td>\n",
       "      <td>[{'term': 'fries', 'class': 'positive', 'proba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id review_time  rating  \\\n",
       "0            1  2024-09-20       1   \n",
       "1            2  2024-12-15       4   \n",
       "2            3  2024-12-15       1   \n",
       "3            4  2024-11-20       5   \n",
       "4            5  2024-10-20       1   \n",
       "\n",
       "                                              review  \\\n",
       "0  Why does it look like someone spit on my food?...   \n",
       "1  It'd McDonalds. It is what it is as far as the...   \n",
       "2  Made a mobile order got to the speaker and che...   \n",
       "3  My mc. Crispy chicken sandwich was ÃÂ¯ÃÂ¿ÃÂ...   \n",
       "4  I repeat my order 3 times in the drive thru, a...   \n",
       "\n",
       "                                    review_processed  \\\n",
       "0  I had a normal transaction, but now I don't wa...   \n",
       "1  It's what it is as far as the food and atmosph...   \n",
       "2  I made a mobile order got to the speaker and c...   \n",
       "3  My mc. Crispy chicken sandwich was  customer s...   \n",
       "4  I repeat my order three times in the drive thr...   \n",
       "\n",
       "                                    aspect_sentiment  \n",
       "0  [{'term': 'food', 'class': 'negative', 'probab...  \n",
       "1  [{'term': 'staff', 'class': 'positive', 'proba...  \n",
       "2  [{'term': 'speaker', 'class': 'neutral', 'prob...  \n",
       "3  [{'term': 'service', 'class': 'positive', 'pro...  \n",
       "4  [{'term': 'fries', 'class': 'positive', 'proba...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data, 'index')\n",
    "\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134416aa-9ea2-45e4-88bb-28d16561e367",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a718467b-131b-4277-a5df-e52970bef934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bing Liu's opinion word dictionary\n",
    "bing_liu_opinion_words = set()  # Add the actual list of opinion words here\n",
    "\n",
    "# Function to load opinion words from Bing Liu lexicon\n",
    "def load_opinion_words(filepath):\n",
    "    global bing_liu_opinion_words\n",
    "    temp = pd.read_table(filepath, comment=';', header=None)[0].to_list()\n",
    "    bing_liu_opinion_words = bing_liu_opinion_words.union(set(temp))\n",
    "\n",
    "\n",
    "# Load opinion words\n",
    "current_dir = os.getcwd()\n",
    "load_opinion_words(os.path.join(current_dir, 'util/opinion-lexicon-English/negative-words.txt'))\n",
    "load_opinion_words(os.path.join(current_dir, 'util/opinion-lexicon-English/positive-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed2e794-2565-4183-87e1-a922f3d7aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['review_processed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695902ef-6962-409f-b145-843b9eda1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17be83cd-a7d9-4b35-bc32-e772a679b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text\n",
    "def preprocessing(text):\n",
    "\n",
    "    # Get token of words\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        t = token.lemma_.lower()\n",
    "\n",
    "        if re.match(r'^[0-9\\W]+$', t) or len(t) < 3 or t in stop_words:\n",
    "            continue\n",
    "        # If the token is adjective, noun, propn, or verb\n",
    "        if token.pos_ in ['NOUN', 'PROPN', 'VERB']:\n",
    "            result.append(t)\n",
    "        # elif token.pos_ in ['ADJ', 'VERB']:\n",
    "        #     result.append(t)\n",
    "        # If the token is ADJ but not sentiment opinion\n",
    "        elif token.pos_ in ['ADJ'] and t not in bing_liu_opinion_words:\n",
    "            result.append(t)\n",
    "        else:\n",
    "            continue\n",
    "        # result.append(t)\n",
    "    return result\n",
    "\n",
    "# Create texts\n",
    "texts = [preprocessing(document) for document in corpus]\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "\n",
    "\n",
    "# Convert documents into Bag-of-words format\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the TF-IDF model\n",
    "tfidf_model = gensim.models.TfidfModel(corpus_bow)\n",
    "\n",
    "# Get corpus tfidf \n",
    "corpus_tfidf = tfidf_model[corpus_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f7334c-7610-4ef3-8c3f-4914c458f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:38<00:00,  4.30s/it]\n"
     ]
    }
   ],
   "source": [
    "def topic_model_coherence_generator(corpus, texts, dictionary,\n",
    "                                    start_topic_count=2, end_topic_count=10,\n",
    "                                    step=1, cpus=1):\n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary,\n",
    "                                           chunksize=1740, alpha='auto',\n",
    "                                           eta='auto', random_state=42,\n",
    "                                           iterations=500, num_topics=topic_nums,\n",
    "                                           passes=20, eval_every=None)\n",
    "\n",
    "        cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model,\n",
    "                                                                     corpus=corpus,\n",
    "                                                                     texts=texts,\n",
    "                                                                     dictionary=dictionary,\n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(lda_model)\n",
    "\n",
    "\n",
    "    return models, coherence_scores\n",
    "\n",
    "models, coherence_scores = topic_model_coherence_generator(corpus=corpus_tfidf,\n",
    "                                                           texts=texts,\n",
    "                                                           dictionary=dictionary)\n",
    "opt_model = models[np.argmax(coherence_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb897b0-5e95-45e6-a52f-f5847f79d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model = models[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387b95e2-497b-42a7-8e1b-5ca74330325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall mean coherence score\n",
    "topics_coherences = opt_model.top_topics(corpus_tfidf, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b49f0771-fc50-4df0-8aec-ce7a72a933a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39835983573199785,\n",
       " 0.48056923951398706,\n",
       " 0.518990126501683,\n",
       " 0.4962744441652319,\n",
       " 0.45629886386610874,\n",
       " 0.5337222806693261,\n",
       " 0.512233069565416,\n",
       " 0.5331722324753213,\n",
       " 0.48853539318880923]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818c3d1-c822-45f0-8126-5682436e3fe1",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d84f8db-aa96-4c1a-8cc8-b5d781153645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic 1:\n",
      "[('get', 0.011), ('order', 0.01), ('drive', 0.009), ('customer', 0.008), ('service', 0.008), ('ask', 0.008), ('line', 0.008), ('thru', 0.007), ('long', 0.007), ('drink', 0.007), ('mcdona', 0.007), ('wait', 0.006), ('time', 0.006), ('busy', 0.006), ('extra', 0.005), ('food', 0.005), ('experience', 0.005), ('wrap', 0.005), ('window', 0.005), ('hang', 0.005)]\n",
      "\n",
      "Topic 2:\n",
      "[('mcdonald', 0.014), ('food', 0.008), ('smile', 0.007), ('fry', 0.007), ('people', 0.007), ('order', 0.007), ('answer', 0.007), ('need', 0.006), ('mean', 0.006), ('see', 0.006), ('attitude', 0.006), ('get', 0.006), ('meal', 0.006), ('time', 0.006), ('window', 0.006), ('day', 0.005), ('mess', 0.005), ('plain', 0.005), ('manager', 0.005), ('bag', 0.005)]\n",
      "\n",
      "Topic 3:\n",
      "[('service', 0.01), ('get', 0.008), ('take', 0.008), ('ice', 0.007), ('order', 0.007), ('food', 0.007), ('cashier', 0.007), ('wait', 0.006), ('time', 0.006), ('3rd', 0.006), ('card', 0.006), ('eat', 0.006), ('person', 0.006), ('taste', 0.006), ('new', 0.005), ('inside', 0.005), ('upgrade', 0.005), ('kitchen', 0.005), ('make', 0.005), ('cookie', 0.005)]\n",
      "\n",
      "Topic 4:\n",
      "[('food', 0.008), ('know', 0.008), ('job', 0.007), ('place', 0.007), ('fill', 0.007), ('order', 0.007), ('staff', 0.006), ('small', 0.006), ('normal', 0.006), ('say', 0.006), ('coffee', 0.005), ('drink', 0.005), ('store', 0.005), ('cup', 0.005), ('take', 0.005), ('chill', 0.005), ('saturday', 0.005), ('able', 0.005), ('professional', 0.005), ('caffeine', 0.005)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize result: Topic with weights\n",
    "\n",
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print(\"LDA Topics with Weights\")\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "  print(f'Topic {idx + 1}:')\n",
    "  print([(term, round(wt, 3)) for wt, term in topic])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fc5c09e-b142-4148-b5d7-e195cf8b332a",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "1. Topic 1: Customer Service and Waiting Experience\n",
    "2. Topic 2: Food Quality and Value for Money\n",
    "3. Topic 3: Drive-Thru and Ice Cream Experience\n",
    "4. Topic 4: Operational Challenges and Meal Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae8fb8b0-724d-4b58-b3db-5dac0a3e75ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food, know, job, place, fill, order, staff, sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service, get, take, ice, order, food, cashier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mcdonald, food, smile, fry, people, order, ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get, order, drive, customer, service, ask, lin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Term per Topic\n",
       "1  food, know, job, place, fill, order, staff, sm...\n",
       "2  service, get, take, ice, order, food, cashier,...\n",
       "3  mcdonald, food, smile, fry, people, order, ans...\n",
       "4  get, order, drive, customer, service, ask, lin..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3))\n",
    "              for term, wt in opt_model.show_topic(n, topn=20)]\n",
    "          for n in range(0, opt_model.num_topics)\n",
    "          ]\n",
    "\n",
    "topic_df = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics],\n",
    "                       columns=['Term per Topic'],\n",
    "                       index=[str(t) for t in range(1, opt_model.num_topics+1)])\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e30c93-8af9-46da-ba60-d0d876b07192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic': '1',\n",
       "  'term': 'food, know, job, place, fill, order, staff, small, normal, say, coffee, drink, store, cup, take, chill, saturday, able, professional, caffeine'},\n",
       " {'topic': '2',\n",
       "  'term': 'service, get, take, ice, order, food, cashier, wait, time, 3rd, card, eat, person, taste, new, inside, upgrade, kitchen, make, cookie'},\n",
       " {'topic': '3',\n",
       "  'term': 'mcdonald, food, smile, fry, people, order, answer, need, mean, see, attitude, get, meal, time, window, day, mess, plain, manager, bag'},\n",
       " {'topic': '4',\n",
       "  'term': 'get, order, drive, customer, service, ask, line, thru, long, drink, mcdona, wait, time, busy, extra, food, experience, wrap, window, hang'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_json = topic_df.reset_index().rename({'index': 'topic', 'Term per Topic': 'term'}, axis=1).to_dict('records')\n",
    "\n",
    "topic_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6dd761a-2e42-4d6f-b3c6-76d633f0dee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9071873),\n",
       " (2, 0.8879401),\n",
       " (1, 0.92724097),\n",
       " (1, 0.8864034),\n",
       " (2, 0.9397753)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpreting result\n",
    "tm_results = opt_model[corpus_tfidf]\n",
    "\n",
    "# Corpus Topics\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0]\n",
    "                 for topics in tm_results]\n",
    "\n",
    "corpus_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff380e5-f8e8-4195-9a07-d71118665750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028695045, 0.041521836, 0.8879401, 0.041842982]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999720603228"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for topics in tm_results:\n",
    "    count += 1\n",
    "    temp = [t[-1] for t in topics]\n",
    "    if count == 2:\n",
    "        break\n",
    "print(temp)\n",
    "sum(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ca3b62-7c31-4536-8154-5e6627598105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>food, know, job, place, fill, order, staff, sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8879</td>\n",
       "      <td>mcdonald, food, smile, fry, people, order, ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>service, get, take, ice, order, food, cashier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>service, get, take, ice, order, food, cashier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>mcdonald, food, smile, fry, people, order, ans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  probability                                              terms\n",
       "1      1       0.9072  food, know, job, place, fill, order, staff, sm...\n",
       "2      3       0.8879  mcdonald, food, smile, fry, people, order, ans...\n",
       "3      2       0.9272  service, get, take, ice, order, food, cashier,...\n",
       "4      2       0.8864  service, get, take, ice, order, food, cashier,...\n",
       "5      3       0.9398  mcdonald, food, smile, fry, people, order, ans..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topic_df = pd.DataFrame(index=df['reviewer_id'].values)\n",
    "corpus_topic_df['topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['probability'] = [round(item[1], 4) for item in corpus_topics]\n",
    "corpus_topic_df['terms'] = [topic_df.iloc[t[0]]['Term per Topic'] for t in corpus_topics]\n",
    "# corpus_topic_df['reviewer_id'] = df['reviewer_id'].values\n",
    "\n",
    "corpus_topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf837974-9a93-467d-b03b-1d86d86ecb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_topic_json = corpus_topic_df.to_dict('index')\n",
    "\n",
    "# corpus_topic_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1780a0e7-1dac-4f90-b505-c740ec0daa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_processed</th>\n",
       "      <th>aspect_sentiment</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>1</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>I had a normal transaction, but now I don't wa...</td>\n",
       "      <td>[{'term': 'food', 'class': 'negative', 'probab...</td>\n",
       "      <td>{'topic': 1, 'probability': 0.9071999788284302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>4</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>It's what it is as far as the food and atmosph...</td>\n",
       "      <td>[{'term': 'staff', 'class': 'positive', 'proba...</td>\n",
       "      <td>{'topic': 3, 'probability': 0.8878999948501587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>I made a mobile order got to the speaker and c...</td>\n",
       "      <td>[{'term': 'speaker', 'class': 'neutral', 'prob...</td>\n",
       "      <td>{'topic': 2, 'probability': 0.9272000193595886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>5</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ÃÂ¯ÃÂ¿ÃÂ...</td>\n",
       "      <td>My mc. Crispy chicken sandwich was  customer s...</td>\n",
       "      <td>[{'term': 'service', 'class': 'positive', 'pro...</td>\n",
       "      <td>{'topic': 2, 'probability': 0.8863999843597412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>1</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>I repeat my order three times in the drive thr...</td>\n",
       "      <td>[{'term': 'fries', 'class': 'positive', 'proba...</td>\n",
       "      <td>{'topic': 3, 'probability': 0.9398000240325928...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id review_time  rating  \\\n",
       "0            1  2024-09-20       1   \n",
       "1            2  2024-12-15       4   \n",
       "2            3  2024-12-15       1   \n",
       "3            4  2024-11-20       5   \n",
       "4            5  2024-10-20       1   \n",
       "\n",
       "                                              review  \\\n",
       "0  Why does it look like someone spit on my food?...   \n",
       "1  It'd McDonalds. It is what it is as far as the...   \n",
       "2  Made a mobile order got to the speaker and che...   \n",
       "3  My mc. Crispy chicken sandwich was ÃÂ¯ÃÂ¿ÃÂ...   \n",
       "4  I repeat my order 3 times in the drive thru, a...   \n",
       "\n",
       "                                    review_processed  \\\n",
       "0  I had a normal transaction, but now I don't wa...   \n",
       "1  It's what it is as far as the food and atmosph...   \n",
       "2  I made a mobile order got to the speaker and c...   \n",
       "3  My mc. Crispy chicken sandwich was  customer s...   \n",
       "4  I repeat my order three times in the drive thr...   \n",
       "\n",
       "                                    aspect_sentiment  \\\n",
       "0  [{'term': 'food', 'class': 'negative', 'probab...   \n",
       "1  [{'term': 'staff', 'class': 'positive', 'proba...   \n",
       "2  [{'term': 'speaker', 'class': 'neutral', 'prob...   \n",
       "3  [{'term': 'service', 'class': 'positive', 'pro...   \n",
       "4  [{'term': 'fries', 'class': 'positive', 'proba...   \n",
       "\n",
       "                                               topic  \n",
       "0  {'topic': 1, 'probability': 0.9071999788284302...  \n",
       "1  {'topic': 3, 'probability': 0.8878999948501587...  \n",
       "2  {'topic': 2, 'probability': 0.9272000193595886...  \n",
       "3  {'topic': 2, 'probability': 0.8863999843597412...  \n",
       "4  {'topic': 3, 'probability': 0.9398000240325928...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'] = df['reviewer_id'].apply(lambda x: corpus_topic_json[x])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f15a7ae-10f9-4607-8358-c43a1c55beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.to_dict('index')\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbd135-12f1-483d-8026-bf87d1fdba29",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95b27d2c-62a0-4fc4-be4d-2d83d649ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"meta-topic.json\", \"w\") as file:\n",
    "#     json.dump(corpus_topic_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4f8d0cf-d241-4511-83a9-ab081545e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"map-topic.json\",  \"w\") as file:\n",
    "#     json.dump(topic_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697faaa5-de31-485d-8c57-0d60c9c9c8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb5194-831c-4ea2-bcee-a11fafadf2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe8e88-ac84-4f19-b2de-383c3ae5fde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa5dd0-f26c-481e-9d19-845c3890f057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
