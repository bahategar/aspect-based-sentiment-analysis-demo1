{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc6a70f-aa67-437e-8586-f5e2e8a1c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Preparation text\n",
    "\n",
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "##========== PREPARATION TEXT ===========##\n",
    "\n",
    "# Contraction\n",
    "def expand_contractions(sentence, contraction_mapping=CONTRACTION_MAP):\n",
    "    \"\"\"\n",
    "    Expand the contractions in a sentence. For example don't => do not.\n",
    "    \n",
    "    Paramters:\n",
    "    sentence (str): The input sentence to clean.\n",
    "    contraction_mapping (dict): A dictionary for mapping contractions.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    str: The expanded contraction sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    def expanded_match(contraction):\n",
    "        \"\"\"\n",
    "        Filter for expanding the matched contraction.\n",
    "        \n",
    "        Parameters:\n",
    "        contraction (str): The input of contraction\n",
    "        \n",
    "        Returns:\n",
    "        str: The expanded contraction.\n",
    "        \"\"\"\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "        \n",
    "        expanded_contraction = first_char + expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "    \n",
    "    expanded_sentence = contractions_pattern.sub(expanded_match, sentence)\n",
    "    return expanded_sentence\n",
    "\n",
    "\n",
    "def remove_extra_spaces(sentence):\n",
    "    # Use regex to replace multiple spaces with a single space\n",
    "    return re.sub(r'\\s+', ' ', sentence).strip()\n",
    "\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "    Remove all non-ASCII characters from the text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to clean.\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned text with only ASCII characters.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return ''.join([char for char in text if ord(char) < 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5537261-6c14-4343-b11d-2eded156a0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04064ce-b7fa-495e-b7b9-b40bfd581241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1a4cd-8a68-4faf-8100-58551b0f9170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540871a1-21fb-4111-9b36-1ced4f12bf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad42086-48fa-4fd8-ae1b-a12340ba8214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01c07b-8be8-4b12-8068-c98e30185055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fa119-4497-45b1-b29a-9847eba20cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d78de-aa18-4ed2-9bea-c45e9c70558a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ee89ea-9ddc-4201-8161-302a45d0b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import ast\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31d174b-2d95-4ca6-bd29-3c5b33ba9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nlp model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a5e46d-d4f5-4b94-8f68-f288250a9424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   review            99 non-null     object\n",
      " 1   ability           99 non-null     object\n",
      " 2   ability_filtered  99 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ability</th>\n",
       "      <th>ability_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The staff were incredibly helpful and patient,...</td>\n",
       "      <td>{0: [('staff', 'were patient'), ('staff', 'wer...</td>\n",
       "      <td>{0: [('staff', 'were patient'), ('staff', 'wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had a great experience purchasing my phone h...</td>\n",
       "      <td>{0: [('process', 'was quick'), ('process', 'wa...</td>\n",
       "      <td>{0: [('process', 'was quick')]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Their selection of phones is amazing, and the ...</td>\n",
       "      <td>{0: [('selection', 'is amazing'), ('price', 'a...</td>\n",
       "      <td>{0: [('selection', 'is amazing')]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I appreciate how the staff walked me through s...</td>\n",
       "      <td>{0: [('I', 'appreciate walked me'), ('I', 'app...</td>\n",
       "      <td>{0: [('I', 'appreciate walked me')]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great customer service, I left with the phone ...</td>\n",
       "      <td>{0: [('question', 'answered'), ('I', 'left wit...</td>\n",
       "      <td>{0: [('question', 'answered'), ('I', 'left wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  The staff were incredibly helpful and patient,...   \n",
       "1  I had a great experience purchasing my phone h...   \n",
       "2  Their selection of phones is amazing, and the ...   \n",
       "3  I appreciate how the staff walked me through s...   \n",
       "4  Great customer service, I left with the phone ...   \n",
       "\n",
       "                                             ability  \\\n",
       "0  {0: [('staff', 'were patient'), ('staff', 'wer...   \n",
       "1  {0: [('process', 'was quick'), ('process', 'wa...   \n",
       "2  {0: [('selection', 'is amazing'), ('price', 'a...   \n",
       "3  {0: [('I', 'appreciate walked me'), ('I', 'app...   \n",
       "4  {0: [('question', 'answered'), ('I', 'left wit...   \n",
       "\n",
       "                                    ability_filtered  \n",
       "0  {0: [('staff', 'were patient'), ('staff', 'wer...  \n",
       "1                    {0: [('process', 'was quick')]}  \n",
       "2                 {0: [('selection', 'is amazing')]}  \n",
       "3               {0: [('I', 'appreciate walked me')]}  \n",
       "4  {0: [('question', 'answered'), ('I', 'left wit...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('example.csv')\n",
    "\n",
    "# Convert the string columns to dictionaries\n",
    "df['ability'] = df['ability'].apply(ast.literal_eval)\n",
    "df['ability_filtered'] = df['ability_filtered'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc95407-7cd1-41ba-9d32-0641a52cf2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['staff were patient. staff were helpful.',\n",
       "       'process was quick. process was smooth.',\n",
       "       'selection is amazing. price are competitive.',\n",
       "       'I appreciate walked me. I appreciate walked through setting new device.',\n",
       "       'question answered. I left with phone.',\n",
       "       'I could not resist offer amazing deals on phones. I could not resist upgrading.',\n",
       "       'I expected. technician fixed faster. technician fixed issue.',\n",
       "       'experience really know stuff.',\n",
       "       'variety was impressive. I found perfect case.', '',\n",
       "       'staff was knowledgeable.', 'price were reasonable.',\n",
       "       'staff really went mile.',\n",
       "       'service service be Excellent. they helped find.',\n",
       "       'staff was friendly. deal was friendly.',\n",
       "       'I love store. buying buying be experience. fixing buying be experience.',\n",
       "       'I got good deal on old phone.',\n",
       "       'service are reliable. service are quick.',\n",
       "       'staff was helpful in setting phone.', 'I m satisfied.',\n",
       "       'staff was patient with questions. variety was patient with questions.',\n",
       "       'process was simple. I m thrilled.',\n",
       "       'they helped choose phone. they helped choose within budget.',\n",
       "       'phone was fixed in minutes.', 'I m. service is outstanding.',\n",
       "       'store hands.', 'I was comfortable with purchase. staff made.',\n",
       "       'I found needed what. they helped get great deal.',\n",
       "       'store has fantastic service.',\n",
       "       'staff was informative. I learned lot about features.',\n",
       "       'variety store be Excellent. store store be Excellent.', '',\n",
       "       'they were quick in setting phone.', '',\n",
       "       'staff are ready. layout is easy.', 'they helped save lot.',\n",
       "       'I been to many stores. one provides best service.',\n",
       "       'they always resolve quickly. service is top notch. they always resolve issues. service is notch.',\n",
       "       'they not fail recommend store. they not fail recommend to family. they not fail recommend to friends.',\n",
       "       'staff took time.', 'place place be Amazing.', 'plan is worth.',\n",
       "       'they were able.', '', 'staff was accommodating.',\n",
       "       'I had great experience with program.',\n",
       "       'service was efficient. service was quick.',\n",
       "       'they even helped transfer contacts. they even helped transfer without extra charge. they even helped data.',\n",
       "       'I bought from here. I bought it. phone has working flawlessly.',\n",
       "       'they fixed perfectly. they even gave discount on repair. they fixed screen.',\n",
       "       'this is reliable.',\n",
       "       'they offer discounts. they offer fantastic promotions.',\n",
       "       'selection selection be Great. service selection be Great. selection selection be phone. service selection be phone.',\n",
       "       'they resolved issue. they resolved very quickly professionally.',\n",
       "       'they fast attend to customers. store is organized.',\n",
       "       'you re looking for good deals.',\n",
       "       'I always leave store. I made right purchase.',\n",
       "       'they really know received excellent advice from team. they really know products.',\n",
       "       'phone looks new.',\n",
       "       'I had to wait over hour. staff was not apologetic.', '',\n",
       "       'price are high. selection is limited.',\n",
       "       'service is poor. one seemed.', 'phone was defective.',\n",
       "       'staff was unhelpful. staff was rude. I m not coming back.',\n",
       "       'they charged me. they charged extra for services. they felt like scam.',\n",
       "       'I had took way. I had took too long.',\n",
       "       'they did not inform of hidden fees. they did not inform me. I bought phone.',\n",
       "       'staff gave incorrect information about plan. staff seemed.',\n",
       "       'warranty is useless. they refused.',\n",
       "       'I had to return faulty phone. they twice gave refund.',\n",
       "       'I very disorganized waited forever.', '',\n",
       "       'they refused to honor promotion.', 'I felt pressured.',\n",
       "       'phone broke again. phone broke within week. repair was done poorly.',\n",
       "       'service was slow. they need.', 'phone was working after repair.',\n",
       "       'phone still has same issue after getting.',\n",
       "       'they upsold me. they upsold on plan.',\n",
       "       'they did not want. staff was unprofessional.',\n",
       "       'policy is awful. I could not exchange phone. I could not exchange despite defects.',\n",
       "       'they did not apply discount.',\n",
       "       'store was understaffed. store was messy.',\n",
       "       'phone broke. warranty just expired.', 'they kept trying.',\n",
       "       'they refused to refund me. job was incomplete.',\n",
       "       'representative were rude on phone.',\n",
       "       'I had to call multiple times.',\n",
       "       'they rushed me. they did not explain clearly. they rushed through purchase. they did not explain anything.',\n",
       "       'support is non.',\n",
       "       'phone stopped quality. phone stopped working outside window.',\n",
       "       'store was with long lines. store was with unhelpful staff. store was chaotic.',\n",
       "       'they did not even have after promising me. they did not even have phone. it was available.',\n",
       "       'they lost order.', 'I felt overcharged.', '',\n",
       "       'technician damaged during repair. technician damaged phone. they did not take responsibility.',\n",
       "       ''], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contraction(x):\n",
    "    flatten = [item for sublist in x.values() for item in sublist]\n",
    "\n",
    "    temp = []\n",
    "    for t in flatten:\n",
    "        temp.append(' '.join(t))\n",
    "\n",
    "    if len(temp) > 0:\n",
    "        return '. '.join(temp) + '.'\n",
    "    return ''\n",
    "    \n",
    "corpus = df['ability'].apply(contraction).values\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9936950b-3c3c-4c2b-a203-36586b566a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "# Preprocessing text\n",
    "def preprocessing(text):\n",
    "    text = remove_extra_spaces(text)\n",
    "    text = expand_contractions(text)\n",
    "    text = remove_non_ascii(text)\n",
    "\n",
    "    # Get token of words\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        t = token.lemma_.lower()\n",
    "\n",
    "        if re.match(r'^[0-9\\W]+$', t) or len(t) < 3 or t in stop_words:\n",
    "            continue\n",
    "        # If the token is adjective, noun, propn, or verb\n",
    "        if token.pos_ in ['NOUN', 'PROPN']:\n",
    "            result.append(t)\n",
    "        elif token.pos_ in ['ADJ', 'VERB']:\n",
    "            result.append(t)\n",
    "        else:\n",
    "            continue\n",
    "    return result\n",
    "\n",
    "# Create texts\n",
    "texts = [preprocessing(document) for document in corpus]\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "\n",
    "\n",
    "# Convert documents into Bag-of-words format\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the TF-IDF model\n",
    "tfidf_model = gensim.models.TfidfModel(corpus_bow)\n",
    "\n",
    "# Get corpus tfidf \n",
    "corpus_tfidf = tfidf_model[corpus_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab3636b-40cd-46ac-8e6d-64a0e9143b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:30<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "def topic_model_coherence_generator(corpus, texts, dictionary,\n",
    "                                    start_topic_count=2, end_topic_count=10,\n",
    "                                    step=1, cpus=1):\n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary,\n",
    "                                           chunksize=1740, alpha='auto',\n",
    "                                           eta='auto', random_state=42,\n",
    "                                           iterations=500, num_topics=topic_nums,\n",
    "                                           passes=20, eval_every=None)\n",
    "\n",
    "        cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model,\n",
    "                                                                     corpus=corpus,\n",
    "                                                                     texts=texts,\n",
    "                                                                     dictionary=dictionary,\n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(lda_model)\n",
    "\n",
    "\n",
    "    return models, coherence_scores\n",
    "\n",
    "models, coherence_scores = topic_model_coherence_generator(corpus=corpus_tfidf,\n",
    "                                                           texts=texts,\n",
    "                                                           dictionary=dictionary)\n",
    "opt_model = models[np.argmax(coherence_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4665cde-ad00-42e2-9c68-a9edfa8bed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall mean coherence score\n",
    "topics_coherences = opt_model.top_topics(corpus_tfidf, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bb97dfb-226b-48f6-b551-709ed5e0e50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6780125508564886,\n",
       " 0.6936101867402961,\n",
       " 0.6954448369156887,\n",
       " 0.6981522176775626,\n",
       " 0.68509081595846,\n",
       " 0.6897949182640505,\n",
       " 0.6482217841172262,\n",
       " 0.6335215408719335,\n",
       " 0.6245686835264562]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9627db7-b282-48ab-86a0-65704177b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic 1:\n",
      "[('help', 0.024), ('deal', 0.023), ('great', 0.022), ('time', 0.022), ('experience', 0.02), ('staff', 0.019), ('friendly', 0.018), ('selection', 0.017), ('find', 0.017), ('get', 0.017), ('service', 0.015), ('resist', 0.015), ('order', 0.014), ('lose', 0.014), ('explain', 0.014), ('rush', 0.014), ('want', 0.014), ('unprofessional', 0.014), ('program', 0.014), ('phone', 0.013)]\n",
      "\n",
      "Topic 2:\n",
      "[('staff', 0.025), ('store', 0.025), ('set', 0.024), ('phone', 0.023), ('resolve', 0.023), ('helpful', 0.02), ('patient', 0.02), ('question', 0.019), ('work', 0.018), ('rude', 0.018), ('service', 0.017), ('good', 0.016), ('leave', 0.016), ('upsold', 0.015), ('outstanding', 0.015), ('hand', 0.015), ('price', 0.015), ('selection', 0.015), ('buy', 0.015), ('unhelpful', 0.014)]\n",
      "\n",
      "Topic 3:\n",
      "[('fix', 0.028), ('reliable', 0.026), ('service', 0.024), ('refuse', 0.023), ('discount', 0.022), ('promotion', 0.016), ('quick', 0.016), ('knowledgeable', 0.016), ('refund', 0.016), ('issue', 0.016), ('phone', 0.015), ('apply', 0.014), ('minute', 0.014), ('charge', 0.014), ('inform', 0.014), ('give', 0.014), ('offer', 0.014), ('variety', 0.013), ('try', 0.013), ('keep', 0.013)]\n",
      "\n",
      "Topic 4:\n",
      "[('store', 0.026), ('phone', 0.023), ('wait', 0.021), ('help', 0.02), ('accommodate', 0.019), ('overcharge', 0.017), ('fantastic', 0.017), ('break', 0.017), ('choose', 0.017), ('stop', 0.016), ('available', 0.015), ('promise', 0.015), ('save', 0.015), ('new', 0.015), ('look', 0.015), ('stuff', 0.015), ('simple', 0.014), ('thrilled', 0.014), ('feel', 0.014), ('lot', 0.013)]\n",
      "\n",
      "Topic 5:\n",
      "[('staff', 0.021), ('take', 0.019), ('seem', 0.018), ('able', 0.018), ('satisfied', 0.018), ('plan', 0.018), ('defective', 0.017), ('place', 0.017), ('mile', 0.017), ('process', 0.015), ('worth', 0.015), ('pressured', 0.015), ('reasonable', 0.015), ('exchange', 0.014), ('poor', 0.014), ('slow', 0.014), ('need', 0.014), ('service', 0.013), ('recommend', 0.013), ('fail', 0.013)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize result: Topic with weights\n",
    "\n",
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print(\"LDA Topics with Weights\")\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "  print(f'Topic {idx + 1}:')\n",
    "  print([(term, round(wt, 3)) for wt, term in topic])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b4812b-efb5-47b0-a5fd-b52aac6d0654",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- Topic 1: This topic revolves around positive interactions with staff, with a focus on helpfulness and friendliness.\n",
    "- Topic 2: This topic highlights mixed customer service experiences, ranging from helpful and patient staff to rude or unhelpful interactions.\n",
    "- Topic 3: The focus here is on the reliability of services provided and the handling of customer issues.\n",
    "- Topic 4: This topic focuses on the in-store experience, including wait times and the store’s ability to meet customer needs.\n",
    "- Topic 5: This topic touches on customer satisfaction with product quality and service outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1682b9-6f77-4c9c-ab82-44d5c1d3854e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
