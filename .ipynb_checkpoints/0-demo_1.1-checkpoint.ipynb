{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2705bb13-b9a9-4136-9d7c-e46693917b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Preparation text\n",
    "\n",
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "##========== PREPARATION TEXT ===========##\n",
    "\n",
    "# Contraction\n",
    "def expand_contractions(sentence, contraction_mapping=CONTRACTION_MAP):\n",
    "    \"\"\"\n",
    "    Expand the contractions in a sentence. For example don't => do not.\n",
    "    \n",
    "    Paramters:\n",
    "    sentence (str): The input sentence to clean.\n",
    "    contraction_mapping (dict): A dictionary for mapping contractions.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    str: The expanded contraction sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    def expanded_match(contraction):\n",
    "        \"\"\"\n",
    "        Filter for expanding the matched contraction.\n",
    "        \n",
    "        Parameters:\n",
    "        contraction (str): The input of contraction\n",
    "        \n",
    "        Returns:\n",
    "        str: The expanded contraction.\n",
    "        \"\"\"\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "        \n",
    "        expanded_contraction = first_char + expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "    \n",
    "    expanded_sentence = contractions_pattern.sub(expanded_match, sentence)\n",
    "    return expanded_sentence\n",
    "\n",
    "\n",
    "def remove_extra_spaces(sentence):\n",
    "    # Use regex to replace multiple spaces with a single space\n",
    "    return re.sub(r'\\s+', ' ', sentence).strip()\n",
    "\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "    Remove all non-ASCII characters from the text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to clean.\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned text with only ASCII characters.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return ''.join([char for char in text if ord(char) < 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5504ba9-ebcd-48cb-a653-669526682845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5473f-39d9-4ccb-922b-d491311d47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve efficiency analysis\n",
    "# 1. Semantic clustering\n",
    "# 2. PageRank for selecting representation documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28ea3c87-801d-4f26-bacf-52da98debe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33396 entries, 0 to 33395\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   reviewer_id  33396 non-null  int64 \n",
      " 1   review_time  33396 non-null  object\n",
      " 2   review       33396 non-null  object\n",
      " 3   rating       33396 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>4 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id   review_time  \\\n",
       "0            1  3 months ago   \n",
       "1            2    5 days ago   \n",
       "2            3    5 days ago   \n",
       "3            4   a month ago   \n",
       "4            5  2 months ago   \n",
       "\n",
       "                                              review   rating  \n",
       "0  Why does it look like someone spit on my food?...   1 star  \n",
       "1  It'd McDonalds. It is what it is as far as the...  4 stars  \n",
       "2  Made a mobile order got to the speaker and che...   1 star  \n",
       "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...  5 stars  \n",
       "4  I repeat my order 3 times in the drive thru, a...   1 star  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('sample-mcd.csv', encoding='latin1')\n",
    "df = pd.read_csv('McDonald_s_Reviews.csv', encoding='latin1')\n",
    "df = df[['reviewer_id', 'review_time', 'review', 'rating']].copy()\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5165824e-7822-477a-ba10-70d575352a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply extraction\n",
    "\n",
    "def process_text(x):\n",
    "    # Prepare sentence\n",
    "    texts = expand_contractions(x)\n",
    "    texts = remove_extra_spaces(x)\n",
    "    texts = remove_non_ascii(x)\n",
    "    \n",
    "    return texts\n",
    "\n",
    "tqdm.pandas()\n",
    "df['review_processed'] = df['review'].progress_apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "65f6bee2-8562-4d2a-b488-e8f84da8a2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = df['review_processed'].values[:10_000]\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44121f-b130-45e8-9d53-3d8d6d4da360",
   "metadata": {},
   "source": [
    "**Semantic Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cdfd81-29a1-44fb-8f6c-0add9ef9ee9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cebd1f89-50a2-43da-96bb-6fd37ab1a0f2",
   "metadata": {},
   "source": [
    "**Selecting Representative Documents Using PageRank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dc8b1fa9-3214-4669-acde-00e1ff000285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_similarity(documents):\n",
    "    \"\"\"\n",
    "    Compute pairwise BM25 similarity between sentences.\n",
    "    \"\"\"\n",
    "    tokenized_documents = [word_tokenize(sentence.lower()) for sentence in documents]\n",
    "    bm25 = BM25Okapi(tokenized_documents)\n",
    "    num_documents = len(documents)\n",
    "    bm25_matrix = np.zeros((num_documents, num_documents))\n",
    "    \n",
    "    # for i, sentence in tqdm(enumerate(tokenized_sentences), desc=\"Calculating BM25 Scores\"):\n",
    "    #     scores = bm25.get_scores(sentence)  # Compute scores for current sentence against all others\n",
    "    #     bm25_matrix[i] = scores\n",
    "    #     # Wrap the delayed function with tqdm\n",
    "\n",
    "    for i in tqdm(range(len(tokenized_documents)), desc=\"Calculating BM25 Scores\"):\n",
    "        scores = bm25.get_scores(tokenized_documents[i])\n",
    "        bm25_matrix[i] = scores\n",
    "\n",
    "    return bm25_matrix\n",
    "\n",
    "def cosine_similarity_matrix(documents):\n",
    "    \"\"\"\n",
    "    Compute pairwise cosine similarity between sentences using TF-IDF.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    cosine_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return cosine_matrix\n",
    "\n",
    "def hybrid_similarity(documents, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Combine BM25 and cosine similarity matrices with a weighting factor.\n",
    "    \n",
    "    Parameters:\n",
    "    - sentences (list of str): List of sentences.\n",
    "    - alpha (float): Weight for BM25 similarity. (1-alpha) is the weight for cosine similarity.\n",
    "    \n",
    "    Returns:\n",
    "    - hybrid_matrix (np.array): Combined similarity matrix.\n",
    "    \"\"\"\n",
    "    bm25_matrix = bm25_similarity(documents)\n",
    "    cosine_matrix = cosine_similarity_matrix(documents)\n",
    "    print(f\"BM25 {bm25_matrix.shape}\\nCOSINE_MATRIX {cosine_matrix.shape}\")\n",
    "    hybrid_matrix = alpha * bm25_matrix + (1 - alpha) * cosine_matrix\n",
    "    return hybrid_matrix\n",
    "\n",
    "def pagerank_hybrid_summarization(documents, threshold=0.75, min_documents=2, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Summarize text using a hybrid of BM25 and cosine similarity with PageRank.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): Input text to summarize.\n",
    "    - num_sentences (int): Number of sentences in the summary.\n",
    "    - alpha (float): Weight for BM25 similarity in the hybrid similarity calculation.\n",
    "    \n",
    "    Returns:\n",
    "    - summary (str): Generated summary.\n",
    "    \"\"\"\n",
    "\n",
    "    def num_documents(scores):\n",
    "        scores.sort(reverse=True)\n",
    "        current_value = 0\n",
    "        for i in tqdm(range(len(scores)), desc=\"Optimize Number Documents\"):\n",
    "            current_value += scores[i]\n",
    "            if current_value > threshold:\n",
    "                return i\n",
    "        return\n",
    "        \n",
    "    if len(documents) < min_documents:\n",
    "        return documents  # Return original documents\n",
    "\n",
    "    print(\"COMPUTE HYBRID SIMILARITY\")\n",
    "    similarity_matrix = hybrid_similarity(documents, alpha)\n",
    "\n",
    "    print(\"APPLY PAGERANK\")\n",
    "    graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(graph)\n",
    "\n",
    "    print(\"DETERMINE NUMBER OF DOCUMENTS\")\n",
    "    n = num_documents(list(scores.values()))\n",
    "    print(\"OPTIMUM SENTENCES: \", n)\n",
    "\n",
    "      \n",
    "    print(\"SELECT TOP N DOCUMENTS\")\n",
    "    ranked_indices = sorted(scores, key=scores.get, reverse=True)[:n]\n",
    "    ranked_indices = sorted(ranked_indices)\n",
    "    pagerank_documents = []\n",
    "    for i in tqdm(range(len(ranked_indices)), desc=\"Sorting Documents\"):\n",
    "        idx = ranked_indices[i]\n",
    "        pagerank_documents.append(documents[idx])\n",
    "\n",
    "    # Step 5: Return the summary\n",
    "    return pagerank_documents\n",
    "\n",
    "\n",
    "\n",
    "# Alternative using compression\n",
    "\n",
    "# def calculate_optimal_num_sentences(text, compression_ratio=0.2):\n",
    "#     sentences = sent_tokenize(text)\n",
    "#     optimal_num_sentences = max(1, int(len(sentences) * compression_ratio))  # Ensure at least 1 sentence\n",
    "#     return optimal_num_sentences\n",
    "\n",
    "# n = calculate_optimal_num_sentences(text, compression_ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab00f7-ab03-406b-9f7f-cf95adec588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "summary = pagerank_hybrid_summarization(documents, alpha=0.7)\n",
    "end_time = time.time()\n",
    "print(len(summary))\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
