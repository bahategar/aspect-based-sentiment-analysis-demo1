{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e421b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "# glove_input_file = './util/glove.twitter.27B.200d.txt'\n",
    "\n",
    "# # Load GloVe vectors directly into a KeyedVectors instance\n",
    "# model = KeyedVectors.load_word2vec_format(glove_input_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3aac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('./util/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf49a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4086e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33396 entries, 0 to 33395\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   reviewer_id  33396 non-null  int64 \n",
      " 1   review_time  33396 non-null  object\n",
      " 2   review       33396 non-null  object\n",
      " 3   rating       33396 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>4 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id   review_time  \\\n",
       "0            1  3 months ago   \n",
       "1            2    5 days ago   \n",
       "2            3    5 days ago   \n",
       "3            4   a month ago   \n",
       "4            5  2 months ago   \n",
       "\n",
       "                                              review   rating  \n",
       "0  Why does it look like someone spit on my food?...   1 star  \n",
       "1  It'd McDonalds. It is what it is as far as the...  4 stars  \n",
       "2  Made a mobile order got to the speaker and che...   1 star  \n",
       "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...  5 stars  \n",
       "4  I repeat my order 3 times in the drive thru, a...   1 star  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./McDonald_s_Reviews.csv\", encoding='latin1')\n",
    "df = df[['reviewer_id', 'review_time', 'review', 'rating']]\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87056ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b7d2b",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236f4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.normalization as norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d668248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization into sentence\n",
    "\n",
    "df_st = df[['reviewer_id', 'review']].copy()\n",
    "\n",
    "# Sentence Tokenization\n",
    "df_st['token_sentence'] = df_st['review'].apply(norm.sentence_tokenize)\n",
    "df_st = df_st.explode('token_sentence')\n",
    "df_st['token_sentence'] = df_st['token_sentence'].str.strip()\n",
    "\n",
    "# Remove non-ASCII\n",
    "df_st['token_sentence'] = df_st['token_sentence'].apply(norm.remove_non_ascii)\n",
    "\n",
    "# Expand contractions\n",
    "df_st['token_sentence'] = df_st['token_sentence'].apply(norm.expand_contractions)\n",
    "\n",
    "# Remove characters\n",
    "df_st['token_sentence'] = df_st['token_sentence'].apply(norm.remove_characters, args=(True,))\n",
    "\n",
    "# Remove enter tab\n",
    "df_st['token_clean'] = df_st['token_sentence'].apply(norm.remove_enter_tab)\n",
    "\n",
    "# Lemmatization\n",
    "df_st['token_clean'] = df_st['token_clean'].apply(norm.lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49666787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 546 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   reviewer_id     546 non-null    int64 \n",
      " 1   review          546 non-null    object\n",
      " 2   token_sentence  546 non-null    object\n",
      " 3   token_clean     546 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 21.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>review</th>\n",
       "      <th>token_sentence</th>\n",
       "      <th>token_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>Why does it look like someone spit on my food</td>\n",
       "      <td>why do it look like someone spit on my food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>I had a normal transaction</td>\n",
       "      <td>i have a normal transaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>everyone was chill and polite</td>\n",
       "      <td>everyone be chill and polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>but now i dont want to eat this.</td>\n",
       "      <td>but now i dont want to eat this .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>Im trying not to think about what this milky w...</td>\n",
       "      <td>im try not to think about what this milky whit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id                                             review  \\\n",
       "0            1  Why does it look like someone spit on my food?...   \n",
       "0            1  Why does it look like someone spit on my food?...   \n",
       "0            1  Why does it look like someone spit on my food?...   \n",
       "0            1  Why does it look like someone spit on my food?...   \n",
       "0            1  Why does it look like someone spit on my food?...   \n",
       "\n",
       "                                      token_sentence  \\\n",
       "0      Why does it look like someone spit on my food   \n",
       "0                         I had a normal transaction   \n",
       "0                      everyone was chill and polite   \n",
       "0                   but now i dont want to eat this.   \n",
       "0  Im trying not to think about what this milky w...   \n",
       "\n",
       "                                         token_clean  \n",
       "0        why do it look like someone spit on my food  \n",
       "0                        i have a normal transaction  \n",
       "0                       everyone be chill and polite  \n",
       "0                  but now i dont want to eat this .  \n",
       "0  im try not to think about what this milky whit...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_st.info())\n",
    "df_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9738ba",
   "metadata": {},
   "source": [
    "# Determine Aspect with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.model as models\n",
    "import util.utility as util\n",
    "from util.utility import get_topics, predict_topic\n",
    "from util.normalization import preprocess_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c69b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = df_st['token_clean'].values\n",
    "\n",
    "# Vectorize the texts using CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "\n",
    "optimal_model, vectorizer = models.get_opt_lda_model(texts, vectorizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics\n",
    "def print_topics(model, vectorizer, num_words=10):\n",
    "    topics = model.components_\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for idx, topic in enumerate(topics):\n",
    "        print(f\"Topic {idx + 1}:\")\n",
    "        print([feature_names[i] for i in topic.argsort()[:-num_words - 1:-1]])\n",
    "        print([topic.argsort()[:-num_words - 1: -1]])\n",
    "\n",
    "print_topics(optimal_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_topics = get_topics(optimal_model, vectorizer, 0.25)\n",
    "print(dict_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393de8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_topic(\"Why does it look like someone spit on my food\", \n",
    "              optimal_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbf060",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.get_nearest_word(\"Why does it look like someone spit on my food\", \n",
    "                      list(dict_topics[1]), model,\n",
    "                      threshold=0.4, get_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x, get_all=False, k=None):\n",
    "    cat = predict_topic(x, optimal_model, vectorizer)\n",
    "    if not cat:\n",
    "        return set()\n",
    "    topic = dict_topics[cat]\n",
    "    result = util.get_nearest_word(x, topic, model,\n",
    "                                   threshold=0.0, get_all=True)\n",
    "    if get_all:\n",
    "        return set(result.keys())\n",
    "    else:\n",
    "        if not k:\n",
    "            return set([list(result.keys())[0]])\n",
    "        return set(list(result.keys())[:k])\n",
    "\n",
    "df_st['topic_lda'] = df_st['token_clean'].apply(fun, args=(False, 3))\n",
    "df_st['cat_topic_lda'] = df_st['token_clean'].apply(predict_topic, args=(optimal_model, vectorizer,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eca359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca373658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st['cat_topic_lda'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7b62c",
   "metadata": {},
   "source": [
    "# Get Aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb212e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_st['sub_aspect'] = df_st['token_clean'].progress_apply(util.get_aspect_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de994173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = \"\"\n",
    "topic_lda = df_st['topic_lda'].values\n",
    "sub_aspect = df_st['sub_aspect'].values\n",
    "for i in range(df_st.shape[0]):\n",
    "    text = text + \" \" + \" \".join(list(topic_lda[i])) + \" \" + \" \".join(list(sub_aspect[i]))\n",
    "    \n",
    "\n",
    "text = text.strip()\n",
    "\n",
    "wordcloud = WordCloud(background_color='white').generate(text)\n",
    "plt.style.use('classic')\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = ['food', 'service', 'order' ,]\n",
    "\n",
    "def fun1(x):\n",
    "    temp = set()\n",
    "    for e in x:\n",
    "        aspect = util.get_nearest_word(e, aspects, model)\n",
    "        if aspect:\n",
    "            temp.add(aspect)\n",
    "    temp = list(temp)\n",
    "    return temp\n",
    "\n",
    "def fun2(x):\n",
    "    result = util.get_nearest_word(\" \".join(x), aspects, model)\n",
    "#     print(util.get_nearest_word(\" \".join(x), aspects, model, 0.45, get_all=True))\n",
    "    if not result:\n",
    "        return []\n",
    "    return [result]\n",
    "\n",
    "tqdm.pandas()\n",
    "# df_st['sub_aspect'].apply(fun)\n",
    "# df_st['aspect'] = df_st['sub_aspect'].progress_apply(lambda x: list({util.get_aspect(e, aspects=aspects, model=model) \n",
    "#                                                                      for e in x}))\n",
    "# df_st['aspect'] = df_st['sub_aspect'].progress_apply(fun1)\n",
    "# df_st['aspect'] = df_st['topic_lda'].progress_apply(fun2)\n",
    "df_st['aspect'] = [list(set(fun1(i) + fun2(j))) for i,j in zip(df_st.sub_aspect, df_st.topic_lda)]\n",
    "df_st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44f3d7",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76579562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.model as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd50fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_st['token_clean'].iloc[4]\n",
    "print(sample)\n",
    "models.pattern_lexicon_model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b71236",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_st['pattern_prediction'] = df_st['token_clean'].progress_apply(models.pattern_lexicon_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_st['roberta_prediction'] = df_st['token_sentence'].progress_apply(models.roberta_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bef846",
   "metadata": {},
   "source": [
    "# Get Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bee164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(aspect, model):\n",
    "    \n",
    "    # Initialization\n",
    "    get_aspects = df_st['aspect'].values\n",
    "    get_predictions = df_st[model].values\n",
    "    \n",
    "    temp = []\n",
    "\n",
    "    for i in range(len(get_aspects)):\n",
    "        if (not get_aspects[i]) or (aspect not in get_aspects[i]):\n",
    "            temp.append(0)\n",
    "        else:\n",
    "            if get_predictions[i] == 'negative':\n",
    "                temp.append(-99)\n",
    "            else:\n",
    "                temp.append(1)\n",
    "    return np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aspects = df_st['aspect'].values\n",
    "get_pattern = df_st['pattern_prediction'].values\n",
    "get_roberta = df_st['roberta_prediction'].values\n",
    "\n",
    "new_fields = set()\n",
    "for aspect in aspects:\n",
    "    \n",
    "    df_st[aspect + f\"_pattern\"] = get_result(aspect, 'pattern_prediction')\n",
    "    df_st[aspect + f\"_roberta\"] = get_result(aspect, 'roberta_prediction')\n",
    "    new_fields.add(aspect + f\"_pattern\")\n",
    "    new_fields.add(aspect + f\"_roberta\")\n",
    "new_fields = list(new_fields)\n",
    "print(df_st.info())\n",
    "df_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df_st[ ['reviewer_id'] + new_fields ].groupby('reviewer_id').sum()\n",
    "\n",
    "grouped_df = grouped_df.applymap(lambda x: 0 if x < 0 else 1).reset_index()\n",
    "\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc24521",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.merge(grouped_df, on='reviewer_id', how='left')\n",
    "\n",
    "print(result.info())\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f002c8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('validation.csv').dropna()\n",
    "\n",
    "print(df_val.info())\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_sentiment(x):\n",
    "    if x == 'Negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1    \n",
    "\n",
    "def join_aspect(x, y):\n",
    "    if x==1 and y==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "for aspect in ['food', 'service', 'order', 'place']:\n",
    "    df_val[aspect] = df_val[aspect].apply(mapping_sentiment)\n",
    "\n",
    "# df_val['service'] = [join_aspect(x, y) for x, y in zip(df_val.service, df_val.order)]\n",
    "# df_val = df_val.drop('order', axis=1)\n",
    "print(df_val.info())\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "print(\"Prediction pattern\")\n",
    "print(\"==============================================================\")\n",
    "for aspect in aspects:\n",
    "    try:\n",
    "        actual = df_val[aspect]\n",
    "        pred = result[aspect + \"_pattern\"]\n",
    "        print(f\"ROC AUC Score: \", roc_auc_score(actual, pred))\n",
    "        print(f\"Result {aspect}\")\n",
    "        print(classification_report(actual, pred))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a954f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction roberta\")\n",
    "print(\"==============================================================\")\n",
    "for aspect in aspects:\n",
    "    try:\n",
    "        actual = df_val[aspect]\n",
    "        pred = result[aspect + \"_roberta\"]\n",
    "        print(f\"ROC AUC Score: \", roc_auc_score(actual, pred))\n",
    "        print(f\"Result {aspect}\")\n",
    "        print(classification_report(actual, pred))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c643f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4389c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
