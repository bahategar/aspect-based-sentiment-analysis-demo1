{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4972684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7238b6f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnorm\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutility\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\aspect-based-sentiment-analysis-demo1\\util\\utility.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m nlp_spacy \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# NLP model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m nlp \u001b[38;5;241m=\u001b[39m StanfordCoreNLP(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(script_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstanford-corenlp-4.5.7\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Load Bing Liu's opinion word dictionary\u001b[39;00m\n\u001b[0;32m     24\u001b[0m bing_liu_opinion_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()  \u001b[38;5;66;03m# Add the actual list of opinion words here\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\stanfordcorenlp\\corenlp.py:46\u001b[0m, in \u001b[0;36mStanfordCoreNLP.__init__\u001b[1;34m(self, path_or_host, port, memory, lang, timeout, quiet, logging_level)\u001b[0m\n\u001b[0;32m     42\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing an existing server \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Check Java\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mcall([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjava\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-version\u001b[39m\u001b[38;5;124m'\u001b[39m], stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJava not found.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Check if the dir exists\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:389\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m p\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "import util.normalization as norm\n",
    "import util.model as models\n",
    "import util.utility as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./sample-mcd.csv', encoding='latin1')\n",
    "df = df[['reviewer_id', 'review_time', 'review', 'rating']]\n",
    "\n",
    "df['rating'] = df['rating'].apply(lambda x: int(x.split(\" \")[0]))\n",
    "\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25f835",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53cc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm = df[['reviewer_id', 'review']].copy()\n",
    "\n",
    "# Remove non-ASCII\n",
    "df_sm['review_clean'] = df_sm['review'].apply(norm.remove_non_ascii)\n",
    "\n",
    "# Expand contractions\n",
    "df_sm['review_clean'] = df_sm['review_clean'].apply(norm.expand_contractions)\n",
    "\n",
    "# Remove characters\n",
    "df_sm['review_clean'] = df_sm['review_clean'].apply(norm.remove_characters, args=(True, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# classifier = pipeline(\"summarization\")\n",
    "classifier = pipeline(\"summarization\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarize(text, min_length=25, max_length=68):\n",
    "    result = classifier(text, min_length=min_length, max_length=max_length)\n",
    "    return result[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_sm['summarize'] = df_sm['review_clean'].progress_apply(get_summarize)\n",
    "print(df_sm.info())\n",
    "df_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Tokenization\n",
    "df_st = df_sm.copy()\n",
    "df_st['token_sentence'] = df_st['summarize'].apply(norm.sentence_tokenize)\n",
    "df_st = df_st.explode('token_sentence')\n",
    "df_st['token_sentence'] = df_st['token_sentence'].str.strip()\n",
    "\n",
    "# Remove characters\n",
    "df_st['token_sentence'] = df_st['token_sentence'].apply(norm.remove_characters, args=(True, ))\n",
    "\n",
    "# Lower text\n",
    "# df_st['token_sentence'] = df_st['token_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "# Lemmatization\n",
    "df_st['token_lemma'] = df_st['token_sentence'].apply(norm.lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10c488",
   "metadata": {},
   "source": [
    "# Get Aspect and Applied Sentiment Analysis (Rules Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c37d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get aspect from rules\n",
    "tqdm.pandas()\n",
    "df_st['aspect'] = df_st['token_lemma']\\\n",
    "                        .progress_apply(util.get_aspect_rules)\n",
    "\n",
    "print(df_st.info())\n",
    "df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a680e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_st['aspect'].apply(lambda x: False if len(x) == 0 else True).values\n",
    "\n",
    "temp = df_st[mask].groupby(['reviewer_id'])\\\n",
    "                .agg({'token_sentence': lambda x: '.\\n'.join(x),\n",
    "                      'token_lemma': lambda x: '.\\n'.join(x)})\\\n",
    "                .reset_index()\n",
    "\n",
    "df_prc = df_st.groupby(['reviewer_id'])\\\n",
    "                .agg({'aspect': lambda x: set().union(*x),})\\\n",
    "                .reset_index()\n",
    "\n",
    "df_prc = df_prc.merge(temp, on='reviewer_id', how='left').fillna(\"\")\n",
    "\n",
    "df_prc = df_sm.merge(df_prc, on='reviewer_id', how='left')\n",
    "print(df_prc.info())\n",
    "df_prc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e09e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prc['token_sentence'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prc['summarize'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = \"\"\n",
    "sub_aspect = df_prc['aspect'].values\n",
    "for i in range(df_prc.shape[0]):\n",
    "    text = text + \" \" + \" \".join(list(sub_aspect[i]))\n",
    "    \n",
    "\n",
    "text = text.strip()\n",
    "\n",
    "wordcloud = WordCloud(background_color='white').generate(text)\n",
    "plt.style.use('classic')\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35752e6",
   "metadata": {},
   "source": [
    "# Get Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feadf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_optimum_lda(dictionary, corpus, texts, limit,\n",
    "#                     start=2, step=1, get_result=False,\n",
    "#                     iterations=20, passes=1):\n",
    "#     coherence_values = []\n",
    "    \n",
    "#     for n in range(start, limit, step):\n",
    "#         lda = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                          num_topics=n,\n",
    "#                                          id2word=dictionary,\n",
    "#                                          iterations=iterations,\n",
    "#                                          passes=passes)\n",
    "        \n",
    "#         # Create coherence\n",
    "#         coherence_model = CoherenceModel(model=lda, \n",
    "#                                          texts=texts,\n",
    "#                                          dictionary=dictionary, \n",
    "#                                          coherence='c_v')\n",
    "#         coherence_values.append(coherence_model.get_coherence())\n",
    "    \n",
    "    \n",
    "#     opt_num_topics = start + coherence_values.index(max(coherence_values))\n",
    "    \n",
    "#     lda_opt = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                          num_topics=opt_num_topics,\n",
    "#                                          id2word=dictionary)\n",
    "    \n",
    "#     if get_result:\n",
    "#         print(coherence_values)\n",
    "    \n",
    "#     return lda_opt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d62cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# from gensim.models import CoherenceModel\n",
    "\n",
    "\n",
    "# texts = df_prc['summarize'].apply(util.preprocess_lda)\n",
    "# # texts = df_prc['sub_aspect'].apply(lambda x: ', '.join(list(x))).apply(util.preprocess_lda)\n",
    "\n",
    "# dictionary = gensim.corpora.Dictionary(texts)\n",
    "\n",
    "# dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100_000)\n",
    "# bow_corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "# lda_opt = get_optimum_lda(dictionary, bow_corpus,\n",
    "#                           texts, 10, get_result=True,\n",
    "#                           passes=75, iterations=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4821f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print topic\n",
    "# for idx, topic in lda_opt.print_topics(-1):\n",
    "#     print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_topic(text):\n",
    "#     text = util.preprocess_lda(text)\n",
    "#     bow_vector = dictionary.doc2bow(text)\n",
    "    \n",
    "#     result = sorted(lda_opt[bow_vector], \n",
    "#                     key=lambda x: -1*x[1])[0][0]\n",
    "    \n",
    "#     return result\n",
    "    \n",
    "# # Extract keywords into a dictionary or list\n",
    "# threshold = 0.05\n",
    "# topics_dict = {}\n",
    "# for topic_num, topic in lda_opt.show_topics(num_topics=10,\n",
    "#                                                 num_words=10,\n",
    "#                                                 formatted=False):\n",
    "#     keywords = [word for word, w in topic if w > threshold]\n",
    "#     topics_dict[topic_num] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569af93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "# df_prc['topic'] = df_prc['summarize'].progress_apply(predict_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "# df_prc['topic_keys'] = df_prc['topic'].progress_apply(lambda x: topics_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4b47d",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = df_prc[['reviewer_id', 'review', 'summarize', 'aspect', 'topic_sentence', 'rating']].copy()\n",
    "result = df_prc.drop('review_clean', axis=1).copy()\n",
    "result = result.merge(df[['reviewer_id','rating']],\n",
    "                      on='reviewer_id',\n",
    "                      how='left')\n",
    "\n",
    "result['aspect'] = result['aspect'].apply(lambda x: ', '.join(list(x)))\n",
    "# result['sub_aspect'] = result['sub_aspect'].apply(lambda x: list(x))\n",
    "# result['topic_keys'] = result['topic_keys'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# result.to_csv(\"./mcd_result/base_mcd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
