{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c615831-571b-45e7-ac47-8b869dc50e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "eac21c66-2234-4386-87f0-6d9c63bdd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Preparation text\n",
    "\n",
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "##========== PREPARATION TEXT ===========##\n",
    "\n",
    "# Contraction\n",
    "def expand_contractions(sentence, contraction_mapping=CONTRACTION_MAP):\n",
    "    \"\"\"\n",
    "    Expand the contractions in a sentence. For example don't => do not.\n",
    "    \n",
    "    Paramters:\n",
    "    sentence (str): The input sentence to clean.\n",
    "    contraction_mapping (dict): A dictionary for mapping contractions.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    str: The expanded contraction sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    def expanded_match(contraction):\n",
    "        \"\"\"\n",
    "        Filter for expanding the matched contraction.\n",
    "        \n",
    "        Parameters:\n",
    "        contraction (str): The input of contraction\n",
    "        \n",
    "        Returns:\n",
    "        str: The expanded contraction.\n",
    "        \"\"\"\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "        \n",
    "        expanded_contraction = first_char + expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "    \n",
    "    expanded_sentence = contractions_pattern.sub(expanded_match, sentence)\n",
    "    return expanded_sentence\n",
    "\n",
    "\n",
    "def remove_extra_spaces(sentence):\n",
    "    # Use regex to replace multiple spaces with a single space\n",
    "    return re.sub(r'\\s+', ' ', sentence).strip()\n",
    "\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "    Remove all non-ASCII characters from the text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to clean.\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned text with only ASCII characters.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return ''.join([char for char in text if ord(char) < 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2314849b-0de2-4d27-ae9b-c48be7df3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper get specific token and handling token\n",
    "\n",
    "\n",
    "##=========== EXTRACT ASPECT ============##\n",
    "# Cross product two lists\n",
    "def cross_product_str(first, second):\n",
    "    \"\"\"\n",
    "    Do cross product\n",
    "\n",
    "    parameters\n",
    "    -----------\n",
    "    first: list/string\n",
    "    second: list/string\n",
    "\n",
    "    return: list of string\n",
    "    \"\"\"\n",
    "    temp = []\n",
    "    if type(first) == str:\n",
    "        first = [first]\n",
    "    if type(second) == str:\n",
    "        second = [second]\n",
    "    for i in first:\n",
    "        for j in second:\n",
    "            text = (i + ' ' + j).strip()\n",
    "            temp.append(text)\n",
    "    return temp\n",
    "\n",
    "def cross_product_tuple(first, second):\n",
    "    \"\"\"\n",
    "    Do cross product\n",
    "\n",
    "    parameters\n",
    "    -----------\n",
    "    first: list/string\n",
    "    second: list/string\n",
    "\n",
    "    return: list of tuple\n",
    "    \"\"\"\n",
    "    temp = []\n",
    "    if type(first) == str:\n",
    "        first = [first]\n",
    "    if type(second) == str:\n",
    "        second = [second]\n",
    "    for i in first:\n",
    "        for j in second:\n",
    "            temp.append((i, j))\n",
    "    return temp\n",
    "\n",
    "# Cross product flatten\n",
    "def cross_product_flatten(input_1, input_2):\n",
    "    # Check if input_2 is a list of tuples or a list of lists\n",
    "    if not isinstance(input_2, list) or not all(isinstance(i, (tuple, list)) for i in input_2):\n",
    "        raise ValueError(\"input_2 must be a list of tuples or a list of lists.\")\n",
    "\n",
    "    if type(input_1) == str:\n",
    "        input_1 = [input_1]\n",
    "                \n",
    "    result = []\n",
    "    for name in input_1:\n",
    "        for item in input_2:\n",
    "            result.append((name, *item))\n",
    "    return result\n",
    "\n",
    "def cross_product_flatten_append(input_1, input_2):\n",
    "    # Check if input_2 is a list of tuples or a list of lists\n",
    "    if not isinstance(input_2, list) or not all(isinstance(i, (tuple, list)) for i in input_2):\n",
    "        raise ValueError(\"input_2 must be a list of tuples or a list of lists.\")\n",
    "\n",
    "    if type(input_1) == str:\n",
    "        input_1 = [input_1]\n",
    "                \n",
    "    result = []\n",
    "    for name in input_1:\n",
    "        for item in input_2:\n",
    "            result.append((*item, name))\n",
    "    return result\n",
    "    \n",
    "# Get neglection text\n",
    "def get_neglect(token):\n",
    "    if token:\n",
    "        for t in token.children:\n",
    "            if (t.dep_ == 'neg') or (t.dep_ == 'det' and t.text.lower() == 'no'):\n",
    "                return 'not'\n",
    "    return ''\n",
    "\n",
    "# Get token specific pos tag\n",
    "def get_token_pos(token, pos):\n",
    "    if type(pos) == str:\n",
    "        pos = [pos]\n",
    "    for t in token.children:\n",
    "        if t.pos_ in pos:\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def get_token_pos_left(token, pos):\n",
    "    if type(pos) == str:\n",
    "        pos = [pos]\n",
    "    for t in token.children:\n",
    "        if (t.pos_ in pos) and (t.i < token.i):\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def get_token_pos_right(token, pos):\n",
    "    if type(pos) == str:\n",
    "        pos = [pos]\n",
    "    for t in token.children:\n",
    "        if (t.pos_ in pos) and (t.i > token.i):\n",
    "            return t\n",
    "    return None\n",
    "    \n",
    "# Get token spcific dependency\n",
    "def get_token_dep(token, dep):\n",
    "    if type(dep) == str:\n",
    "        dep = [dep]\n",
    "    for t in token.children:\n",
    "        if t.dep_ in dep:\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def get_token_dep_left(token, dep):\n",
    "    if type(dep) == str:\n",
    "        dep = [dep]\n",
    "    for t in token.children:\n",
    "        if (t.dep_ in dep) and (t.i < token.i):\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def get_token_dep_right(token, dep):\n",
    "    if type(dep) == str:\n",
    "        dep = [dep]\n",
    "    for t in token.children:\n",
    "        if (t.dep_ in dep) and (t.i > token.i):\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def get_all_token_dep(token, dep):\n",
    "    result = []\n",
    "    if type(dep) == str:\n",
    "        dep = [dep]\n",
    "    for t in token.children:\n",
    "        if t.dep_ in dep:\n",
    "            result.append(t)\n",
    "    return result\n",
    "\n",
    "def get_all_token_dep_right(token, dep):\n",
    "    result = []\n",
    "    if type(dep) == str:\n",
    "        dep = [dep]\n",
    "    for t in token.children:\n",
    "        if t.dep_ in dep and t.i > token.i:\n",
    "            result.append(t)\n",
    "    return result\n",
    "\n",
    "def get_all_token_dep_left(token, dep):\n",
    "    result = []\n",
    "    if type(dep) == str:\n",
    "        dep = [dep]\n",
    "    for t in token.children:\n",
    "        if t.dep_ in dep and t.i < token.i:\n",
    "            result.append(t)\n",
    "    return result\n",
    "\n",
    "# Crawling all possibile conjunct\n",
    "def extract_conj(token, neglect=False, lemma=False):\n",
    "    result = []\n",
    "    current = get_token_dep(token, dep='conj')\n",
    "    while current:\n",
    "        if neglect:\n",
    "            neg = get_neglect(current)\n",
    "            # If lemma\n",
    "            if lemma:\n",
    "                text = (neg + ' ' + current.lemma_).strip()\n",
    "            else:\n",
    "                text = (neg + ' ' + current.text).strip()\n",
    "                    \n",
    "            result.append(text)\n",
    "        else:\n",
    "            result.append(current.text)\n",
    "        current = get_token_dep(current, dep='conj')\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_all_token_conj(token):\n",
    "    result = []\n",
    "    current = get_token_dep(token, dep='conj')\n",
    "    while current:\n",
    "        result.append(current)\n",
    "        current = get_token_dep(current, dep='conj')\n",
    "    return result\n",
    "\n",
    "# Get sentences that include coordinating conjunction and its conjunct\n",
    "def get_text_conj(token):\n",
    "    # Get all sentence of series include the conjugation\n",
    "    tokens = [token]\n",
    "    # Get all token\n",
    "    tokens += extract_conj(token, all_token=True)\n",
    "\n",
    "    text = ''\n",
    "    for i, t in enumerate(tokens):\n",
    "        text = text + t.text\n",
    "        if i < len(tokens) - 1:\n",
    "            if t.dep_ == 'cc':\n",
    "                text += ' '\n",
    "            else:\n",
    "                text += ', '\n",
    "\n",
    "    # text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Crawling all possibile pre modifier object\n",
    "def extract_pre_amod(token, lemma=False):\n",
    "    result = []\n",
    "    current_idx = token.i\n",
    "    for child in token.children:\n",
    "        if child.dep_ in ['amod', 'compound'] and child.i < current_idx:\n",
    "            if lemma:\n",
    "                result.append((child.lemma_, child.i))\n",
    "            else:\n",
    "                result.append((child.text, child.i))\n",
    "\n",
    "    # Sort by its index\n",
    "    result = sorted(result, key=lambda x: x[1])\n",
    "\n",
    "    # Return only list of string\n",
    "    result = [item[0] for item in result]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Crawling all possible post modifier object\n",
    "def extract_post_amod(token, lemma=False):\n",
    "    result = []\n",
    "    current_idx = token.i\n",
    "    for child in token.children:\n",
    "        if child.dep_ == 'amod' and child.i > current_idx:\n",
    "            if lemma:\n",
    "                result.append((child.lemma_, child.i))\n",
    "            else:\n",
    "                result.append((child.text, child.i))\n",
    "\n",
    "    # Sort by its index\n",
    "    result = sorted(result, key=lambda x: x[1])\n",
    "\n",
    "    # Return only list of string\n",
    "    result = [item[0] for item in result]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Crawling all possible adverb\n",
    "def extract_adv(token, lemma=True):\n",
    "    conjunctions = [\n",
    "    # Coordinating conjunctions\n",
    "    \"for\", \"and\", \"nor\", \"but\", \"or\", \"yet\", \"so\",\n",
    "    \n",
    "    # Subordinating conjunctions\n",
    "    \"although\", \"because\", \"since\", \"if\", \"when\", \"while\", \"before\", \"after\", \"unless\", \"though\",\n",
    "    \n",
    "    # Correlative conjunctions (listed as single strings)\n",
    "    \"either\", \"neither\", \"both\", \"also\", \"whether\", \"as\",\n",
    "    \n",
    "    # Conjunctive adverbs\n",
    "    \"however\", \"therefore\", \"moreover\", \"consequently\", \"nevertheless\", \"thus\", \"furthermore\"\n",
    "    ]\n",
    "\n",
    "    result_pre = []\n",
    "    result_post = []\n",
    "    current_idx = token.i\n",
    "    for child in token.children:\n",
    "        # If pre-position adverb\n",
    "        if child.pos_ == 'ADV' and child.i < current_idx and child.lemma_.lower() not in conjunctions:\n",
    "            if lemma:\n",
    "                result_pre.append((child.lemma_, child.i))\n",
    "            else:\n",
    "                result_pre.append((child.text, child.i))\n",
    "\n",
    "        # If post-position adverb\n",
    "        if child.pos_ == 'ADV' and child.i > current_idx and child.lemma_.lower() not in conjunctions:\n",
    "            if lemma:\n",
    "                result_post.append((child.lemma_, child.i))\n",
    "            else:\n",
    "                result_post.append((child.text, child.i))\n",
    "\n",
    "    # Sort by its index\n",
    "    result_pre = sorted(result_pre, key=lambda x: x[1])\n",
    "    result_post = sorted(result_post, key=lambda x: x[1])\n",
    "\n",
    "    # Return only list of string\n",
    "    result_pre = [item[0] for item in result_pre]\n",
    "    result_post = [item[0] for item in result_post]\n",
    "\n",
    "    return result_pre, result_post\n",
    "\n",
    "# Crawling preposition phrase after particullar token\n",
    "def crawling_after_token_prep_phrase(token, neglect=False):\n",
    "    result = []\n",
    "    basis_idx = token.i\n",
    "    prep = get_all_token_dep(token, dep='prep')\n",
    "    if prep:\n",
    "        # If contain children: dep pcomp dep VERB pos tag; Until reach dobj or pobj\n",
    "        for p in prep:\n",
    "            prep_idx = p.i\n",
    "            # If the preposition on the left basis token index, continue\n",
    "            if basis_idx > prep_idx:\n",
    "                continue\n",
    "                \n",
    "            current = get_token_dep(p, dep=['pcomp', 'dobj', 'pobj'])\n",
    "            # Store objects\n",
    "            obj = []\n",
    "            # Store complement\n",
    "            comp = [p.text]\n",
    "            while current:\n",
    "                text = current.text\n",
    "                # If current token is object, get the pre-modifier adjective\n",
    "                if current.dep_ in ['dobj', 'pobj']:\n",
    "                    pre_adj = ' '.join(extract_pre_amod(current))\n",
    "                    obj += cross_product_str(pre_adj, text)\n",
    "\n",
    "                    # Extract conjunct object\n",
    "                    obj_conj = extract_conj(current, neglect=neglect)\n",
    "                    if len(obj_conj) > 0:\n",
    "                        obj += obj_conj\n",
    "                else:\n",
    "                    comp = cross_product_str(comp, text)\n",
    "                    \n",
    "                current = get_token_dep(current, dep=['pcomp', 'dobj', 'pobj'])\n",
    "\n",
    "            result += cross_product_str(comp, obj)\n",
    "            \n",
    "    return result\n",
    "\n",
    "def get_sentence_location(mapper, position):\n",
    "    for s in mapper.keys():\n",
    "        interval = mapper[s]\n",
    "        if position >= interval[0] and position < interval[1]:\n",
    "            return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0a6b5412-19a8-4275-86fa-34f09ad41ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coreference Resolution\n",
    "\n",
    "# Generate mapper pronouns-antecedents (subject only)\n",
    "def get_mapper_pron_ant(doc):\n",
    "    \n",
    "    def locate_subject_ant_pron(_doc):\n",
    "        # Locate potential antecedents and pronouns (subject only)\n",
    "    \n",
    "        # Define local variables\n",
    "        antecedents = []\n",
    "        pron = []\n",
    "        prohibit_pronouns = [ 'i', 'you', 'me', 'my', 'mine']\n",
    "    \n",
    "        # Get sentence mapper\n",
    "        sentence_points = {}\n",
    "        for i, s in enumerate(_doc.sents):\n",
    "            sentence_points[i] = (s.start, s.end)\n",
    "        \n",
    "        for token in _doc:\n",
    "            # Condition potential antecedents\n",
    "            # If the token is not pronouns and it's a subject\n",
    "            if (token.pos_ in ['NOUN', 'PROPN']) and (token.dep_ == 'nsubj'):\n",
    "                start = token.i\n",
    "                end = start + 1\n",
    "                location_sentence = get_sentence_location(sentence_points, start)\n",
    "                antecedents.append((token, start, location_sentence))\n",
    "                # Check is there any conj\n",
    "                # antecedents += extract_conj(token, only_token=True)\n",
    "        \n",
    "            # if (token.pos_ != 'PRON') and (token.dep_ == 'dobj' or token.dep_ == 'pobj'):\n",
    "            #     start = token.i\n",
    "            #     end = start + 1\n",
    "            #     location_sentence = get_sentence_location(sentence_points, start)\n",
    "            #     antecedents.append((token, start, location_sentence))\n",
    "            #     # Check is there any conj\n",
    "            #     # antecedents += extract_conj(token, only_token=True)    \n",
    "        \n",
    "            # Condition potential pronouns\n",
    "            # Rule 1\n",
    "            # If pron is subject (it could be same sentence or previously)\n",
    "            if (token.pos_ == 'PRON' and token.text.lower() not in prohibit_pronouns) and (token.dep_ == 'nsubj'):\n",
    "                start = token.i\n",
    "                end = start + 1\n",
    "                location_sentence = get_sentence_location(sentence_points, start)\n",
    "                pron.append((token, start, location_sentence))\n",
    "                \n",
    "            # Rule 2\n",
    "            # If pron is possesion (ant is subject in the same sentence)\n",
    "            if (token.pos_ == 'PRON' and token.text.lower() not in prohibit_pronouns) and (token.dep_ == 'poss'):\n",
    "                start = token.i\n",
    "                end = start + 1\n",
    "                location_sentence = get_sentence_location(sentence_points, start)\n",
    "                pron.append((token, start, location_sentence))\n",
    "        \n",
    "            # Rule 3\n",
    "            # If pron is object\n",
    "            # if (token.pos_ == 'PRON') and (token.dep_ == 'dobj' or token.dep_ == 'pobj'):\n",
    "            #     start = token.i\n",
    "            #     end = start + 1\n",
    "            #     location_sentence = get_sentence_location(sentence_points, start)\n",
    "            #     pron.append((token, start, location_sentence))\n",
    "        \n",
    "        \n",
    "        return (antecedents, pron)\n",
    "\n",
    "    # Filter sentence\n",
    "    def filter_sentence(_list, location):\n",
    "        temp = []\n",
    "        for e in _list:\n",
    "            if e[-1] == location:\n",
    "                temp.append(e)\n",
    "        return temp\n",
    "\n",
    "    # Define local variable\n",
    "    mapper = {}\n",
    "    result = None\n",
    "\n",
    "    antecedents, pronouns = locate_subject_ant_pron(doc)\n",
    "    \n",
    "    if len(pronouns) > 0:\n",
    "        for p in pronouns:\n",
    "            # Current status\n",
    "            is_success = False\n",
    "\n",
    "            # Get current text, index token, and location sentence token\n",
    "            token_pron, index_pron, sent_pron = p\n",
    "            current_sentence = sent_pron\n",
    "            \n",
    "            while current_sentence > -1:\n",
    "                # Get the antecedents\n",
    "                filter_antecedents = filter_sentence(antecedents, current_sentence)\n",
    "\n",
    "                # If the filter antecedents exist\n",
    "                if len(filter_antecedents) > 0:\n",
    "                    for ant in filter_antecedents:\n",
    "                        token_ant, index_ant, sent_ant = ant\n",
    "                        # If antecedent is subject and pronouns is subject or possession and antecedent on the left of pronoun\n",
    "                        if ('subj' in token_ant.dep_) and ('subj' in token_pron.dep_ or 'poss' in token_pron.dep_) and (index_ant < index_pron):\n",
    "                            mapper[index_pron] = index_ant\n",
    "                            is_success = True\n",
    "                            break\n",
    "                        # if ('obj' in token_ant.dep_ and 'obj' in token_pron.dep_) and (index_ant < index_pron):\n",
    "                        #     mapper[index_pron] = index_ant\n",
    "                        #     is_success = True\n",
    "                        #     break\n",
    "                \n",
    "                # If already success, break it.\n",
    "                if is_success:\n",
    "                    break\n",
    "                    \n",
    "                current_sentence -= 1\n",
    "\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ae6cb69b-3794-4586-94af-e7d17835e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main aspect extraction\n",
    "\n",
    "# Extract all raw aspects\n",
    "def get_raw_aspects(doc):\n",
    "    \"\"\"\n",
    "        return: list of tuple, tuple: (aspect, start, end)\n",
    "    \"\"\"\n",
    "    # Define global variables\n",
    "    global bing_liu_opinion_words\n",
    "    \n",
    "    # Define local variables\n",
    "    storage = []\n",
    "\n",
    "    # Define helper function\n",
    "    def is_abnormal_noun(text):\n",
    "        \"\"\"\n",
    "            If text only contains special character/number/both OR total length less than 3 it specified as abnormal.\n",
    "        \"\"\"\n",
    "        if re.match(r'^[0-9\\W]+$', token.text) or len(token.text) < 3:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Going through all token\n",
    "    for idx, token in enumerate(doc):\n",
    "        # Make sure the text is not abnormal\n",
    "        if is_abnormal_noun(token.text):\n",
    "            continue\n",
    "\n",
    "        # If the word is noun and preceded by an adjective\n",
    "        if idx != 0 and (token.pos_ == 'NOUN' and doc[idx - 1].pos_ == 'ADJ'):\n",
    "            # If the adjective is an opinion\n",
    "            if doc[idx - 1].text not in bing_liu_opinion_words:\n",
    "                # Concatenate adj + word then add to storage\n",
    "                text = doc[idx - 1].text + ' ' + token.text\n",
    "                storage.append((text, idx - 1, idx + 1))\n",
    "            else:\n",
    "                # Else, add noun only\n",
    "                text = token.text\n",
    "                storage.append((text, idx, idx + 1))\n",
    "            continue\n",
    "            \n",
    "        # If the word is noun and preceded by another noun\n",
    "        if idx != 0 and (token.pos_ == 'NOUN' and doc[idx - 1].pos_ == 'NOUN'):\n",
    "            text = doc[idx - 1].text + ' ' + token.text\n",
    "            storage.append((text, idx - 1, idx + 1))\n",
    "            continue\n",
    "\n",
    "        # If the word is noun and direct object\n",
    "        if token.pos_ == 'NOUN' and (token.dep_ == 'dobj'):\n",
    "            text = token.text\n",
    "            storage.append((text, idx, idx + 1))\n",
    "            continue\n",
    "    \n",
    "        # If the word is noun and a subject of sentence\n",
    "        if token.pos_ == 'NOUN' and token.dep_ == 'nsubj':\n",
    "            text = token.text\n",
    "            storage.append((text, idx, idx + 1))\n",
    "            continue\n",
    "    \n",
    "        # If the word is noun and a conj of another noun\n",
    "        if (token.pos_ == 'NOUN' and token.dep_ == 'conj') and (token.head.pos_ == 'NOUN'):\n",
    "            text = token.text\n",
    "            storage.append((text, idx, idx + 1))\n",
    "            continue\n",
    "    \n",
    "        # # If the sentence contains SUBJECT VERB, then makes it true\n",
    "        # if token.dep_ == 'nsubj' and token.head.pos_ == 'VERB':\n",
    "        #     is_contain_subject_verb = True\n",
    "    \n",
    "        # # If token is word that contain pre-modifier\n",
    "        # if (token.dep_ == 'amod' and token.head.pos_ == 'NOUN'):\n",
    "        #     if token.head.i != idx + 1:\n",
    "        #         continue\n",
    "        #     text = token.text + ' ' + token.head.text\n",
    "        #     storage.append((text, idx, token.head.i + 1))\n",
    "    \n",
    "        # # If token is word that contain post-modifier\n",
    "        # if (token.dep_ == 'pobj' and token.pos_ == 'NOUN'):\n",
    "        #     if token.head.dep_ == 'prep' and token.head.head.pos_ == 'NOUN':\n",
    "        #         text = token.head.head.text + ' ' + token.head.text + ' ' + token.text\n",
    "        #         start = token.head.head.i\n",
    "        #         storage.append((text, start, idx + 1))\n",
    "            \n",
    "        \n",
    "        # If token is adverb modifier and its head is NOUN then store it.\n",
    "        if (token.dep_ == 'advmod' and token.head.pos_ == 'NOUN'):\n",
    "            text = token.head.text + ' ' + token.text\n",
    "            storage.append((text, token.head.i, idx + 1))\n",
    "            # adv_adj_mod.append((text, idx, idx + 1))\n",
    "\n",
    "    # Sort storage\n",
    "    storage = list(set(storage))\n",
    "    storage = sorted(storage, key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    return storage\n",
    "\n",
    "# Prunning raw aspect\n",
    "def prunning_aspect(list_, doc):\n",
    "    # Define local variables\n",
    "    drop_idx = []\n",
    "    storage = {}\n",
    "    \n",
    "    # Get sentence mapper\n",
    "    sentence_points = {}\n",
    "    for i, s in enumerate(doc.sents):\n",
    "        sentence_points[i] = (s.start, s.end)\n",
    "\n",
    "    for idx, item in enumerate(list_):\n",
    "        # As long as current idx does not more than maximum list_ index\n",
    "        if idx != len(list_) - 1:\n",
    "            # Get the next item\n",
    "            next_item = list_[idx + 1]\n",
    "            # If current item start position and next item end position are overlapping\n",
    "            if item[-1] - 1 == next_item[1]:\n",
    "                # We merge the text based on last text in current item and first text in next item\n",
    "                append_text = ' '.join(next_item[0].split()[1:])\n",
    "                # Update next item values\n",
    "                new_text = item[0] + ' ' + append_text\n",
    "                new_start = item[1]\n",
    "                new_end = next_item[-1]\n",
    "                list_[idx + 1] = (new_text, new_start, new_end)\n",
    "\n",
    "                # Add current index into dropped index list\n",
    "                drop_idx.append(idx)\n",
    "            \n",
    "            # If current item start position = next item end position (They are next to each other)\n",
    "            if item[-1] == next_item[1]:\n",
    "                # Update the next value (do not have to merge the text based on specific text).\n",
    "                new_text = item[0] + ' ' + next_item[0]\n",
    "                new_start = item[1]\n",
    "                new_end = next_item[-1]\n",
    "                list_[idx + 1] = (new_text, new_start, new_end)\n",
    "\n",
    "                # Add current index into dropped index list\n",
    "                drop_idx.append(idx)\n",
    "                \n",
    "    list_ = [list_[i] for i in range(len(list_)) if i not in drop_idx]\n",
    "\n",
    "    # Create return as aspect-list of sentence mapper\n",
    "    for i, s in enumerate(list_):\n",
    "        aspect, start, end = s\n",
    "        sentence_location = get_sentence_location(sentence_points, start)\n",
    "        sentence = list(doc.sents)[sentence_location].text\n",
    "        # Update value and store text as lowercase\n",
    "        # storage[sentence_location].append(aspect.lower())\n",
    "        if not storage.get(aspect.lower()):\n",
    "            storage[aspect.lower()] = [sentence]\n",
    "        else:\n",
    "            storage[aspect.lower()].append(sentence)\n",
    "    return storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9b695-0a2c-4dbd-a017-dc774b9eba6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fd811-0755-4a9b-9652-3dfe85fba8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2f42562f-6132-4aaf-878f-42847795364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Subject active rules (Conjunct Handling)\n",
    "\n",
    "\n",
    "##==================== CONJUNCT HANDLING ==============================##\n",
    "\n",
    "def ability_obj_conjunct(obj, base, set_rep=False):\n",
    "    #====== Conjunct Object =======#\n",
    "    result = []\n",
    "    reps =  [] # Representative conjunct storage\n",
    "    neg = ' '\n",
    "    conjuncts = get_all_token_conj(obj)\n",
    "    if len(conjuncts) > 0:\n",
    "        for conjunct in conjuncts:\n",
    "            # Get neglection object\n",
    "            pre_amod_token = get_token_dep_left(conjunct, dep='amod')\n",
    "            # If the neglection does not appear at front of object, it may refers to the most left pre modifier\n",
    "            neg = get_neglect(conjunct) or get_neglect(pre_amod_token)\n",
    "            # Get pre adjectvie modifier of conjunct\n",
    "            pre_adj = ' '.join(extract_pre_amod(conjunct))\n",
    "                \n",
    "            # Concatenate components (compliment) into: aux (optional) + not (optional) + adv (optional) \n",
    "            #                                             + verb + aux-comp (optional) + compliment + not (optional)\n",
    "            # Concatenate components into: aux (optional) + not (optional) + adv (optional) + verb + not (optional)\n",
    "            # Concatenate components into: base + not (optional)\n",
    "            ability = cross_product_str(base, neg)\n",
    "            # Concatenate components (compliment) into: aux (optional) + not (optional) + adv (optional) \n",
    "            #                                             + verb + aux-comp (optional) + compliment + not (optional) + adj (optional)\n",
    "            # Concatenate components into: aux (optional) + not (optional) + adv (optional) + verb + not (optional) + adj (optional)\n",
    "            # Concatenate components into: base + not (optional) + adj (optional)\n",
    "            ability = cross_product_str(ability, pre_adj)\n",
    "            # Concatenate components (compliment) into: aux (optional) + not (optional) + adv (optional) \n",
    "            #                                             + verb + aux-comp (optional) + compliment + not (optional) + adj (optional) + Conjunct object\n",
    "            # Concatenate components into: aux (optional) + not (optional) + adv (optional) + verb + not (optional) + adj (optional) + Conjunct object\n",
    "            # Concatenate components into: base + not (optional) + adj (optional) + Conjunct object\n",
    "            ability = cross_product_str(ability, conjunct.text)\n",
    "        \n",
    "            # Add the ability into abilities\n",
    "            # IF with representative\n",
    "            if set_rep:\n",
    "                result += cross_product_tuple(ability, [(conjunct.lemma_,)])\n",
    "            else:\n",
    "                result += ability\n",
    "            # EXPECTED PATTERN: aux (optional) + not (optional) + adv (optional) + verb + adj (optional) + Conjunct object\n",
    "            # EXPECTED PATTERN (compliment) : aux (optional) + not (optional) + adv (optional) + verb + aux-comp (optional) + compliment \n",
    "            #                                   + adj (optional) + Conjunct object\n",
    "            # Note: Since normaly, If direct object is noun/propn/pron the conjuncts are noun/propn/pron too.\n",
    "            #        This rule follow this concept. In somehow, the conjunct could be adjective or another verb.\n",
    "    return result\n",
    "\n",
    "def ability_adj_conjunct(adj, base, set_rep=False):\n",
    "    #====== Conjunct Adjective =======#\n",
    "    result = []\n",
    "    conjuncts = get_all_token_conj(adj)\n",
    "    if len(conjuncts) > 0:\n",
    "        for conjunct in conjuncts:\n",
    "            # Get neglection adjective\n",
    "            neg = get_neglect(conjunct)\n",
    "    \n",
    "            # Concatenate components into: aux (optional) + not (optional) + adj\n",
    "            ability = cross_product_str(base, conjunct.text)\n",
    "    \n",
    "            # IF with representative\n",
    "            if set_rep:\n",
    "                result += cross_product_tuple(ability, [(conjunct.lemma_,)])\n",
    "            else:\n",
    "                result += ability\n",
    "    return result\n",
    "\n",
    "\n",
    "def ability_adv_conjunct(advmod, base, set_rep=False):\n",
    "    result = []\n",
    "    conjuncts = get_all_token_conj(advmod)\n",
    "    \n",
    "    if len(conjuncts) > 0:\n",
    "        for conjunct in conjuncts:\n",
    "            # Get pre adverb modifier\n",
    "            pre_adv = get_token_dep_left(conjunct, dep=['advmod', 'npadvmod'])\n",
    "            if pre_adv:\n",
    "                # Get pre and post adverb after pre adverb main verb\n",
    "                pre_advmod_temp, _ = extract_adv(pre_adv)\n",
    "                pre_advmod_temp = ' '.join(pre_advmod_temp)\n",
    "            \n",
    "                pre_adv = [pre_advmod_temp, pre_adv.text]\n",
    "                pre_adv = (' '.join(pre_adv)).strip()\n",
    "            else:\n",
    "                pre_adv = ' '\n",
    "                \n",
    "            # Get neglection adjective\n",
    "            neg = get_neglect(conjunct)\n",
    "            # Concatenate components into: base + not (optional)\n",
    "            ability = cross_product_str(base, neg)\n",
    "            # Concatenate components into: base + not (optional) + pre-adv (optional)\n",
    "            ability = cross_product_str(ability, pre_adv)\n",
    "            # Concatenate components into: base + not (optional) + pre-adv (optional) + adv\n",
    "            ability = cross_product_str(ability, conjunct.text)\n",
    "    \n",
    "            # IF with representative\n",
    "            if set_rep:\n",
    "                result += cross_product_tuple(ability, [(conjunct.lemma_,)])\n",
    "            else:\n",
    "                result += ability\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "05e7c81f-9263-43f8-a3d9-7e97cd508914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: subject active rules (Head is verb) components\n",
    "\n",
    "def get_components_verb(verb):\n",
    "    # Get main components after verb that generate sentences.\n",
    "    \n",
    "    # Get direct object verb token\n",
    "    obj = get_token_dep(verb, dep='dobj')\n",
    "    # Get post-modifier adverb token\n",
    "    advmod = get_token_dep_right(verb, dep=['advmod', 'npadvmod'])\n",
    "    # Get preposition after verb token\n",
    "    prep = get_token_dep(verb, dep='prep')\n",
    "    # Get adjectival compliment\n",
    "    acomp = get_token_dep(verb, dep='acomp')\n",
    "    \n",
    "    return {'obj': obj, 'advmod': advmod, 'prep': prep, 'acomp': acomp}\n",
    "\n",
    "def base_sentence(main_aux, main_verb, neg):\n",
    "    \n",
    "    if (main_verb) or (main_aux):\n",
    "        # Concatenate components into: not (optional)\n",
    "        ability = cross_product_str(neg, ' ')\n",
    "        if main_verb:\n",
    "            # Get pre advmod if exist\n",
    "            pre_adv = get_token_dep_left(main_verb, dep=['advmod', 'npadvmod'])\n",
    "            if pre_adv:\n",
    "                # Get pre and post adverb after pre adverb main verb\n",
    "                pre_advmod_temp, post_advmod_temp = extract_adv(pre_adv)\n",
    "                pre_advmod_temp = ' '.join(pre_advmod_temp)\n",
    "                post_advmod_temp = ' '.join(post_advmod_temp)\n",
    "                        \n",
    "                pre_adv = [pre_advmod_temp, pre_adv.text, post_advmod_temp]\n",
    "                pre_adv = (' '.join(pre_adv)).strip()\n",
    "            else:\n",
    "                pre_adv = ' '\n",
    "                \n",
    "            # Concatenate components into: not (optional) + adv (optional)\n",
    "            ability = cross_product_str(ability, pre_adv)\n",
    "            # Concatenate components into: not (optional) + adv (optional) + verb\n",
    "            ability = cross_product_str(ability, main_verb.text)\n",
    "        # If auxiliary token exist\n",
    "        if main_aux:\n",
    "            # Concatenate components into: aux (optional) + not (optional) + adv (optional) + verb\n",
    "            ability = cross_product_str(main_aux.text, ability)\n",
    "        return ability\n",
    "    return [' ']\n",
    "\n",
    "\n",
    "def ability_advmod(advmod, base):\n",
    "    result = []\n",
    "\n",
    "    pre_adv = get_token_dep_left(advmod, dep=['advmod', 'npadvmod'])\n",
    "    if pre_adv:\n",
    "        # Get pre and post adverb after pre adverb main verb\n",
    "        pre_advmod_temp, _ = extract_adv(pre_adv)\n",
    "        pre_advmod_temp = ' '.join(pre_advmod_temp)\n",
    "    \n",
    "        pre_adv = [pre_advmod_temp, pre_adv.text]\n",
    "        pre_adv = (' '.join(pre_adv)).strip()\n",
    "    else:\n",
    "        pre_adv = ' '\n",
    "    \n",
    "    # Concatenate components: pre-adv (optional) + adv\n",
    "    ability = cross_product_str(pre_adv, advmod.text)\n",
    "        \n",
    "    # Concatenate components into (if custom base exist): base + pre-adv (optional) + adv\n",
    "    ability = cross_product_str(base, ability)\n",
    "    \n",
    "    # Get preposition after adverb\n",
    "    prep_after_advmod = crawling_after_token_prep_phrase(advmod)\n",
    "    # If preposition after adverb exist\n",
    "    if prep_after_advmod:\n",
    "        # Concatenate components into (if custom base exist): base + pre-adv (optional) + adv + preposition phrase (optional)\n",
    "        ability = cross_product_str(ability, prep_after_advmod)\n",
    "\n",
    "    result += ability\n",
    "    \n",
    "    # Conjunct adverb handling\n",
    "    result += ability_adv_conjunct(advmod, base, set_rep=False)\n",
    "    \n",
    "    # EXPECTED PATTERN (if custom base exist): base + pre-adv (optional) + adv + preposition phrase (optional)\n",
    "    return result\n",
    "\n",
    "def ability_dobj(obj, base):\n",
    "    result = []\n",
    "\n",
    "    # Get neglection direct object\n",
    "    pre_amod_token = get_token_dep_left(obj, dep='amod')\n",
    "    # If the neglection does not appear at front of object, it may refers to the most left pre modifier\n",
    "    neg = get_neglect(obj) or get_neglect(pre_amod_token)\n",
    "    \n",
    "    # Get pre adjectvie modifier of object\n",
    "    pre_adj = ' '.join(extract_pre_amod(obj))\n",
    "    \n",
    "    # Concatenate components: adj (optional) + Direct object\n",
    "    ability = cross_product_str(pre_adj, obj.text)\n",
    "\n",
    "    # Concatenate components: not (optional) + adj (optional) + Direct object\n",
    "    ability = cross_product_str(neg, ability)\n",
    "\n",
    "    # Concatenate components into: base + not (optional) + adj (optional) + Direct object\n",
    "    ability = cross_product_str(base, ability)\n",
    "\n",
    "    # GET PREPOSITION AFTER OBJ and ADNOMINAL CLAUSE\n",
    "    prep = get_token_dep(obj, dep='prep')\n",
    "    acl = get_token_dep(obj, dep='acl')\n",
    "    if (prep) or (acl):\n",
    "        if prep:\n",
    "            # Get phrase: preposition + preposition-compliment (optional) + pre-adj (optional) + object\n",
    "\n",
    "            phrase = ability_prep(prep)        \n",
    "            # EXPECTED PATTERN (compliment): base + not (optional) + adj (optional) + Direct object + preposition + preposition-compliment (optional) \n",
    "            #                                  not (optional) + pre-adj (optional) + object\n",
    "            result += cross_product_str(ability, phrase)\n",
    "        if acl:\n",
    "            # Get aux acl\n",
    "            aux_acl = get_token_dep(acl, dep='aux')\n",
    "            # Neglection acl\n",
    "            neg = get_neglect(acl)\n",
    "            # Define base Adnominal Clause\n",
    "            # Concatenate components into (if custom base exist): base + not (optional) + adj (optional) + Direct object + not (optional)\n",
    "            temp = cross_product_str(ability, neg)\n",
    "            if aux_acl:\n",
    "                # Concatenate components into (if custom base exist): base + not (optional) + adj (optional) + Direct object + not (optional) + aux-acl\n",
    "                temp = cross_product_str(temp, aux_acl.text)\n",
    "                \n",
    "            # Concatenate components into (if custom base exist): base + not (optional) + adj (optional) + Direct object + not (optional) + aux-acl\n",
    "            #                                                       + acl\n",
    "            temp = cross_product_str(temp, acl.text)\n",
    "            # EXPECTED PATTERN: base + not (optional) + adj (optional) + Direct object + not (optional) + aux-acl + acl + all possible option\n",
    "            result += ability_adnominal_clause(acl=acl, base=temp)\n",
    "    else:\n",
    "        # EXPECTED PATTERN: aux (optional) + not (optional) + adv (optional) + verb + adj (optional) + not (optional) + Direct object\n",
    "        # EXPECTED PATTERN (compliment): aux (optional) + not (optional) + adv (optional) + verb + aux-comp (optional)\n",
    "        #                                  + compliment + adj (optional) + not (optional) + Direct object\n",
    "        result += ability\n",
    "    \n",
    "    # Conjunct object handling\n",
    "    result += ability_obj_conjunct(obj, base=base)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def ability_prep(prep, base=None):\n",
    "    # Get object of preposition\n",
    "    obj = get_token_dep_right(prep, dep=['dobj', 'pobj'])\n",
    "    pcomp = None\n",
    "    # If object does not exist\n",
    "    if not obj:\n",
    "        # Get the preposition complement\n",
    "        pcomp = get_token_dep_right(prep, dep='pcomp')\n",
    "        if pcomp:\n",
    "            # Get the object that refers to preposition complement\n",
    "            obj = get_token_dep_right(pcomp, dep=['dobj', 'pobj'])\n",
    "    \n",
    "    # Concatenate components: preposition\n",
    "    ability = cross_product_str(prep.text, ' ')\n",
    "    if (pcomp) or (obj):\n",
    "        # If preposition compliment exist\n",
    "        if pcomp:\n",
    "            # Concatenate components: preposition + preposition-compliment (optional)\n",
    "            ability = cross_product_str(ability, pcomp.text)\n",
    "        # If object exist\n",
    "        if obj:\n",
    "            # Get neglection object\n",
    "            pre_amod_token = get_token_dep_left(obj, dep='amod')\n",
    "            # If the neglection does not appear at front of object, it may refers to the most left pre modifier\n",
    "            neg = get_neglect(obj) or get_neglect(pre_amod_token)\n",
    "            # Temporary storage\n",
    "            temp = []\n",
    "            # Get pre adjective modifier object\n",
    "            pre_adj = ' '.join(extract_pre_amod(obj))\n",
    "            # Concatenate components: preposition + preposition-compliment (optional) + not (optional)\n",
    "            temporary = cross_product_str(ability, neg)\n",
    "            # Concatenate components: preposition + preposition-compliment (optional) + not (optional) + pre-adj (optional)\n",
    "            temporary = cross_product_str(temporary, pre_adj)\n",
    "            # Concatenate components: preposition + preposition-compliment (optional) + not (optional) + pre-adj (optional) + object\n",
    "            temp += cross_product_str(temporary, obj.text)\n",
    "            \n",
    "            # Conjunct object handling\n",
    "            temp += ability_obj_conjunct(obj, base=ability)\n",
    "            \n",
    "            ability = temp\n",
    "\n",
    "        # If base is None, return phrase only\n",
    "        if not base:\n",
    "            # EXPECTED PATTERN: preposition + preposition-compliment (optional) + pre-adj (optional) + object\n",
    "            return ability\n",
    "        else:\n",
    "            # EXPECTED PATTERN: base + preposition + preposition-compliment (optional) + pre-adj (optional) + object\n",
    "            ability = cross_product_str(base, ability)\n",
    "            return ability\n",
    "            \n",
    "    return []\n",
    "\n",
    "\n",
    "def ability_acomp(acomp, base):\n",
    "    # Get neglection \n",
    "    neg = get_neglect(acomp)\n",
    "    # if not base:\n",
    "    #     if comp:\n",
    "    #         # Get base sentence: aux (optional) + not (optional) + adv (optional) + verb + aux-comp (optional) + compliment\n",
    "    #         base = base_sentence_comp(comp, **kwargs)  \n",
    "    #     else:\n",
    "    #         # Get base sentence: aux (optional) + not (optional) + adv (optional) + verb\n",
    "    #         base = base_sentence(main_aux=kwargs.get('main_aux'),\n",
    "    #                                 main_verb=kwargs.get('main_verb'),\n",
    "    #                                 neg=kwargs.get('neg'))\n",
    "\n",
    "    # Concatenate components into: not (optional) + acomp\n",
    "    ability = cross_product_str(neg, acomp.text)\n",
    "    # Concatenate components into: aux (optional) + not (optional) + adv (optional) + verb + not (optional) + acomp\n",
    "    # Concatenate components into (compliment): aux (optional) + not (optional) + adv (optional) + verb + aux-comp (optional) \n",
    "    #                                             + compliment + not (optional) + acomp\n",
    "    # Concatenate components into (if custom base exist): base + not (optional) + acomp\n",
    "    ability = cross_product_str(base, ability)                    \n",
    "    # EXPECTED PATTERN: aux (optional) + not (optional) + adv (optional) + verb + adv + preposition phrase (optional)\n",
    "    # EXPECTED PATTERN (compliment): aux (optional) + not (optional) + adv (optional) + verb + aux-comp (optional)\n",
    "    #                                             + compliment + adv + preposition phrase (optional)\n",
    "    # EXPECTED PATTERN (if custom base exist): base + adv + preposition phrase (optional)\n",
    "    return ability\n",
    "\n",
    "\n",
    "def ability_adnominal_clause(acl, base):\n",
    "    # Define local variable\n",
    "    result = []\n",
    "    \n",
    "    # Get intransitive rate score\n",
    "    int_rate_acl = map_verb_intrans.get(acl.text) or map_verb_intrans.get(acl.lemma_)\n",
    "    # If the verb is not in the mapper ( we assume it is transitive verb )\n",
    "    if not int_rate_acl:\n",
    "        int_rate_acl = 0\n",
    "\n",
    "    \n",
    "    temp = ability_relative_verb(acl, base=base)\n",
    "    if len(temp) > 0:\n",
    "        # result += cross_product_tuple(temp, [tuple(reps)])\n",
    "        result += temp\n",
    "    else:\n",
    "        # If do not contain any of that, but intransitive verb ==> Subject + aux (optional) + not (optional) + adv (optional) + verb\n",
    "        if int_rate_acl > 0.5 and comp.lemma_.lower() not in ['be', 'do', 'have']:\n",
    "            ability = cross_product_str(base, aux_acl.text)\n",
    "            ability = cross_product_str(ability, acl.text)\n",
    "            # EXPECTED PATTERN: aux (optional) + not (optional) + adv (optional) + verb\n",
    "            result += ability\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9be3ac54-76a5-43b9-8c73-bea173f42a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Case Head is verb\n",
    "\n",
    "def ability_relative_verb(verb, base):\n",
    "    # Get ability that relative to particlar verb\n",
    "    result = []\n",
    "    comp = None\n",
    "\n",
    "        \n",
    "    # Extract all token\n",
    "    obj, advmod, prep, acomp = get_components_verb(verb).values()\n",
    "    if (advmod) or (prep) or (obj) or (acomp):\n",
    "        # If adverb after verb exist\n",
    "        if advmod:\n",
    "            ability = ability_advmod(advmod, base=base)\n",
    "            # EXPECTED PATTERN: Subject + aux (optional) + not (optional) + adv (optional) + verb + adv + prepositional phrase (optional)\n",
    "            result += ability\n",
    "    \n",
    "        # If prep after verb\n",
    "        if prep:\n",
    "            ability = ability_prep(prep, base=base)\n",
    "            # EXPECTED PATTERN: Subject + aux (optional) + not (optional) + adv (optional) + verb + preposition phrase\n",
    "            result += ability\n",
    "    \n",
    "        # If direct object exist\n",
    "        if obj:\n",
    "            ability = ability_dobj(obj, base=base)\n",
    "            result += ability\n",
    "    \n",
    "        # If adjective compliment exist\n",
    "        if acomp:\n",
    "            ability = ability_acomp(acomp, base=base)\n",
    "            result += ability\n",
    "    \n",
    "    return result\n",
    "\n",
    "def ability_verb(main_verb):\n",
    "    result = []\n",
    "    reps = [main_verb.lemma_] # Representative ability.\n",
    "    ###============ DEFINE VARIABLES ================###\n",
    "    # Get main auxiliary\n",
    "    aux = get_token_dep(main_verb, dep='aux')\n",
    "    # Get neglect; If there is no neglect, return empty text.\n",
    "    neg = get_neglect(main_verb)\n",
    "    # Get intransitive rate score\n",
    "    int_rate = map_verb_intrans.get(main_verb.text) or map_verb_intrans.get(main_verb.lemma_)\n",
    "    # If the verb is not in the mapper ( we assume it is transitive verb )\n",
    "    if not int_rate:\n",
    "        int_rate = 0\n",
    "\n",
    "    #==================== COMPLIMENT ========================#\n",
    "    # Get compliment verb\n",
    "    comp = get_token_dep(main_verb, dep=['xcomp', 'ccomp'])\n",
    "    if comp and (comp.pos_ not in ['VERB', 'AUX'] or get_token_dep(comp, dep='auxpass')):\n",
    "        comp = None\n",
    "        \n",
    "    # NOTE: a single verb to directly have both a ccomp and an xcomp dependency simultaneously \n",
    "    #         is rare and typically wouldn't occur. If a verb does have two clausal complements, \n",
    "    #         each clause would serve a different function or role in the sentence.\n",
    "    int_rate_comp = map_verb_intrans.get(main_verb.text) or map_verb_intrans.get(main_verb.lemma_)\n",
    "    if not int_rate_comp:\n",
    "        int_rate_comp = 0\n",
    "        \n",
    "    ###===================== CONDITION =====================###\n",
    "    components = {'main_aux': aux, 'main_verb': main_verb, 'neg': neg, }\n",
    "    base = base_sentence(**components)\n",
    "    \n",
    "    temp = ability_relative_verb(main_verb, base=base)\n",
    "    result += cross_product_tuple(temp, [tuple(reps)])\n",
    "    # result += ability_relative_verb(main_verb, **components)\n",
    "    if comp:\n",
    "        # Add compliment verb as representative\n",
    "        reps.append(comp.lemma_)\n",
    "        # Add auxiliary compliment into components\n",
    "        aux_comp = get_token_dep(comp, dep='aux')\n",
    "        # Update base\n",
    "        if aux_comp:\n",
    "            base = cross_product_str(base, aux_comp.text)\n",
    "        base = cross_product_str(base, comp.text)\n",
    "            \n",
    "        temp = ability_relative_verb(comp, base=base)\n",
    "        # temp = ability_relative_verb(comp, base=base, is_comp=True, **components)\n",
    "        if len(temp) > 0:\n",
    "            result += cross_product_tuple(temp, [tuple(reps)])\n",
    "        else:\n",
    "            # If do not contain any of that, but intransitive verb ==> Subject + aux (optional) + not (optional) + adv (optional) + verb\n",
    "            if int_rate_comp > 0.5 and comp.lemma_.lower() not in ['be', 'do', 'have']:\n",
    "                # EXPECTED PATTERN: aux (optional) + not (optional) + adv (optional) + verb\n",
    "                result += cross_product_tuple(base, [tuple(reps)])       \n",
    "\n",
    "    if len(result) == 0:\n",
    "        # If do not contain any of that, but intransitive verb ==> Subject + aux (optional) + not (optional) + adv (optional) + verb\n",
    "        if int_rate > 0.5 and main_verb.lemma_.lower() not in ['be', 'do', 'have']:\n",
    "            ability = base_sentence(**components)\n",
    "            # EXPECTED PATTERN: aux (optional) + not (optional) + adv (optional) + verb\n",
    "            result += cross_product_tuple(ability, [tuple(reps)])\n",
    "\n",
    "    # Labeling VERB\n",
    "    result = cross_product_flatten_append('VERB', result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e3c891e8-53a4-40d2-a281-518ba9329622",
   "metadata": {},
   "outputs": [],
   "source": [
    "###============ AUXILIARY ================###\n",
    "\n",
    "def ability_aux(aux):\n",
    "    # Define local variables\n",
    "    result = []\n",
    "    # Get neglect of auxiliary\n",
    "    neg = get_neglect(aux)\n",
    "    components = {'main_aux': aux, 'neg': neg, 'main_verb': None}\n",
    "    base = base_sentence(**components)\n",
    "    \n",
    "    # Get the component tokens\n",
    "    \n",
    "    # Get adjective token\n",
    "    # NOTE: if 'AUX' is root, only have one adjective with dependency acomp.\n",
    "    adj = get_token_dep(aux, dep='acomp')\n",
    "    \n",
    "    # Get noun token\n",
    "    noun = get_token_pos_right(aux, pos=['NOUN', 'PROPN'])\n",
    "    if noun and noun.dep_ in ['nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "        noun = None\n",
    "        \n",
    "    # Get prepositinal token\n",
    "    prep = get_token_dep(aux, dep='prep')\n",
    "\n",
    "    ### CONDITIONAL TOKEN ###\n",
    "    if adj:\n",
    "        temp = ability_aux_adj(adj, base=base)\n",
    "        ability = cross_product_flatten_append('ADJ', temp)\n",
    "        # EXPECTED PATTERN: Subject + aux + not (optional) + adj\n",
    "        result += ability\n",
    "\n",
    "    if noun:\n",
    "        temp = ability_aux_noun(noun, base=base)\n",
    "        ability = cross_product_flatten_append('OTHER', temp)\n",
    "        # EXPECTED PATTERN: Subject + aux + not (optional) + pre-modifier adjective (optional) + noun\n",
    "        result += ability\n",
    "\n",
    "    if prep:\n",
    "        temp = ability_aux_prep(prep, base=base)\n",
    "        ability = cross_product_flatten_append('OTHER', temp)\n",
    "        # EXPECTED PATTERN: Subject + aux + not (optional) + phrase\n",
    "        result += ability\n",
    "\n",
    "    return result\n",
    "\n",
    "def ability_aux_adj(adj, base):\n",
    "    result = []\n",
    "    reps = [adj.lemma_] # Representative ability.\n",
    "\n",
    "    # GET PREPOSITION AFTER ADJ\n",
    "    prep = get_token_dep(adj, dep='prep')\n",
    "    # Concatenate components into: base + adj\n",
    "    ability = cross_product_str(base, adj.text)\n",
    "    if prep:\n",
    "        phrase = ability_prep(prep)\n",
    "        # Concatenate components into: base + adj + preposition phrase (optional)\n",
    "        ability = cross_product_str(ability, phrase)\n",
    "        \n",
    "    # Concatenate components into: base + adj + preposition phrase (optional)\n",
    "    result += cross_product_tuple(ability, [tuple(reps)])\n",
    "\n",
    "    # GET CONJUNCT\n",
    "    temp = ability_adj_conjunct(adj, base=base, set_rep=True)\n",
    "    if len(temp) > 0:\n",
    "        result += temp\n",
    "    return result\n",
    "\n",
    "def ability_aux_noun(noun, base):\n",
    "    result = []\n",
    "    reps = [noun.lemma_] # Representative ability\n",
    "    \n",
    "    \n",
    "    # Get pre-modifier adjective of noun\n",
    "    pre_adj = ' '.join(extract_pre_amod(noun))\n",
    "    # Concatenate components into: base + pre-modifier adjective (optional)\n",
    "    ability = cross_product_str(base, pre_adj)\n",
    "    # Concatenate components into: base + pre-modifier adjective (optional) + noun\n",
    "    ability = cross_product_str(base, noun.text)\n",
    "\n",
    "    result += cross_product_tuple(ability, [tuple(reps)])\n",
    "    return result\n",
    "\n",
    "def ability_aux_prep(prep, base):\n",
    "    result = []\n",
    "    \n",
    "    # Get preposition phrase\n",
    "    phrase = ability_prep(prep)\n",
    "    \n",
    "    # Conncatenate components into: base + Prepositional phrase\n",
    "    ability = cross_product_str(base, phrase)\n",
    "    # NOTE: It included preposition object conjuncts.\n",
    "\n",
    "    # Extract representative word\n",
    "    for a in ability:\n",
    "        temp = a.split()\n",
    "        temp = cross_product_tuple(a, [(temp[-1],)])\n",
    "        result += temp\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e5ea923f-20e3-4128-82f1-2fa3eff66f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ability_pass_agent(agent, base):\n",
    "    result = []\n",
    "    # Get object agent\n",
    "    obj_agent = get_token_dep(agent, dep=['pobj', 'dobj'])\n",
    "\n",
    "    if obj_agent:   \n",
    "        # Update Base\n",
    "        # Concatenate components: aux (optional) + neg (optional) + auxpass + verb + agent\n",
    "        base = cross_product_str(base, agent.text)\n",
    "\n",
    "        # Get neglection object\n",
    "        pre_amod_token = get_token_dep_left(obj_agent, dep='amod')\n",
    "        # If the neglection does not appear at front of object, it may refers to the most left pre modifier\n",
    "        neg = get_neglect(obj_agent) or get_neglect(pre_amod_token)\n",
    "        # Get pre adjectvie modifier of conjunct\n",
    "        pre_adj = ' '.join(extract_pre_amod(obj_agent))\n",
    "\n",
    "        # Concatenate components: aux (optional) + neg (optional) + auxpass + verb + agent + adj (optional)\n",
    "        ability = cross_product_str(base, pre_adj)\n",
    "        # Concatenate components: aux (optional) + neg (optional) + auxpass + verb + agent + adj (optional) + object\n",
    "        ability = cross_product_str(base, obj_agent.text)\n",
    "        # EXPECTED PATTERN: aux (optional) + neg (optional) + auxpass + verb + agent + adj (optional) + object\n",
    "        result += ability\n",
    "\n",
    "        # Handling object conjuncts\n",
    "        result += ability_obj_conjunct(obj_agent, base=base, set_rep=False)\n",
    "        \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4731a9da-4f41-4c16-a4fb-13221e843618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Helper subject active rules\n",
    "\n",
    "def is_contain_question(token):\n",
    "    questions = ['what', 'who', 'why', 'whom', 'when', 'which', 'where', 'whose', 'how']\n",
    "    tokens = get_all_token_dep(token, dep=['advmod', 'attr'])\n",
    "    for t in tokens:\n",
    "        if t.text.lower() in questions:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_perfect_sentence(sent):\n",
    "    for token in sent:\n",
    "        if token.dep_ in ['nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def imperfect_sentence_rules(token):\n",
    "    properties = []\n",
    "    result = []\n",
    "    if token.head.text == token.text:\n",
    "        # Get compound or amod\n",
    "        properties = get_all_token_dep_left(token, dep=['compound', 'amod'])\n",
    "    \n",
    "    if len(properties) > 0:\n",
    "        for p in properties:\n",
    "            temp = cross_product_str('be', p.text.lower())\n",
    "            if p.pos_ == 'ADJ':\n",
    "                label = 'ADJ'\n",
    "            else:\n",
    "                label = 'OTHER'\n",
    "            temp = cross_product_tuple(temp, [(p.lemma_,)])\n",
    "            result += cross_product_flatten_append(label, temp)\n",
    "            # result += cross_product_tuple(temp, [(p.lemma_,)])\n",
    "        # properties = cross_product_tuple(temp, [tuple(properties)])\n",
    "        return result\n",
    "        \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6b09456f-f615-44f8-bea0-505fe07d7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_active_rules(token, subject):\n",
    "    abilities = []\n",
    "    # Go to its head\n",
    "    head = token.head\n",
    "\n",
    "    # If head is Verb and it is root\n",
    "    # if (head.pos_ == 'VERB') and ((head.head.text == head.text) or head.dep_ == 'conj'):\n",
    "    if (head.pos_ == 'VERB'):\n",
    "        any_question = is_contain_question(head)\n",
    "        if any_question:\n",
    "            return abilities\n",
    "        \n",
    "        elif (head.head.text == head.text):\n",
    "            verb_conjunct = [head]\n",
    "    \n",
    "            verb_conjunct += get_all_token_conj(head)\n",
    "            ###============ GET ALL TOKENS ================###\n",
    "            for verb in verb_conjunct:\n",
    "                compare = get_token_dep(verb, dep=['nsubj', 'nsubjpass'])\n",
    "                if not compare or (compare.text == subject.text):\n",
    "                    abilities += ability_verb(verb)\n",
    "\n",
    "        elif (head.pos_ == 'VERB') and (head.dep_ in ['conj', 'advcl']):\n",
    "            compare = get_token_dep(head, dep=['nsubj'])\n",
    "            if compare and (subject.text == compare.text):\n",
    "                verb_conjunct = [head]\n",
    "                if head.dep_ == 'advcl':\n",
    "                    verb_conjunct += get_all_token_conj(head)\n",
    "                for verb in verb_conjunct:\n",
    "                    abilities += ability_verb(verb)\n",
    "        \n",
    "    # If head is aux\n",
    "    elif head.pos_ == 'AUX':\n",
    "        abilities += ability_aux(head)           \n",
    "    return abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db8d92-2fb6-4b4e-b6b7-ddcd95358cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "81ca2f51-4475-42ca-a153-9671f52eff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_sentence_passive(main_auxpass, main_verb, main_aux, neg):\n",
    "    # Get pre advmod if exist\n",
    "    pre_adv = get_token_dep_left(main_verb, dep=['advmod', 'npadvmod'])\n",
    "    if pre_adv:\n",
    "        # Get pre and post adverb after pre adverb main verb\n",
    "        pre_advmod_temp, post_advmod_temp = extract_adv(pre_adv)\n",
    "        pre_advmod_temp = ' '.join(pre_advmod_temp)\n",
    "        post_advmod_temp = ' '.join(post_advmod_temp)\n",
    "                        \n",
    "        pre_adv = [pre_advmod_temp, pre_adv.text, post_advmod_temp]\n",
    "        pre_adv = (' '.join(pre_adv)).strip()\n",
    "    else:\n",
    "        pre_adv = ' '\n",
    "                    \n",
    "    # If aux exist\n",
    "    if main_aux:\n",
    "        # Concatenate components: aux (optional) + neg (optional)\n",
    "        ability = cross_product_str(main_aux.text, neg)\n",
    "        # Concatenate components: aux (optional) + neg (optional) + auxpass\n",
    "        ability = cross_product_str(ability, main_auxpass.text)\n",
    "    else:\n",
    "        # Concatenate components: auxpass + neg (optional)\n",
    "        ability = cross_product_str(main_auxpass.text, neg)\n",
    "\n",
    "    # Concatenate components: aux (optional) + neg (optional) + auxpass + adv (optional)\n",
    "    ability = cross_product_str(ability, pre_adv)\n",
    "    \n",
    "    # Concatenate components: aux (optional) + neg (optional) + auxpass + adv (optional) + verb\n",
    "    ability = cross_product_str(ability, main_verb.text)\n",
    "\n",
    "    return ability    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b39907a7-a551-491d-bd93-ad0b64a4fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_passive_rules(token):\n",
    "    abilities = []\n",
    "    result = []\n",
    "    reps = [token.head.lemma_]\n",
    "    # Get the token head (verb). Since passive form at least form: Subject + auxpass + verb \n",
    "    head = token.head\n",
    "    if head.pos_ != 'VERB':\n",
    "        return []\n",
    "\n",
    "    ##================= GET ALL POSSIBLE COMPONENTS ===============##\n",
    "    # 1. Get Possible Tokens (on Left Side) #\n",
    "    # Get neglect; If there is no neglect, return empty text.\n",
    "    neg = get_neglect(head)\n",
    "\n",
    "    # Get aux token\n",
    "    aux = get_token_dep(head, dep='aux')\n",
    "    # Get auxpass token\n",
    "    auxpass = get_token_dep(head, dep='auxpass')\n",
    "    if not auxpass:\n",
    "        # Since passive sentence must have auxpass in its component.\n",
    "        return []\n",
    "\n",
    "    # 2. Get Possible Tokens (on Right Side) #\n",
    "    # Get the agent token\n",
    "    agent = get_token_dep_right(head, dep='agent')\n",
    "    \n",
    "    # Get advmod after verb token\n",
    "    advmod = get_token_dep_right(head, dep=['advmod', 'npadvmod'])\n",
    "\n",
    "    # Get prepositional phrase\n",
    "    prep = get_token_dep(head, dep='prep')\n",
    "\n",
    "    # Get xcomp token\n",
    "    comp = get_token_dep(head, dep=['xcomp', 'ccomp'])\n",
    "\n",
    "    ##================= STORING ABILITIES ===============##    \n",
    "    components = {'main_auxpass': auxpass , 'main_verb': head, 'main_aux': aux, 'neg': neg}\n",
    "    base = base_sentence_passive(main_auxpass=components.get('main_auxpass'), \n",
    "                                 main_verb=components.get('main_verb'), \n",
    "                                 main_aux=components.get('main_aux'), \n",
    "                                 neg=components.get('neg'))\n",
    "    \n",
    "    # Store ability: If adverb modifier exist\n",
    "    if advmod:\n",
    "        # EXPECTED PATTERN: aux (optional) + neg (optional) + auxpass + verb + object\n",
    "        abilities += ability_advmod(advmod, base=base)\n",
    "\n",
    "    # Store ability: If agent and object agent token exist\n",
    "    if agent:\n",
    "        # EXPECTED PATTERN: aux (optional) + neg (optional) + auxpass + verb + object\n",
    "        abilities += ability_pass_agent(agent, base=base)\n",
    "\n",
    "    # Store ability: If preposition after verb exist\n",
    "    if prep:\n",
    "        # EXPECTED PATTERN: aux (optional) + neg (optional) + auxpass + verb + preposition phrase\n",
    "        abilities += ability_prep(prep, base=base)\n",
    "\n",
    "    # Store into result storage\n",
    "    if len(abilities) > 0:\n",
    "        result += cross_product_tuple(abilities, [tuple(reps)])\n",
    "\n",
    "    # Store ability: If xcomp exist\n",
    "    if comp:\n",
    "        # Add compliment verb as representative\n",
    "        reps.append(comp.lemma_)\n",
    "        # Add auxiliary compliment into components\n",
    "        aux_comp = get_token_dep(comp, dep='aux')\n",
    "        # Update base\n",
    "        if aux_comp:\n",
    "            base = cross_product_str(base, aux_comp.text)\n",
    "        base = cross_product_str(base, comp.text)\n",
    "            \n",
    "        temp = ability_relative_verb(comp, base=base)\n",
    "        if len(temp) > 0:\n",
    "            result += cross_product_tuple(temp, [tuple(reps)])\n",
    "        else:\n",
    "            # If do not contain any of that, but intransitive verb ==> Subject + aux (optional) + not (optional) + adv (optional) + verb\n",
    "            if int_rate_comp > 0.5 and comp.lemma_.lower() not in ['be', 'do', 'have']:\n",
    "                # EXPECTED PATTERN: aux (optional) + not (optional) + adv (optional) + verb\n",
    "                result += cross_product_tuple(base, [tuple(reps)]) \n",
    "\n",
    "    # Labeling VERB\n",
    "    result = cross_product_flatten_append('VERB', result)\n",
    "    # return abilities\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8673d-a86f-4fab-98ed-f0536bea3543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1433c-3784-41c5-b769-ad8537d68cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37da49-3665-427d-8d05-e370ffba0388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e75d90-194d-49e8-a7de-61399fe12029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816a70f-64cd-45da-9b91-7e6febfc0149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36781dc0-57cf-4e83-8522-a940228555a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4e8afc4b-5808-42a7-b556-efb2acc1ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_abilities(doc, ant_first_pron='the user'):\n",
    "    # Define local variable.\n",
    "    storage = {}\n",
    "    first_person_pronouns = [ 'i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours']\n",
    "    pronouns = [\n",
    "    \"he\", \"she\", \"they\", \"it\", # Personal Pronouns (Subjective)\n",
    "    \"him\", \"her\", \"them\", \"it\", \"you\",  # Personal Pronouns (Objective)\n",
    "    \"his\", \"hers\", \"theirs\", \"its\", \"mine\", \"yours\", \"ours\",  # Possessive Pronouns\n",
    "    \"her\", \"their\", \"its\",  # Possessive Adjectives\n",
    "    \"himself\", \"herself\", \"themself\", \"themselves\", \"Itself\",  # Reflexive Pronouns,\n",
    "    \"this\", \"that\", \"these\", \"those\", # Demonstrative Pronouns\n",
    "    \"who\", \"whom\", \"whose\", \"which\", \"that\"  # Relative Pronouns\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Get sentence mapper, prepare storage, and type of sentence\n",
    "    sentence_points = {}\n",
    "    type_sentence = {}\n",
    "    for i, s in enumerate(doc.sents):\n",
    "        sentence_points[i] = (s.start, s.end)\n",
    "        storage[i] = []\n",
    "        \n",
    "        if is_perfect_sentence(s):\n",
    "            type_sentence[i] = 'perfect'\n",
    "        else:\n",
    "            type_sentence[i] = 'imperfect'\n",
    "\n",
    "    # Get mapper pronoun and antecedents\n",
    "    mapper_pron_ant = get_mapper_pron_ant(doc)\n",
    "\n",
    "    # Define local variable.\n",
    "    result = []\n",
    "    for idx, token in enumerate(doc):\n",
    "        abilities = []\n",
    "\n",
    "        ## ==================== SUBJECT ACTIVE SENTENCE =========================== ##\n",
    "        # If token is subject (should be nsubj and nsubjpass). This time only nsubj\n",
    "        # In case active sentence form\n",
    "        if token.dep_ == 'nsubj':\n",
    "            abilities += subject_active_rules(token, subject=token)\n",
    "\n",
    "        ## ==================== SUBJECT PASSIVE SENTENCE =========================== ##\n",
    "        # If sentence is passive form.\n",
    "        if token.dep_ == 'nsubjpass':\n",
    "            abilities += subject_passive_rules(token)\n",
    "\n",
    "        ## ==================== IF SENTENCE IS IMPERFECT ========================== ##\n",
    "        sentence_location = get_sentence_location(sentence_points, idx)\n",
    "        if (type_sentence[sentence_location] == 'imperfect') and token.pos_ in ['NOUN', 'PROPN', 'PRON']:\n",
    "            abilities += imperfect_sentence_rules(token)\n",
    "            \n",
    "                \n",
    "        # Store final result\n",
    "        if len(abilities) > 0:\n",
    "            # Subject handling\n",
    "            subject = token.lemma_\n",
    "            # subjects = [token] + get_all_token_conj(token)\n",
    "            # for subject in subjects:\n",
    "            #     # Get posession\n",
    "            #     temp = get_token_dep_left(token, dep='poss')\n",
    "            #     if temp:\n",
    "            #         subjects = cross_product_str((temp.text + \"'s\") if temp.pos_ == 'PROPN' else temp.text, subject.text)\n",
    "                \n",
    "            # current_idx = token.i\n",
    "            # If the subject is pronouns and first person pronouns\n",
    "            # if token.pos_ == 'PRON' and token.text.lower() in first_person_pronouns:\n",
    "            #     subject = ant_first_pron\n",
    "            # # If subject is pronouns and its token location in mapper_pron_ant\n",
    "            # elif token.pos_ == 'PRON' and idx in mapper_pron_ant.keys():\n",
    "            #     # Get the antecedent index location\n",
    "            #     idx_map = mapper_pron_ant[idx]\n",
    "            #     # Change current token subject\n",
    "            #     token = doc[idx_map]\n",
    "            #     subject = token.lemma_\n",
    "            # # If the current child is pronoun (but not in mapper_pron_ant keys)\n",
    "            # elif token.pos_ == 'PRON' and token.text.lower() in pronouns:\n",
    "            #     continue\n",
    "            # # If token only contains special characters or numbers, or length text less than 3 (NOT PRONOUNS)\n",
    "            # elif (re.match(r'^[0-9\\W]+$', token.text)) or (len(token.text) < 3):\n",
    "            #     continue\n",
    "                \n",
    "            # Get all conj subject + current subject\n",
    "            subjects = [subject] + extract_conj(token)\n",
    "            # # Store result\n",
    "            # result += cross_product_tuple(subjects, abilities)\n",
    "            # Storage final result\n",
    "            sentence_location = get_sentence_location(sentence_points, idx)\n",
    "            # storage[sentence_location] += cross_product_tuple(subjects, abilities)\n",
    "\n",
    "            # THIS IS NEW OUTPUT STORAGE SHOULD BE: UNCOMMENT AFTER SUBJECT PASSIVE AND INPERFECT RULES ALREADY ADJUSTED\n",
    "            storage[sentence_location] += cross_product_flatten(subjects, abilities)\n",
    "\n",
    "    # Storing final result\n",
    "    # Make storage unique only\n",
    "    if storage:\n",
    "        for key, value in storage.items():\n",
    "            storage[key] = list(set(value))\n",
    "    return storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38bee4-4bcb-4df6-a22d-905e5040e5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea2505-8cf2-40a5-913e-3a849255651c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155855d-5909-4ee1-ad40-e16d4d2bde02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae028897-7f68-41e7-8974-e0aa82cc989a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e40287-7ca6-4073-8ee8-a41f841326ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01971f72-589c-4528-856a-d9d5fa263725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ab0b4-9a7c-4339-8a98-cb87eb8d69d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b96cf-4d13-4dc2-b58d-88ac47ef2406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3144e136-d10f-4c01-9e0d-53b24ee97aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "620adcac-39b8-4f09-b33b-8888a1e64313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bing Liu's opinion word dictionary\n",
    "bing_liu_opinion_words = set()  # Add the actual list of opinion words here\n",
    "\n",
    "# Function to load opinion words from Bing Liu lexicon\n",
    "def load_opinion_words(filepath):\n",
    "    global bing_liu_opinion_words\n",
    "    temp = pd.read_table(filepath, comment=';', header=None)[0].to_list()\n",
    "    bing_liu_opinion_words = bing_liu_opinion_words.union(set(temp))\n",
    "\n",
    "\n",
    "# Load opinion words\n",
    "current_dir = os.getcwd()\n",
    "load_opinion_words(os.path.join(current_dir, 'util/opinion-lexicon-English/negative-words.txt'))\n",
    "load_opinion_words(os.path.join(current_dir, 'util/opinion-lexicon-English/positive-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "856a7bc6-0472-4c9b-95fe-d5d7d53e187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intransitive rate verb\n",
    "\n",
    "data_verb = pd.read_csv('verb_transitivity.tsv', sep='\\t')\n",
    "\n",
    "map_verb_intrans = data_verb[['verb', 'percent_intrans']].set_index('verb').to_dict()['percent_intrans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "eb91066e-c17f-446e-9cdb-deb92bdf650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nlp model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "67cfa3aa-8323-4a48-8164-c448c84e145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-11-02'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_random_date_this_month():\n",
    "    today = datetime.now()\n",
    "    start_date = today.replace(day=1)\n",
    "    end_date = today.replace(day=today.day)\n",
    "    random_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
    "    return random_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "generate_random_date_this_month()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0c42b932-345d-4f3f-a766-0dff46278928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "positive_reviews = [\n",
    "    \"The staff were incredibly helpful and patient, helping me find the perfect phone!\",\n",
    "    \"I had a great experience purchasing my phone here, the process was smooth and quick.\",\n",
    "    \"Their selection of phones is amazing, and the prices are very competitive!\",\n",
    "    \"I appreciate how the staff walked me through setting up my new device.\",\n",
    "    \"Great customer service, I left with the phone I wanted and all my questions answered.\",\n",
    "    \"They offer amazing deals on phones, I couldn’t resist upgrading.\",\n",
    "    \"The technician fixed my phone’s issue faster than I expected. Highly recommend!\",\n",
    "    \"Fantastic experience, the staff really know their stuff!\",\n",
    "    \"I found the perfect phone case here, and the variety was impressive.\",\n",
    "    \"Upgrading my phone was a breeze thanks to their professional service.\",\n",
    "    \"Staff was knowledgeable and made sure I knew everything about my new phone.\",\n",
    "    \"Prices were reasonable and the staff very courteous!\",\n",
    "    \"Very happy with my purchase, the staff really went the extra mile.\",\n",
    "    \"Excellent service! They helped me find exactly what I was looking for.\",\n",
    "    \"Great deals on accessories, and the staff was super friendly!\",\n",
    "    \"I love this store! Always a smooth experience buying or fixing my phone.\",\n",
    "    \"I got a really good trade-in deal on my old phone.\",\n",
    "    \"Their repair services are quick and reliable.\",\n",
    "    \"The staff was extremely helpful in setting up my phone and transferring all my data.\",\n",
    "    \"Very professional and friendly service, I’m super satisfied!\",\n",
    "    \"Great variety of phones, and the staff was very patient with my questions.\",\n",
    "    \"The process was super simple, and I’m thrilled with my new phone.\",\n",
    "    \"They helped me choose a phone within my budget, which I really appreciated.\",\n",
    "    \"My phone was fixed in less than 30 minutes, such fast service!\",\n",
    "    \"I’m a loyal customer because their customer service is always outstanding.\",\n",
    "    \"Best phone store in town, hands down!\",\n",
    "    \"The staff made sure I was completely comfortable with my purchase.\",\n",
    "    \"I found exactly what I needed, and they helped me get a great deal.\",\n",
    "    \"This store has a fantastic warranty service!\",\n",
    "    \"The staff was very informative, I learned a lot about phone features I didn’t know about.\",\n",
    "    \"Excellent store for buying phone accessories, so much variety!\",\n",
    "    \"The phone I bought here is working perfectly, couldn’t be happier.\",\n",
    "    \"They were super quick in setting up my phone, I was out of there in no time.\",\n",
    "    \"Always come here for upgrades, they never disappoint!\",\n",
    "    \"The store layout is easy to navigate and staff are always ready to help.\",\n",
    "    \"Best pricing for phone plans, they helped me save a lot!\",\n",
    "    \"I’ve been to many phone stores, but this one by far provides the best service.\",\n",
    "    \"Customer service here is top-notch, they always resolve my issues quickly.\",\n",
    "    \"I always recommend this store to friends and family, they never fail to impress.\",\n",
    "    \"The staff took the time to show me all my options, no pressure sales.\",\n",
    "    \"Amazing place to buy the latest phones at great prices!\",\n",
    "    \"Their warranty plan is worth every penny, such a relief!\",\n",
    "    \"I appreciate how they were able to fix my phone on the same day.\",\n",
    "    \"Got a great deal on my new phone and an awesome case as well!\",\n",
    "    \"The staff was very accommodating when I had questions about phone features.\",\n",
    "    \"I had a great experience with their trade-in program.\",\n",
    "    \"Service was quick and efficient, I was in and out within 15 minutes!\",\n",
    "    \"They even helped me transfer all my contacts and data without extra charge.\",\n",
    "    \"My phone has been working flawlessly since I bought it from here.\",\n",
    "    \"They fixed my screen perfectly and even gave me a discount on the repair.\",\n",
    "    \"This is my go-to store for any phone issues, always reliable.\",\n",
    "    \"They offer fantastic promotions and discounts!\",\n",
    "    \"Great phone selection and even better customer service.\",\n",
    "    \"They resolved my issue very quickly and professionally.\",\n",
    "    \"I love how organized the store is and how fast they attend to customers.\",\n",
    "    \"Highly recommend this store if you’re looking for good deals on phones!\",\n",
    "    \"I always leave this store feeling like I made the right purchase.\",\n",
    "    \"I received excellent advice from the sales team, they really know their products.\",\n",
    "    \"Very happy with the repair service here, my phone looks brand new!\"\n",
    "]\n",
    "\n",
    "\n",
    "negative_reviews = [\n",
    "    \"I had to wait over an hour to be helped, and the staff wasn’t apologetic at all.\",\n",
    "    \"Bought a phone here that stopped working within a week, very disappointing.\",\n",
    "    \"Their prices are too high, and the selection is limited.\",\n",
    "    \"Customer service is poor, no one seemed interested in helping me.\",\n",
    "    \"I had a terrible experience, the phone they sold me was defective.\",\n",
    "    \"The staff was rude and unhelpful, I’m never coming back.\",\n",
    "    \"They charged me extra for services I didn’t need, felt like a scam.\",\n",
    "    \"Phone repairs took way too long, I had to come back multiple times.\",\n",
    "    \"I bought a phone, but they didn’t inform me of all the hidden fees.\",\n",
    "    \"Staff seemed untrained and gave me incorrect information about the phone plan.\",\n",
    "    \"Their warranty is useless, they refused to fix my phone under it.\",\n",
    "    \"I had to return a faulty phone twice before they finally gave me a refund.\",\n",
    "    \"Very disorganized, I waited forever just to get a simple issue resolved.\",\n",
    "    \"The phone I purchased here was overpriced compared to other stores.\",\n",
    "    \"They refused to honor the promotion I came in for, very misleading.\",\n",
    "    \"I felt pressured to buy accessories I didn’t need.\",\n",
    "    \"The repair was done poorly, and my phone broke again within a week.\",\n",
    "    \"Customer service was extremely slow, they need to hire more staff.\",\n",
    "    \"They didn’t even check if my phone was working after the repair.\",\n",
    "    \"Terrible experience, my phone still has the same issue after getting it 'fixed'.\",\n",
    "    \"They upsold me on a phone plan I didn’t need, very deceptive.\",\n",
    "    \"The staff was unprofessional and seemed like they didn’t want to be there.\",\n",
    "    \"Their return policy is awful, I couldn’t exchange my phone despite its defects.\",\n",
    "    \"They didn’t apply the discount I was promised.\",\n",
    "    \"The store was messy and understaffed.\",\n",
    "    \"My phone broke down just after the warranty expired, very frustrating.\",\n",
    "    \"They kept trying to sell me more expensive phones when I clearly stated my budget.\",\n",
    "    \"The repair job was incomplete, and they refused to refund me.\",\n",
    "    \"Their customer service representatives were extremely rude on the phone.\",\n",
    "    \"I had to call multiple times just to get a response, very unprofessional.\",\n",
    "    \"They didn’t explain anything clearly and rushed me through the purchase.\",\n",
    "    \"I regret buying from here, their post-purchase support is non-existent.\",\n",
    "    \"Phone stopped working just outside the return window, terrible quality.\",\n",
    "    \"The store was chaotic, with long lines and unhelpful staff.\",\n",
    "    \"They didn’t even have the phone I wanted in stock after promising me it was available.\",\n",
    "    \"Terrible follow-up, they lost my repair order, and I had to start over.\",\n",
    "    \"I felt overcharged for a simple screen repair.\",\n",
    "    \"Bought a refurbished phone that had several issues they didn’t disclose.\",\n",
    "    \"The technician damaged my phone during the repair, and they didn’t take responsibility.\",\n",
    "    \"I’m extremely disappointed, will not be coming back here again.\"\n",
    "]\n",
    "\n",
    "date = ['2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-01',\n",
    "        '2024-11-02',\n",
    "        '2024-11-02',\n",
    "        '2024-11-02',\n",
    "        '2024-11-02',\n",
    "        '2024-11-02',\n",
    "        '2024-11-03',\n",
    "        '2024-11-03',\n",
    "        '2024-11-03',\n",
    "        '2024-11-03',\n",
    "        '2024-11-03',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-04',\n",
    "        '2024-11-05',\n",
    "        '2024-11-05',\n",
    "        '2024-11-05',\n",
    "        '2024-11-05',\n",
    "        '2024-11-06',\n",
    "        '2024-11-06',\n",
    "        '2024-11-06',\n",
    "        '2024-11-06',\n",
    "        '2024-11-06',\n",
    "        '2024-11-07',\n",
    "        '2024-11-07',\n",
    "        '2024-11-07',\n",
    "        '2024-11-07',\n",
    "        '2024-11-08',\n",
    "        '2024-11-08',\n",
    "        '2024-11-08',\n",
    "        '2024-11-08',\n",
    "        '2024-11-09',\n",
    "        '2024-11-09',\n",
    "        '2024-11-10',\n",
    "        '2024-11-10',\n",
    "        '2024-11-10',\n",
    "        '2024-11-10',\n",
    "        '2024-11-10',\n",
    "        '2024-11-10',\n",
    "        '2024-11-10',\n",
    "        '2024-11-10',\n",
    "        '2024-11-11',\n",
    "        '2024-11-11',\n",
    "        '2024-11-11',\n",
    "        '2024-11-11',\n",
    "        '2024-11-11',\n",
    "        '2024-11-12',\n",
    "        '2024-11-12',\n",
    "        '2024-11-12',\n",
    "        '2024-11-12',\n",
    "        '2024-11-13',\n",
    "        '2024-11-13',\n",
    "        '2024-11-13',\n",
    "        '2024-11-13',\n",
    "        '2024-11-13',\n",
    "        '2024-11-13',\n",
    "        '2024-11-13',\n",
    "        '2024-11-13',\n",
    "        '2024-11-14',\n",
    "        '2024-11-14',\n",
    "        '2024-11-14',\n",
    "        '2024-11-14',\n",
    "        '2024-11-14',\n",
    "        '2024-11-14',\n",
    "        '2024-11-14',\n",
    "        '2024-11-14',\n",
    "        '2024-11-15',\n",
    "        '2024-11-15',\n",
    "        '2024-11-15',\n",
    "        '2024-11-15',\n",
    "        '2024-11-15',\n",
    "        '2024-11-16',\n",
    "        '2024-11-16',\n",
    "        '2024-11-16',\n",
    "        '2024-11-17',\n",
    "        '2024-11-17',\n",
    "        '2024-11-17',\n",
    "        '2024-11-17',\n",
    "        '2024-11-17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ba1430b2-5446-44c2-bf3f-57e7222f9b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      99 non-null     int64 \n",
      " 1   review  99 non-null     object\n",
      " 2   date    99 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The staff were incredibly helpful and patient,...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I had a great experience purchasing my phone h...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Their selection of phones is amazing, and the ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I appreciate how the staff walked me through s...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great customer service, I left with the phone ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review        date\n",
       "0   1  The staff were incredibly helpful and patient,...  2024-11-01\n",
       "1   2  I had a great experience purchasing my phone h...  2024-11-01\n",
       "2   3  Their selection of phones is amazing, and the ...  2024-11-01\n",
       "3   4  I appreciate how the staff walked me through s...  2024-11-01\n",
       "4   5  Great customer service, I left with the phone ...  2024-11-01"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'id': range(1, 100),\n",
    "                   'review': positive_reviews + negative_reviews,\n",
    "                  'date': date})\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e4ea5119-916b-4a51-a3d9-6a1ed3e3d0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 1,\n",
       "  'review': 'The staff were incredibly helpful and patient, helping me find the perfect phone!',\n",
       "  'date': '2024-11-01'},\n",
       " 1: {'id': 2,\n",
       "  'review': 'I had a great experience purchasing my phone here, the process was smooth and quick.',\n",
       "  'date': '2024-11-01'},\n",
       " 2: {'id': 3,\n",
       "  'review': 'Their selection of phones is amazing, and the prices are very competitive!',\n",
       "  'date': '2024-11-01'},\n",
       " 3: {'id': 4,\n",
       "  'review': 'I appreciate how the staff walked me through setting up my new device.',\n",
       "  'date': '2024-11-01'},\n",
       " 4: {'id': 5,\n",
       "  'review': 'Great customer service, I left with the phone I wanted and all my questions answered.',\n",
       "  'date': '2024-11-01'},\n",
       " 5: {'id': 6,\n",
       "  'review': 'They offer amazing deals on phones, I couldn’t resist upgrading.',\n",
       "  'date': '2024-11-01'},\n",
       " 6: {'id': 7,\n",
       "  'review': 'The technician fixed my phone’s issue faster than I expected. Highly recommend!',\n",
       "  'date': '2024-11-01'},\n",
       " 7: {'id': 8,\n",
       "  'review': 'Fantastic experience, the staff really know their stuff!',\n",
       "  'date': '2024-11-01'},\n",
       " 8: {'id': 9,\n",
       "  'review': 'I found the perfect phone case here, and the variety was impressive.',\n",
       "  'date': '2024-11-01'},\n",
       " 9: {'id': 10,\n",
       "  'review': 'Upgrading my phone was a breeze thanks to their professional service.',\n",
       "  'date': '2024-11-01'},\n",
       " 10: {'id': 11,\n",
       "  'review': 'Staff was knowledgeable and made sure I knew everything about my new phone.',\n",
       "  'date': '2024-11-01'},\n",
       " 11: {'id': 12,\n",
       "  'review': 'Prices were reasonable and the staff very courteous!',\n",
       "  'date': '2024-11-01'},\n",
       " 12: {'id': 13,\n",
       "  'review': 'Very happy with my purchase, the staff really went the extra mile.',\n",
       "  'date': '2024-11-01'},\n",
       " 13: {'id': 14,\n",
       "  'review': 'Excellent service! They helped me find exactly what I was looking for.',\n",
       "  'date': '2024-11-01'},\n",
       " 14: {'id': 15,\n",
       "  'review': 'Great deals on accessories, and the staff was super friendly!',\n",
       "  'date': '2024-11-01'},\n",
       " 15: {'id': 16,\n",
       "  'review': 'I love this store! Always a smooth experience buying or fixing my phone.',\n",
       "  'date': '2024-11-02'},\n",
       " 16: {'id': 17,\n",
       "  'review': 'I got a really good trade-in deal on my old phone.',\n",
       "  'date': '2024-11-02'},\n",
       " 17: {'id': 18,\n",
       "  'review': 'Their repair services are quick and reliable.',\n",
       "  'date': '2024-11-02'},\n",
       " 18: {'id': 19,\n",
       "  'review': 'The staff was extremely helpful in setting up my phone and transferring all my data.',\n",
       "  'date': '2024-11-02'},\n",
       " 19: {'id': 20,\n",
       "  'review': 'Very professional and friendly service, I’m super satisfied!',\n",
       "  'date': '2024-11-02'},\n",
       " 20: {'id': 21,\n",
       "  'review': 'Great variety of phones, and the staff was very patient with my questions.',\n",
       "  'date': '2024-11-03'},\n",
       " 21: {'id': 22,\n",
       "  'review': 'The process was super simple, and I’m thrilled with my new phone.',\n",
       "  'date': '2024-11-03'},\n",
       " 22: {'id': 23,\n",
       "  'review': 'They helped me choose a phone within my budget, which I really appreciated.',\n",
       "  'date': '2024-11-03'},\n",
       " 23: {'id': 24,\n",
       "  'review': 'My phone was fixed in less than 30 minutes, such fast service!',\n",
       "  'date': '2024-11-03'},\n",
       " 24: {'id': 25,\n",
       "  'review': 'I’m a loyal customer because their customer service is always outstanding.',\n",
       "  'date': '2024-11-03'},\n",
       " 25: {'id': 26,\n",
       "  'review': 'Best phone store in town, hands down!',\n",
       "  'date': '2024-11-04'},\n",
       " 26: {'id': 27,\n",
       "  'review': 'The staff made sure I was completely comfortable with my purchase.',\n",
       "  'date': '2024-11-04'},\n",
       " 27: {'id': 28,\n",
       "  'review': 'I found exactly what I needed, and they helped me get a great deal.',\n",
       "  'date': '2024-11-04'},\n",
       " 28: {'id': 29,\n",
       "  'review': 'This store has a fantastic warranty service!',\n",
       "  'date': '2024-11-04'},\n",
       " 29: {'id': 30,\n",
       "  'review': 'The staff was very informative, I learned a lot about phone features I didn’t know about.',\n",
       "  'date': '2024-11-04'},\n",
       " 30: {'id': 31,\n",
       "  'review': 'Excellent store for buying phone accessories, so much variety!',\n",
       "  'date': '2024-11-04'},\n",
       " 31: {'id': 32,\n",
       "  'review': 'The phone I bought here is working perfectly, couldn’t be happier.',\n",
       "  'date': '2024-11-04'},\n",
       " 32: {'id': 33,\n",
       "  'review': 'They were super quick in setting up my phone, I was out of there in no time.',\n",
       "  'date': '2024-11-04'},\n",
       " 33: {'id': 34,\n",
       "  'review': 'Always come here for upgrades, they never disappoint!',\n",
       "  'date': '2024-11-04'},\n",
       " 34: {'id': 35,\n",
       "  'review': 'The store layout is easy to navigate and staff are always ready to help.',\n",
       "  'date': '2024-11-05'},\n",
       " 35: {'id': 36,\n",
       "  'review': 'Best pricing for phone plans, they helped me save a lot!',\n",
       "  'date': '2024-11-05'},\n",
       " 36: {'id': 37,\n",
       "  'review': 'I’ve been to many phone stores, but this one by far provides the best service.',\n",
       "  'date': '2024-11-05'},\n",
       " 37: {'id': 38,\n",
       "  'review': 'Customer service here is top-notch, they always resolve my issues quickly.',\n",
       "  'date': '2024-11-05'},\n",
       " 38: {'id': 39,\n",
       "  'review': 'I always recommend this store to friends and family, they never fail to impress.',\n",
       "  'date': '2024-11-06'},\n",
       " 39: {'id': 40,\n",
       "  'review': 'The staff took the time to show me all my options, no pressure sales.',\n",
       "  'date': '2024-11-06'},\n",
       " 40: {'id': 41,\n",
       "  'review': 'Amazing place to buy the latest phones at great prices!',\n",
       "  'date': '2024-11-06'},\n",
       " 41: {'id': 42,\n",
       "  'review': 'Their warranty plan is worth every penny, such a relief!',\n",
       "  'date': '2024-11-06'},\n",
       " 42: {'id': 43,\n",
       "  'review': 'I appreciate how they were able to fix my phone on the same day.',\n",
       "  'date': '2024-11-06'},\n",
       " 43: {'id': 44,\n",
       "  'review': 'Got a great deal on my new phone and an awesome case as well!',\n",
       "  'date': '2024-11-07'},\n",
       " 44: {'id': 45,\n",
       "  'review': 'The staff was very accommodating when I had questions about phone features.',\n",
       "  'date': '2024-11-07'},\n",
       " 45: {'id': 46,\n",
       "  'review': 'I had a great experience with their trade-in program.',\n",
       "  'date': '2024-11-07'},\n",
       " 46: {'id': 47,\n",
       "  'review': 'Service was quick and efficient, I was in and out within 15 minutes!',\n",
       "  'date': '2024-11-07'},\n",
       " 47: {'id': 48,\n",
       "  'review': 'They even helped me transfer all my contacts and data without extra charge.',\n",
       "  'date': '2024-11-08'},\n",
       " 48: {'id': 49,\n",
       "  'review': 'My phone has been working flawlessly since I bought it from here.',\n",
       "  'date': '2024-11-08'},\n",
       " 49: {'id': 50,\n",
       "  'review': 'They fixed my screen perfectly and even gave me a discount on the repair.',\n",
       "  'date': '2024-11-08'},\n",
       " 50: {'id': 51,\n",
       "  'review': 'This is my go-to store for any phone issues, always reliable.',\n",
       "  'date': '2024-11-08'},\n",
       " 51: {'id': 52,\n",
       "  'review': 'They offer fantastic promotions and discounts!',\n",
       "  'date': '2024-11-09'},\n",
       " 52: {'id': 53,\n",
       "  'review': 'Great phone selection and even better customer service.',\n",
       "  'date': '2024-11-09'},\n",
       " 53: {'id': 54,\n",
       "  'review': 'They resolved my issue very quickly and professionally.',\n",
       "  'date': '2024-11-10'},\n",
       " 54: {'id': 55,\n",
       "  'review': 'I love how organized the store is and how fast they attend to customers.',\n",
       "  'date': '2024-11-10'},\n",
       " 55: {'id': 56,\n",
       "  'review': 'Highly recommend this store if you’re looking for good deals on phones!',\n",
       "  'date': '2024-11-10'},\n",
       " 56: {'id': 57,\n",
       "  'review': 'I always leave this store feeling like I made the right purchase.',\n",
       "  'date': '2024-11-10'},\n",
       " 57: {'id': 58,\n",
       "  'review': 'I received excellent advice from the sales team, they really know their products.',\n",
       "  'date': '2024-11-10'},\n",
       " 58: {'id': 59,\n",
       "  'review': 'Very happy with the repair service here, my phone looks brand new!',\n",
       "  'date': '2024-11-10'},\n",
       " 59: {'id': 60,\n",
       "  'review': 'I had to wait over an hour to be helped, and the staff wasn’t apologetic at all.',\n",
       "  'date': '2024-11-10'},\n",
       " 60: {'id': 61,\n",
       "  'review': 'Bought a phone here that stopped working within a week, very disappointing.',\n",
       "  'date': '2024-11-10'},\n",
       " 61: {'id': 62,\n",
       "  'review': 'Their prices are too high, and the selection is limited.',\n",
       "  'date': '2024-11-11'},\n",
       " 62: {'id': 63,\n",
       "  'review': 'Customer service is poor, no one seemed interested in helping me.',\n",
       "  'date': '2024-11-11'},\n",
       " 63: {'id': 64,\n",
       "  'review': 'I had a terrible experience, the phone they sold me was defective.',\n",
       "  'date': '2024-11-11'},\n",
       " 64: {'id': 65,\n",
       "  'review': 'The staff was rude and unhelpful, I’m never coming back.',\n",
       "  'date': '2024-11-11'},\n",
       " 65: {'id': 66,\n",
       "  'review': 'They charged me extra for services I didn’t need, felt like a scam.',\n",
       "  'date': '2024-11-11'},\n",
       " 66: {'id': 67,\n",
       "  'review': 'Phone repairs took way too long, I had to come back multiple times.',\n",
       "  'date': '2024-11-12'},\n",
       " 67: {'id': 68,\n",
       "  'review': 'I bought a phone, but they didn’t inform me of all the hidden fees.',\n",
       "  'date': '2024-11-12'},\n",
       " 68: {'id': 69,\n",
       "  'review': 'Staff seemed untrained and gave me incorrect information about the phone plan.',\n",
       "  'date': '2024-11-12'},\n",
       " 69: {'id': 70,\n",
       "  'review': 'Their warranty is useless, they refused to fix my phone under it.',\n",
       "  'date': '2024-11-12'},\n",
       " 70: {'id': 71,\n",
       "  'review': 'I had to return a faulty phone twice before they finally gave me a refund.',\n",
       "  'date': '2024-11-13'},\n",
       " 71: {'id': 72,\n",
       "  'review': 'Very disorganized, I waited forever just to get a simple issue resolved.',\n",
       "  'date': '2024-11-13'},\n",
       " 72: {'id': 73,\n",
       "  'review': 'The phone I purchased here was overpriced compared to other stores.',\n",
       "  'date': '2024-11-13'},\n",
       " 73: {'id': 74,\n",
       "  'review': 'They refused to honor the promotion I came in for, very misleading.',\n",
       "  'date': '2024-11-13'},\n",
       " 74: {'id': 75,\n",
       "  'review': 'I felt pressured to buy accessories I didn’t need.',\n",
       "  'date': '2024-11-13'},\n",
       " 75: {'id': 76,\n",
       "  'review': 'The repair was done poorly, and my phone broke again within a week.',\n",
       "  'date': '2024-11-13'},\n",
       " 76: {'id': 77,\n",
       "  'review': 'Customer service was extremely slow, they need to hire more staff.',\n",
       "  'date': '2024-11-13'},\n",
       " 77: {'id': 78,\n",
       "  'review': 'They didn’t even check if my phone was working after the repair.',\n",
       "  'date': '2024-11-13'},\n",
       " 78: {'id': 79,\n",
       "  'review': \"Terrible experience, my phone still has the same issue after getting it 'fixed'.\",\n",
       "  'date': '2024-11-14'},\n",
       " 79: {'id': 80,\n",
       "  'review': 'They upsold me on a phone plan I didn’t need, very deceptive.',\n",
       "  'date': '2024-11-14'},\n",
       " 80: {'id': 81,\n",
       "  'review': 'The staff was unprofessional and seemed like they didn’t want to be there.',\n",
       "  'date': '2024-11-14'},\n",
       " 81: {'id': 82,\n",
       "  'review': 'Their return policy is awful, I couldn’t exchange my phone despite its defects.',\n",
       "  'date': '2024-11-14'},\n",
       " 82: {'id': 83,\n",
       "  'review': 'They didn’t apply the discount I was promised.',\n",
       "  'date': '2024-11-14'},\n",
       " 83: {'id': 84,\n",
       "  'review': 'The store was messy and understaffed.',\n",
       "  'date': '2024-11-14'},\n",
       " 84: {'id': 85,\n",
       "  'review': 'My phone broke down just after the warranty expired, very frustrating.',\n",
       "  'date': '2024-11-14'},\n",
       " 85: {'id': 86,\n",
       "  'review': 'They kept trying to sell me more expensive phones when I clearly stated my budget.',\n",
       "  'date': '2024-11-14'},\n",
       " 86: {'id': 87,\n",
       "  'review': 'The repair job was incomplete, and they refused to refund me.',\n",
       "  'date': '2024-11-15'},\n",
       " 87: {'id': 88,\n",
       "  'review': 'Their customer service representatives were extremely rude on the phone.',\n",
       "  'date': '2024-11-15'},\n",
       " 88: {'id': 89,\n",
       "  'review': 'I had to call multiple times just to get a response, very unprofessional.',\n",
       "  'date': '2024-11-15'},\n",
       " 89: {'id': 90,\n",
       "  'review': 'They didn’t explain anything clearly and rushed me through the purchase.',\n",
       "  'date': '2024-11-15'},\n",
       " 90: {'id': 91,\n",
       "  'review': 'I regret buying from here, their post-purchase support is non-existent.',\n",
       "  'date': '2024-11-15'},\n",
       " 91: {'id': 92,\n",
       "  'review': 'Phone stopped working just outside the return window, terrible quality.',\n",
       "  'date': '2024-11-16'},\n",
       " 92: {'id': 93,\n",
       "  'review': 'The store was chaotic, with long lines and unhelpful staff.',\n",
       "  'date': '2024-11-16'},\n",
       " 93: {'id': 94,\n",
       "  'review': 'They didn’t even have the phone I wanted in stock after promising me it was available.',\n",
       "  'date': '2024-11-16'},\n",
       " 94: {'id': 95,\n",
       "  'review': 'Terrible follow-up, they lost my repair order, and I had to start over.',\n",
       "  'date': '2024-11-17'},\n",
       " 95: {'id': 96,\n",
       "  'review': 'I felt overcharged for a simple screen repair.',\n",
       "  'date': '2024-11-17'},\n",
       " 96: {'id': 97,\n",
       "  'review': 'Bought a refurbished phone that had several issues they didn’t disclose.',\n",
       "  'date': '2024-11-17'},\n",
       " 97: {'id': 98,\n",
       "  'review': 'The technician damaged my phone during the repair, and they didn’t take responsibility.',\n",
       "  'date': '2024-11-17'},\n",
       " 98: {'id': 99,\n",
       "  'review': 'I’m extremely disappointed, will not be coming back here again.',\n",
       "  'date': '2024-11-17'}}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data json format\n",
    "\n",
    "data_json = df.to_dict('index')\n",
    "\n",
    "data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "fcbd1c83-8c4e-4279-9868-f85a7870afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_words(corpus, thres_tfidf=75, thres_idf=25):\n",
    "    # Define local variables\n",
    "    storage_idf = set()\n",
    "    # storage_tfidf = set()\n",
    "    storage_tfidf = {}\n",
    "\n",
    "    # Define the list of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Preprocessing text\n",
    "    def preprocessing(text):\n",
    "        text = remove_extra_spaces(text)\n",
    "        text = expand_contractions(text)\n",
    "        text = remove_non_ascii(text)\n",
    "\n",
    "        # Get token of words\n",
    "        doc = nlp(text)\n",
    "        result = []\n",
    "        for token in doc:\n",
    "            t = token.lemma_.lower()\n",
    "\n",
    "            # If only contains special characters or numbers and length less than 3\n",
    "            if re.match(r'^[0-9\\W]+$', t) or len(t) < 3 or t in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                result.append(t)\n",
    "        return result\n",
    "\n",
    "    ##========= GENERATE MODEL =========##\n",
    "    # Create texts\n",
    "    texts = [preprocessing(document) for document in corpus]\n",
    "\n",
    "    # Create dictionary\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "    # Convert documents into Bag-of-words format\n",
    "    corpus_bow = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Train the TF-IDF model\n",
    "    tfidf_model = gensim.models.TfidfModel(corpus_bow)\n",
    "\n",
    "    ##============ EXTRACT IMPORTANT VALUES =========##\n",
    "    # Get the idf values\n",
    "    idf_values = tfidf_model.idfs # Return (word_id: idf_values)\n",
    "    scores_idf = np.array(list(idf_values.values()))\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for id, value in idf_values.items():\n",
    "        word = dictionary[id]\n",
    "        idf_dict[word] = value\n",
    "        \n",
    "\n",
    "    # Apply the model to the corpus (get corpus tfidf)\n",
    "    corpus_tfidf = tfidf_model[corpus_bow]\n",
    "\n",
    "    # Get dictionary of tfidf values and scores\n",
    "    scores_tfidf = []\n",
    "    tfidf_dict = {}\n",
    "    for doc_idx, doc in enumerate(corpus_tfidf):\n",
    "\n",
    "        dict_doc = {}\n",
    "        for word_id, score in doc:\n",
    "            word = dictionary[word_id]\n",
    "            dict_doc[word] = score\n",
    "            scores_tfidf.append(score)\n",
    "\n",
    "        tfidf_dict[doc_idx] = dict_doc\n",
    "    \n",
    "    ##=========== Get the threshold =========##\n",
    "    threshold_idf = np.percentile(scores_idf, thres_idf)\n",
    "    threshold_tfidf = np.percentile(scores_tfidf, thres_tfidf)\n",
    "\n",
    "\n",
    "    ##========== Get Words =============##\n",
    "    # IDF\n",
    "    for key, value in idf_dict.items():\n",
    "        if value <= threshold_idf:\n",
    "            storage_idf.add(key)\n",
    "\n",
    "    # TF IDF\n",
    "    # for idx_doc, dict_words in tfidf_dict.items():\n",
    "    #     for key, value in dict_words.items():\n",
    "    #         if value >= threshold_tfidf:\n",
    "    #             storage_tfidf.add(key)\n",
    "\n",
    "    for idx_doc, dict_words in tfidf_dict.items():\n",
    "        temp = set()\n",
    "        for key, value in dict_words.items():\n",
    "            if value >= threshold_tfidf:\n",
    "                temp.add(key)\n",
    "            \n",
    "        storage_tfidf[idx_doc] = temp\n",
    "\n",
    "    return storage_idf, storage_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b727df68-409e-4e3e-8f15-8c527807ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_filter(data, id, mapper_idf=None, mapper_tfidf=None):\n",
    "    # Define the list of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def preprocessing(text):\n",
    "        text = remove_extra_spaces(text)\n",
    "        text = expand_contractions(text)\n",
    "        text = remove_non_ascii(text)\n",
    "\n",
    "        # Get token of words\n",
    "        doc = nlp(text)\n",
    "        result_obj = []\n",
    "        result_verb_adj = []\n",
    "        for token in doc:\n",
    "            t = token.lemma_.lower()\n",
    "            # If only contains special characters or numbers and length less than 3\n",
    "            if re.match(r'^[0-9\\W]+$', t) or len(t) < 3 or t in stop_words:\n",
    "                continue\n",
    "            # If the token is adjective, noun, propn, or verb\n",
    "            if token.pos_ in ['NOUN', 'PROPN']:\n",
    "                result_obj.append(t)\n",
    "            elif token.pos_ in ['ADJ', 'VERB']:\n",
    "                result_verb_adj.append(t)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return result_obj, result_verb_adj\n",
    "        \n",
    "    if not mapper_idf and not mapper_tfidf:\n",
    "        return data\n",
    "\n",
    "    mapper = mapper_idf | mapper_tfidf[id]\n",
    "    temp = {}\n",
    "    for idx, element in data.items():\n",
    "        temp[idx] = []\n",
    "        for d in element:\n",
    "            text = ' '.join(d)\n",
    "            compare_obj, compare_verb_adj = preprocessing(text)\n",
    "\n",
    "            is_object_pass = False\n",
    "            is_verb_adj_pass = False\n",
    "\n",
    "            # Handling object\n",
    "            if len(compare_obj) == 0:\n",
    "                is_object_pass = True\n",
    "            else:\n",
    "                for w in compare_obj:\n",
    "                    if w in mapper:\n",
    "                        is_object_pass = True\n",
    "                        break\n",
    "            \n",
    "            # Handling verb ajective\n",
    "            if not is_verb_adj_pass:\n",
    "                for w in compare_verb_adj:\n",
    "                    if w in mapper:\n",
    "                        is_verb_adj_pass = True\n",
    "                        break\n",
    "\n",
    "            if is_object_pass and is_verb_adj_pass:\n",
    "                temp[idx].append(d)\n",
    "\n",
    "            # If object passed and verb-adj passed ==> True\n",
    "            # If object passed but verb-adj not passed ==> False\n",
    "            # If object not passed ==> False\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "88ab018e-218e-48f4-9753-b38271a4b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_filter_aspect(data, id, mapper_idf=None, mapper_tfidf=None):\n",
    "\n",
    "    if not mapper_idf and not mapper_tfidf:\n",
    "        return data\n",
    "\n",
    "    mapper = mapper_idf | mapper_tfidf[id]\n",
    "    temp = []\n",
    "    for d in data:\n",
    "        doc = nlp(d)\n",
    "        for token in doc:\n",
    "            if token.text.lower() in mapper:\n",
    "                temp.append(d)\n",
    "                break\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "cf4d8192-c356-49ef-8360-4274700a7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_words_aspect(dict_doc, idx_doc, mapper_1=None, mapper_2=None):\n",
    "    # If mapper_1 and mapper_2 is None, do not filter it.\n",
    "    if not mapper_1 and not mapper_2:\n",
    "        return dict_doc\n",
    "\n",
    "    # Copy dictionary\n",
    "    dictionary = dict_doc.copy()\n",
    "    \n",
    "    # Get mapper based on its document.\n",
    "    if mapper_2 :\n",
    "        mapper_2 = mapper_2[idx_doc]\n",
    "\n",
    "    for key, value in dictionary.items():\n",
    "        temp = []\n",
    "        for v1 in value:\n",
    "            # Since it could be multiple word, we must check one by one\n",
    "            for v in v1.split():\n",
    "                # If aspect is in mapper_1 or mapper_2 then keep it\n",
    "                if v in mapper_1 or v in mapper_2:\n",
    "                    # Append full value\n",
    "                    temp.append(v1)\n",
    "                    break\n",
    "\n",
    "        # Update list of string\n",
    "        dictionary[key] = temp\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "04d81284-6cd5-43ce-b5f0-dcb357fda3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function for preprocessing data\n",
    "\n",
    "# Function to check if a specific word exists in text\n",
    "def word_exists(word, text):\n",
    "    # Create the regex pattern with word boundaries\n",
    "    pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "    \n",
    "    # Search for the word in the text\n",
    "    if re.search(pattern, text, re.IGNORECASE):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def flatten_data(x):\n",
    "    return [item for sublist in x.values() for item in sublist]\n",
    "\n",
    "def contraction(x):\n",
    "    flatten = flatten_data(x)\n",
    "\n",
    "    if len(flatten) > 0:\n",
    "        temp = [item[0] + ' ' + item[1] for item in flatten]\n",
    "        return '. '.join(temp) + '.'\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b14d9646-27dc-434a-bbc5-ae1e9ac1a72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {0: [('staff', 'were helpful', ('helpful',), '...\n",
       "1     {0: [('process', 'was quick', ('quick',), 'ADJ...\n",
       "2     {0: [('selection', 'is amazing', ('amazing',),...\n",
       "3     {0: [('I', 'appreciate walked me', ('appreciat...\n",
       "4     {0: [('I', 'left with phone', ('leave',), 'VER...\n",
       "                            ...                        \n",
       "94    {0: [('they', 'lost repair order', ('lose',), ...\n",
       "95    {0: [('I', 'felt overcharged', ('feel',), 'VER...\n",
       "96                                              {0: []}\n",
       "97    {0: [('they', 'did not take responsibility', (...\n",
       "98                                              {0: []}\n",
       "Name: review, Length: 99, dtype: object"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply extraction\n",
    "\n",
    "def process_ability(x):\n",
    "    # Prepare sentence\n",
    "    texts = remove_extra_spaces(x)\n",
    "    texts = expand_contractions(x)\n",
    "    texts = remove_non_ascii(x)\n",
    "\n",
    "    # Get aspect\n",
    "    doc = nlp(texts)\n",
    "    mapper_pron_ant = get_mapper_pron_ant(doc)\n",
    "    result = get_raw_abilities(doc)\n",
    "    \n",
    "    return result\n",
    "\n",
    "df_ability = df['review'].apply(process_ability)\n",
    "df_ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e2e2c44b-7325-4a47-9a97-110358c6e386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['staff were helpful. staff were patient.',\n",
       "       'process was quick. process was smooth.',\n",
       "       'selection is amazing. price are competitive.',\n",
       "       'I appreciate walked me. I appreciate walked through setting new device.',\n",
       "       'I left with phone. question answered.',\n",
       "       'I could not resist offer amazing deals on phones. I could not resist upgrading.',\n",
       "       'technician fixed faster. technician fixed phones issue. I expected.',\n",
       "       'experience really know stuff.',\n",
       "       'I found perfect phone case. variety was impressive.', '',\n",
       "       'staff was knowledgeable.', 'price were reasonable.',\n",
       "       'staff really went mile.',\n",
       "       'service be excellent. they helped find.',\n",
       "       'deal was friendly. staff was friendly.',\n",
       "       'I love store. buying be experience. fixing be experience.',\n",
       "       'I got good deal on old phone.',\n",
       "       'service are quick. service are reliable.',\n",
       "       'staff was helpful in setting phone.', 'I m satisfied.',\n",
       "       'staff was patient with questions. variety was patient with questions.',\n",
       "       'process was simple. I m thrilled.',\n",
       "       'they helped choose within budget. they helped choose phone.',\n",
       "       'phone was fixed in minutes.', 'service is outstanding. I m.',\n",
       "       'store hands.', 'I was comfortable with purchase. staff made.',\n",
       "       'I found needed what. they helped get great deal.',\n",
       "       'store has fantastic warranty service.',\n",
       "       'staff was informative. I learned lot about phone features. I learned was informative.',\n",
       "       'variety be excellent. store be excellent.', '',\n",
       "       'they were quick in setting phone.', '',\n",
       "       'layout is easy. staff are ready.', 'they helped save lot.',\n",
       "       'I been to many phone stores. one provides best service.',\n",
       "       'they always resolve is notch. they always resolve quickly. they always resolve issues. service is notch. service is notch.',\n",
       "       'they not fail recommend to family. they not fail recommend store. they not fail recommend to friends.',\n",
       "       'staff took time.', 'place be amazing.', 'plan is worth.',\n",
       "       'they were able. I appreciate were able.', '',\n",
       "       'staff was accommodating.', 'I had great experience with program.',\n",
       "       'service was quick. service was efficient.',\n",
       "       'they even helped transfer contacts. they even helped transfer without extra charge. they even helped transfer data.',\n",
       "       'phone has working flawlessly. I bought it. I bought from here.',\n",
       "       'they even gave discount on repair. they fixed perfectly. they fixed screen.',\n",
       "       'this is reliable.',\n",
       "       'they offer fantastic promotions. they offer discounts.',\n",
       "       'selection be phone. service be great. service be phone. selection be great.',\n",
       "       'they resolved professionally. they resolved very quickly. they resolved issue.',\n",
       "       'they fast attend to customers. I love is organized. store is organized.',\n",
       "       'you re looking for good deals.',\n",
       "       'I always leave store. I made right purchase.',\n",
       "       'they really know received excellent advice from sales team. they really know products.',\n",
       "       'phone looks new.',\n",
       "       'I had to wait over hour. staff was not apologetic.', '',\n",
       "       'price are high. selection is limited.',\n",
       "       'one seemed is poor. service is poor.', 'phone was defective.',\n",
       "       'I m not coming was rude. staff was rude. I m not coming back. staff was unhelpful.',\n",
       "       'they charged me. they felt like scam. they charged extra for services.',\n",
       "       'I had took too long. I had took way.',\n",
       "       'they did not inform me. they did not inform of hidden fees. I bought phone.',\n",
       "       'staff seemed. staff gave incorrect information about phone plan.',\n",
       "       'they refused is useless. warranty is useless.',\n",
       "       'they twice gave refund. I had to return faulty phone.',\n",
       "       'I very disorganized waited forever.', '',\n",
       "       'they refused to honor promotion.', 'I felt pressured.',\n",
       "       'repair was done poorly. phone broke again. phone broke within week.',\n",
       "       'they need was slow. service was slow.',\n",
       "       'phone was working after repair.',\n",
       "       'phone still has same issue after getting.',\n",
       "       'they upsold on phone plan. they upsold me.',\n",
       "       'they did not want to be there. staff was unprofessional.',\n",
       "       'I could not exchange despite defects. policy is awful. I could not exchange phone. I could not exchange is awful.',\n",
       "       'they did not apply discount.',\n",
       "       'store was understaffed. store was messy.',\n",
       "       'warranty just expired. phone broke.', 'they kept trying.',\n",
       "       'job was incomplete. they refused to refund me.',\n",
       "       'representative were rude on phone.',\n",
       "       'I had to call multiple times.',\n",
       "       'they did not explain anything. they rushed me. they rushed through purchase. they did not explain clearly.',\n",
       "       'support is non.',\n",
       "       'phone stopped working outside return window. phone stopped quality.',\n",
       "       'store was chaotic. store was with unhelpful staff. store was with long lines.',\n",
       "       'they did not even have after promising me. it was available. they did not even have phone.',\n",
       "       'they lost repair order.', 'I felt overcharged.', '',\n",
       "       'they did not take responsibility. technician damaged during repair. technician damaged phone.',\n",
       "       ''], dtype=object)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df_ability.apply(contraction).values\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "06a6eb43-f9bb-48ef-9914-ba5ef0a61170",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = corpus\n",
    "\n",
    "mapper_1, mapper_2 = get_words(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2ae1235f-97ab-4f04-a0c7-c3d710063960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'always',\n",
       " 'amazing',\n",
       " 'appreciate',\n",
       " 'break',\n",
       " 'buy',\n",
       " 'charge',\n",
       " 'could',\n",
       " 'deal',\n",
       " 'discount',\n",
       " 'even',\n",
       " 'excellent',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'fantastic',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'find',\n",
       " 'fix',\n",
       " 'get',\n",
       " 'give',\n",
       " 'good',\n",
       " 'great',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'issue',\n",
       " 'know',\n",
       " 'leave',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'make',\n",
       " 'need',\n",
       " 'new',\n",
       " 'offer',\n",
       " 'one',\n",
       " 'patient',\n",
       " 'phone',\n",
       " 'plan',\n",
       " 'price',\n",
       " 'process',\n",
       " 'promotion',\n",
       " 'purchase',\n",
       " 'question',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'really',\n",
       " 'refund',\n",
       " 'refuse',\n",
       " 'reliable',\n",
       " 'repair',\n",
       " 'resolve',\n",
       " 'return',\n",
       " 'rude',\n",
       " 'seem',\n",
       " 'selection',\n",
       " 'service',\n",
       " 'set',\n",
       " 'staff',\n",
       " 'store',\n",
       " 'take',\n",
       " 'technician',\n",
       " 'time',\n",
       " 'unhelpful',\n",
       " 'variety',\n",
       " 'wait',\n",
       " 'warranty',\n",
       " 'within',\n",
       " 'work'}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8faf5158-196f-44f8-b093-1b956428d5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: set(),\n",
       " 1: {'process'},\n",
       " 2: set(),\n",
       " 3: {'walk'},\n",
       " 4: {'answer'},\n",
       " 5: {'resist'},\n",
       " 6: {'technician'},\n",
       " 7: set(),\n",
       " 8: set(),\n",
       " 9: set(),\n",
       " 10: {'knowledgeable'},\n",
       " 11: {'reasonable'},\n",
       " 12: {'mile'},\n",
       " 13: set(),\n",
       " 14: {'friendly'},\n",
       " 15: {'experience'},\n",
       " 16: {'old'},\n",
       " 17: {'service'},\n",
       " 18: {'helpful', 'set'},\n",
       " 19: {'satisfied'},\n",
       " 20: {'patient', 'question'},\n",
       " 21: {'simple', 'thrilled'},\n",
       " 22: {'choose'},\n",
       " 23: {'minute'},\n",
       " 24: {'outstanding'},\n",
       " 25: {'hand'},\n",
       " 26: {'comfortable'},\n",
       " 27: set(),\n",
       " 28: {'fantastic'},\n",
       " 29: {'informative', 'learn'},\n",
       " 30: {'excellent'},\n",
       " 31: set(),\n",
       " 32: {'quick', 'set'},\n",
       " 33: set(),\n",
       " 34: set(),\n",
       " 35: {'save'},\n",
       " 36: set(),\n",
       " 37: {'notch'},\n",
       " 38: {'fail', 'recommend'},\n",
       " 39: {'take', 'time'},\n",
       " 40: {'place'},\n",
       " 41: {'worth'},\n",
       " 42: {'able'},\n",
       " 43: set(),\n",
       " 44: {'accommodate'},\n",
       " 45: {'program'},\n",
       " 46: {'efficient', 'service'},\n",
       " 47: {'transfer'},\n",
       " 48: {'buy'},\n",
       " 49: set(),\n",
       " 50: {'reliable'},\n",
       " 51: {'offer'},\n",
       " 52: {'great', 'selection'},\n",
       " 53: {'resolve'},\n",
       " 54: {'organize'},\n",
       " 55: {'look'},\n",
       " 56: set(),\n",
       " 57: set(),\n",
       " 58: {'look', 'new'},\n",
       " 59: set(),\n",
       " 60: set(),\n",
       " 61: set(),\n",
       " 62: {'poor'},\n",
       " 63: {'defective'},\n",
       " 64: {'come'},\n",
       " 65: {'charge'},\n",
       " 66: {'take'},\n",
       " 67: {'inform'},\n",
       " 68: set(),\n",
       " 69: {'useless'},\n",
       " 70: set(),\n",
       " 71: {'disorganized', 'forever'},\n",
       " 72: set(),\n",
       " 73: {'honor'},\n",
       " 74: {'pressured'},\n",
       " 75: {'break'},\n",
       " 76: {'slow'},\n",
       " 77: {'repair', 'work'},\n",
       " 78: {'still'},\n",
       " 79: {'upsold'},\n",
       " 80: {'unprofessional', 'want'},\n",
       " 81: {'exchange'},\n",
       " 82: {'apply'},\n",
       " 83: set(),\n",
       " 84: {'expire'},\n",
       " 85: {'keep', 'try'},\n",
       " 86: set(),\n",
       " 87: {'representative', 'rude'},\n",
       " 88: {'call', 'multiple'},\n",
       " 89: {'explain', 'rush'},\n",
       " 90: {'non', 'support'},\n",
       " 91: {'stop'},\n",
       " 92: {'store'},\n",
       " 93: {'even'},\n",
       " 94: {'lose', 'order'},\n",
       " 95: {'overcharge'},\n",
       " 96: set(),\n",
       " 97: {'damage'},\n",
       " 98: set()}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982e8f4-1a3b-471e-bd24-9f97df3ceb9d",
   "metadata": {},
   "source": [
    "**Important Sentence Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ba6a041b-f714-4b58-90af-9694447cab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: FILTER FOR SENTENCES ==> CHANGE WITH LSI SUMMARIZATION.\n",
    "\n",
    "# df['ability_filtered'] = [weighted_filter(data, id=id, mapper_idf=mapper_1, mapper_tfidf=mapper_2) for id, data in enumerate(df['ability'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de237bad-28d6-4162-94be-0abfa9b7d13a",
   "metadata": {},
   "source": [
    "**Aspect Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e7189e4f-ba67-4d5c-90ba-8dffa99aa4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_matched_patterns(input_string, patterns):\n",
    "#     # Create a regex pattern by joining the list of patterns using the '|' (OR) operator\n",
    "#     regex_pattern = '|'.join(map(re.escape, patterns))\n",
    "    \n",
    "#     # Use re.findall to find all matches in the input string\n",
    "#     matches = re.findall(regex_pattern, input_string)\n",
    "    \n",
    "#     return matches\n",
    "\n",
    "# # Example usage\n",
    "# input_string = \"This is an apple, melon dragon, and orange\"\n",
    "# patterns = ['apple', 'an apple', 'melon dragon', 'melon', 'dragon', 'manggoo', 'pink']\n",
    "\n",
    "# matched_patterns = find_matched_patterns(input_string, patterns)\n",
    "# print(matched_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f1ce402e-322d-4fdb-a959-539ba5d2ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'staff': {'ADJ': [(('helpful',), 'staff were helpful.'),\n",
       "    (('patient',), 'staff were patient.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'process': {'ADJ': [(('quick',), 'process was quick.'),\n",
       "    (('smooth',), 'process was smooth.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'selection': {'ADJ': [(('amazing',), 'selection is amazing.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []},\n",
       "  'price': {'ADJ': [(('competitive',), 'price are competitive.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'question': {'ADJ': [],\n",
       "   'VERB': [(('answer',), 'question answered.')],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'technician': {'ADJ': [],\n",
       "   'VERB': [(('fix',), 'technician fixed faster.'),\n",
       "    (('fix',), 'technician fixed phones issue.')],\n",
       "   'OTHER': []},\n",
       "  'phones issue': {'ADJ': [],\n",
       "   'VERB': [(('fix',), 'technician fixed phones issue.')],\n",
       "   'OTHER': []}},\n",
       " {'experience': {'ADJ': [],\n",
       "   'VERB': [(('know',), 'experience really know stuff.')],\n",
       "   'OTHER': []}},\n",
       " {'variety': {'ADJ': [(('impressive',), 'variety was impressive.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'staff': {'ADJ': [(('knowledgeable',), 'staff was knowledgeable.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'price': {'ADJ': [(('reasonable',), 'price were reasonable.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'staff': {'ADJ': [],\n",
       "   'VERB': [(('go',), 'staff really went mile.')],\n",
       "   'OTHER': []}},\n",
       " {'service': {'ADJ': [(('excellent',), 'service be excellent.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'deal': {'ADJ': [(('friendly',), 'deal was friendly.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []},\n",
       "  'staff': {'ADJ': [(('friendly',), 'staff was friendly.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'buying': {'ADJ': [],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('experience',), 'buying be experience.')]},\n",
       "  'fixing': {'ADJ': [],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('experience',), 'fixing be experience.')]}},\n",
       " {},\n",
       " {'service': {'ADJ': [(('quick',), 'service are quick.'),\n",
       "    (('reliable',), 'service are reliable.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'phone': {'ADJ': [(('helpful',), 'staff was helpful in setting phone.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []},\n",
       "  'staff': {'ADJ': [(('helpful',), 'staff was helpful in setting phone.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'staff': {'ADJ': [(('patient',), 'staff was patient with questions.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []},\n",
       "  'variety': {'ADJ': [(('patient',), 'variety was patient with questions.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'process': {'ADJ': [(('simple',), 'process was simple.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'phone': {'ADJ': [],\n",
       "   'VERB': [(('fix',), 'phone was fixed in minutes.')],\n",
       "   'OTHER': []}},\n",
       " {'service': {'ADJ': [(('outstanding',), 'service is outstanding.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'store': {'ADJ': [], 'VERB': [(('hand',), 'store hands.')], 'OTHER': []}},\n",
       " {'staff': {'ADJ': [], 'VERB': [(('make',), 'staff made.')], 'OTHER': []}},\n",
       " {},\n",
       " {'warranty service': {'ADJ': [],\n",
       "   'VERB': [(('have',), 'store has fantastic warranty service.')],\n",
       "   'OTHER': []},\n",
       "  'store': {'ADJ': [],\n",
       "   'VERB': [(('have',), 'store has fantastic warranty service.')],\n",
       "   'OTHER': []}},\n",
       " {'staff': {'ADJ': [(('informative',), 'staff was informative.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'variety': {'ADJ': [(('excellent',), 'variety be excellent.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []},\n",
       "  'store': {'ADJ': [(('excellent',), 'store be excellent.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'layout': {'ADJ': [(('easy',), 'layout is easy.')], 'VERB': [], 'OTHER': []},\n",
       "  'staff': {'ADJ': [(('ready',), 'staff are ready.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'service': {'ADJ': [],\n",
       "   'VERB': [(('provide',), 'one provides best service.')],\n",
       "   'OTHER': []},\n",
       "  'one': {'ADJ': [],\n",
       "   'VERB': [(('provide',), 'one provides best service.')],\n",
       "   'OTHER': []}},\n",
       " {'service': {'ADJ': [(('notch',), 'service is notch.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('notch',), 'service is notch.')]}},\n",
       " {},\n",
       " {'time': {'ADJ': [], 'VERB': [(('take',), 'staff took time.')], 'OTHER': []},\n",
       "  'staff': {'ADJ': [],\n",
       "   'VERB': [(('take',), 'staff took time.')],\n",
       "   'OTHER': []}},\n",
       " {'place': {'ADJ': [(('amazing',), 'place be amazing.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'plan': {'ADJ': [(('worth',), 'plan is worth.')], 'VERB': [], 'OTHER': []}},\n",
       " {},\n",
       " {},\n",
       " {'staff': {'ADJ': [(('accommodating',), 'staff was accommodating.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'service': {'ADJ': [(('quick',), 'service was quick.'),\n",
       "    (('efficient',), 'service was efficient.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'phone': {'ADJ': [],\n",
       "   'VERB': [(('work',), 'phone has working flawlessly.')],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'selection': {'ADJ': [(('great',), 'selection be great.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('phone',), 'selection be phone.')]},\n",
       "  'service': {'ADJ': [(('great',), 'service be great.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('phone',), 'service be phone.')]}},\n",
       " {},\n",
       " {'store': {'ADJ': [(('organize',), 'store is organized.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'phone': {'ADJ': [],\n",
       "   'VERB': [(('look',), 'phone looks new.')],\n",
       "   'OTHER': []}},\n",
       " {'staff': {'ADJ': [(('apologetic',), 'staff was not apologetic.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'price': {'ADJ': [(('high',), 'price are high.')], 'VERB': [], 'OTHER': []},\n",
       "  'selection': {'ADJ': [(('limited',), 'selection is limited.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'one': {'ADJ': [],\n",
       "   'VERB': [(('seem', 'be'), 'one seemed is poor.')],\n",
       "   'OTHER': []},\n",
       "  'service': {'ADJ': [(('poor',), 'service is poor.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'phone': {'ADJ': [(('defective',), 'phone was defective.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'staff': {'ADJ': [(('rude',), 'staff was rude.'),\n",
       "    (('unhelpful',), 'staff was unhelpful.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'staff': {'ADJ': [],\n",
       "   'VERB': [(('seem',), 'staff seemed.'),\n",
       "    (('give',), 'staff gave incorrect information about phone plan.')],\n",
       "   'OTHER': []},\n",
       "  'phone plan': {'ADJ': [],\n",
       "   'VERB': [(('give',), 'staff gave incorrect information about phone plan.')],\n",
       "   'OTHER': []}},\n",
       " {'warranty': {'ADJ': [(('useless',), 'warranty is useless.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'repair': {'ADJ': [],\n",
       "   'VERB': [(('do',), 'repair was done poorly.')],\n",
       "   'OTHER': []},\n",
       "  'phone': {'ADJ': [],\n",
       "   'VERB': [(('break',), 'phone broke again.'),\n",
       "    (('break',), 'phone broke within week.')],\n",
       "   'OTHER': []}},\n",
       " {'service': {'ADJ': [(('slow',), 'service was slow.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'phone': {'ADJ': [],\n",
       "   'VERB': [(('work',), 'phone was working after repair.')],\n",
       "   'OTHER': []}},\n",
       " {'same issue': {'ADJ': [],\n",
       "   'VERB': [(('have',), 'phone still has same issue after getting.')],\n",
       "   'OTHER': []},\n",
       "  'phone': {'ADJ': [],\n",
       "   'VERB': [(('have',), 'phone still has same issue after getting.')],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'staff': {'ADJ': [(('unprofessional',), 'staff was unprofessional.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'policy': {'ADJ': [(('awful',), 'policy is awful.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {'store': {'ADJ': [(('understaffed',), 'store was understaffed.'),\n",
       "    (('messy',), 'store was messy.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'warranty': {'ADJ': [],\n",
       "   'VERB': [(('expire',), 'warranty just expired.')],\n",
       "   'OTHER': []},\n",
       "  'phone': {'ADJ': [], 'VERB': [(('break',), 'phone broke.')], 'OTHER': []}},\n",
       " {},\n",
       " {'job': {'ADJ': [(('incomplete',), 'job was incomplete.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'representative': {'ADJ': [(('rude',),\n",
       "     'representative were rude on phone.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {},\n",
       " {},\n",
       " {'support': {'ADJ': [(('non',), 'support is non.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': []}},\n",
       " {'return window': {'ADJ': [],\n",
       "   'VERB': [(('stop', 'work'),\n",
       "     'phone stopped working outside return window.')],\n",
       "   'OTHER': []},\n",
       "  'phone': {'ADJ': [],\n",
       "   'VERB': [(('stop', 'work'), 'phone stopped working outside return window.'),\n",
       "    (('stop',), 'phone stopped quality.')],\n",
       "   'OTHER': []}},\n",
       " {'store': {'ADJ': [(('chaotic',), 'store was chaotic.')],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('staff',), 'store was with unhelpful staff.'),\n",
       "    (('lines',), 'store was with long lines.')]},\n",
       "  'staff': {'ADJ': [],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('staff',), 'store was with unhelpful staff.')]},\n",
       "  'long lines': {'ADJ': [],\n",
       "   'VERB': [],\n",
       "   'OTHER': [(('lines',), 'store was with long lines.')]}},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'technician': {'ADJ': [],\n",
       "   'VERB': [(('damage',), 'technician damaged during repair.'),\n",
       "    (('damage',), 'technician damaged phone.')],\n",
       "   'OTHER': []}},\n",
       " {}]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aspect extraction rules\n",
    "\n",
    "def find_matched_patterns(input_string, patterns):\n",
    "    # Create a regex pattern by joining the list of patterns using the '|' (OR) operator\n",
    "    regex_pattern = '|'.join(map(re.escape, patterns))\n",
    "    \n",
    "    # Use re.findall to find all matches in the input string\n",
    "    matches = re.findall(regex_pattern, input_string)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def process_aspect_rules(data, id):\n",
    "    subject_pronouns = ['i', 'you', 'he', 'she', 'it', 'we', 'they', 'this', 'that', 'these', 'those']\n",
    "    \n",
    "    # Data is converted into flatten\n",
    "    data = flatten_data(data)\n",
    "    # Get text and subject of data\n",
    "    if len(data) > 0:\n",
    "        text, subjects, keywords, labels = zip(*[(item[0] + ' ' + item[1] + '.', item[0], item[2], item[3]) for item in data])\n",
    "    else: \n",
    "        text, subjects, keywords, labels = ('', '', '', '')\n",
    "\n",
    "\n",
    "    \n",
    "    # Convert text into string    \n",
    "    doc = nlp('. '.join(text))\n",
    "\n",
    "    # Extract from rules ==> Weighted pattern extraction\n",
    "    result = get_raw_aspects(doc)\n",
    "    result = prunning_aspect(result, doc)\n",
    "    # Get aspects\n",
    "    aspects = list(result.keys())\n",
    "    # Weighted filter\n",
    "    aspects = weighted_filter_aspect(aspects, id, mapper_idf=mapper_1, mapper_tfidf=mapper_2)\n",
    "\n",
    "    # update_storage = {}\n",
    "    storage = {}\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        s, t, k, l = subjects[i].lower(), text[i], keywords[i], labels[i]\n",
    "        \n",
    "        # If subject is pron continue\n",
    "        if s in subject_pronouns:\n",
    "            continue\n",
    "        \n",
    "        # Get matched aspects and Filtering\n",
    "        matched = []\n",
    "        if len(aspects) > 0:\n",
    "            matched += find_matched_patterns(t, aspects)\n",
    "            matched = [a for a in matched if not word_exists(s, a)]\n",
    "        matched.append(s)\n",
    "            \n",
    "        # Storing\n",
    "        for a in matched:\n",
    "            # storage[a] = temp\n",
    "            if not storage.get(a):\n",
    "                storage[a] = {'ADJ': [],\n",
    "                              'VERB': [],\n",
    "                              'OTHER': [],}\n",
    "                storage[a][l].append((k, t))\n",
    "            else:\n",
    "                storage[a][l].append((k, t))\n",
    "                    \n",
    "    return storage\n",
    "\n",
    "aspects = [process_aspect_rules(data, id) for id, data in enumerate(df_ability.values)]\n",
    "\n",
    "print(len(aspects))\n",
    "aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "89182656-1a06-44a9-aca5-acd3e861d144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       99 non-null     int64 \n",
      " 1   review   99 non-null     object\n",
      " 2   date     99 non-null     object\n",
      " 3   aspects  99 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The staff were incredibly helpful and patient,...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'staff': {'ADJ': [(('helpful',), 'staff were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I had a great experience purchasing my phone h...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'process': {'ADJ': [(('quick',), 'process was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Their selection of phones is amazing, and the ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'selection': {'ADJ': [(('amazing',), 'selecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I appreciate how the staff walked me through s...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great customer service, I left with the phone ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'question': {'ADJ': [], 'VERB': [(('answer',)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review        date  \\\n",
       "0   1  The staff were incredibly helpful and patient,...  2024-11-01   \n",
       "1   2  I had a great experience purchasing my phone h...  2024-11-01   \n",
       "2   3  Their selection of phones is amazing, and the ...  2024-11-01   \n",
       "3   4  I appreciate how the staff walked me through s...  2024-11-01   \n",
       "4   5  Great customer service, I left with the phone ...  2024-11-01   \n",
       "\n",
       "                                             aspects  \n",
       "0  {'staff': {'ADJ': [(('helpful',), 'staff were ...  \n",
       "1  {'process': {'ADJ': [(('quick',), 'process was...  \n",
       "2  {'selection': {'ADJ': [(('amazing',), 'selecti...  \n",
       "3                                                 {}  \n",
       "4  {'question': {'ADJ': [], 'VERB': [(('answer',)...  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.copy()\n",
    "df_test['aspects'] = aspects\n",
    "\n",
    "print(df_test.info())\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2e92b293-6ae3-4dd5-9522-773194772c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I appreciate how the staff walked me through s...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>They offer amazing deals on phones, I couldn’t...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Upgrading my phone was a breeze thanks to thei...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>I got a really good trade-in deal on my old ph...</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Very professional and friendly service, I’m su...</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>They helped me choose a phone within my budget...</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>I found exactly what I needed, and they helped...</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>The phone I bought here is working perfectly, ...</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>They were super quick in setting up my phone, ...</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>Always come here for upgrades, they never disa...</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Best pricing for phone plans, they helped me s...</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>I always recommend this store to friends and f...</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>I appreciate how they were able to fix my phon...</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Got a great deal on my new phone and an awesom...</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>I had a great experience with their trade-in p...</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>They even helped me transfer all my contacts a...</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>They fixed my screen perfectly and even gave m...</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>This is my go-to store for any phone issues, a...</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>They offer fantastic promotions and discounts!</td>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>They resolved my issue very quickly and profes...</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>Highly recommend this store if you’re looking ...</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>I always leave this store feeling like I made ...</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>I received excellent advice from the sales tea...</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>Bought a phone here that stopped working withi...</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>They charged me extra for services I didn’t ne...</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>Phone repairs took way too long, I had to come...</td>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>I bought a phone, but they didn’t inform me of...</td>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>I had to return a faulty phone twice before th...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>Very disorganized, I waited forever just to ge...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>The phone I purchased here was overpriced comp...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>They refused to honor the promotion I came in ...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>I felt pressured to buy accessories I didn’t n...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>They upsold me on a phone plan I didn’t need, ...</td>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>They didn’t apply the discount I was promised.</td>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>They kept trying to sell me more expensive pho...</td>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>I had to call multiple times just to get a res...</td>\n",
       "      <td>2024-11-15</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>They didn’t explain anything clearly and rushe...</td>\n",
       "      <td>2024-11-15</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>They didn’t even have the phone I wanted in st...</td>\n",
       "      <td>2024-11-16</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>Terrible follow-up, they lost my repair order,...</td>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>I felt overcharged for a simple screen repair.</td>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Bought a refurbished phone that had several is...</td>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>I’m extremely disappointed, will not be coming...</td>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             review        date aspects\n",
       "3    4  I appreciate how the staff walked me through s...  2024-11-01      {}\n",
       "5    6  They offer amazing deals on phones, I couldn’t...  2024-11-01      {}\n",
       "9   10  Upgrading my phone was a breeze thanks to thei...  2024-11-01      {}\n",
       "16  17  I got a really good trade-in deal on my old ph...  2024-11-02      {}\n",
       "19  20  Very professional and friendly service, I’m su...  2024-11-02      {}\n",
       "22  23  They helped me choose a phone within my budget...  2024-11-03      {}\n",
       "27  28  I found exactly what I needed, and they helped...  2024-11-04      {}\n",
       "31  32  The phone I bought here is working perfectly, ...  2024-11-04      {}\n",
       "32  33  They were super quick in setting up my phone, ...  2024-11-04      {}\n",
       "33  34  Always come here for upgrades, they never disa...  2024-11-04      {}\n",
       "35  36  Best pricing for phone plans, they helped me s...  2024-11-05      {}\n",
       "38  39  I always recommend this store to friends and f...  2024-11-06      {}\n",
       "42  43  I appreciate how they were able to fix my phon...  2024-11-06      {}\n",
       "43  44  Got a great deal on my new phone and an awesom...  2024-11-07      {}\n",
       "45  46  I had a great experience with their trade-in p...  2024-11-07      {}\n",
       "47  48  They even helped me transfer all my contacts a...  2024-11-08      {}\n",
       "49  50  They fixed my screen perfectly and even gave m...  2024-11-08      {}\n",
       "50  51  This is my go-to store for any phone issues, a...  2024-11-08      {}\n",
       "51  52     They offer fantastic promotions and discounts!  2024-11-09      {}\n",
       "53  54  They resolved my issue very quickly and profes...  2024-11-10      {}\n",
       "55  56  Highly recommend this store if you’re looking ...  2024-11-10      {}\n",
       "56  57  I always leave this store feeling like I made ...  2024-11-10      {}\n",
       "57  58  I received excellent advice from the sales tea...  2024-11-10      {}\n",
       "60  61  Bought a phone here that stopped working withi...  2024-11-10      {}\n",
       "65  66  They charged me extra for services I didn’t ne...  2024-11-11      {}\n",
       "66  67  Phone repairs took way too long, I had to come...  2024-11-12      {}\n",
       "67  68  I bought a phone, but they didn’t inform me of...  2024-11-12      {}\n",
       "70  71  I had to return a faulty phone twice before th...  2024-11-13      {}\n",
       "71  72  Very disorganized, I waited forever just to ge...  2024-11-13      {}\n",
       "72  73  The phone I purchased here was overpriced comp...  2024-11-13      {}\n",
       "73  74  They refused to honor the promotion I came in ...  2024-11-13      {}\n",
       "74  75  I felt pressured to buy accessories I didn’t n...  2024-11-13      {}\n",
       "79  80  They upsold me on a phone plan I didn’t need, ...  2024-11-14      {}\n",
       "82  83     They didn’t apply the discount I was promised.  2024-11-14      {}\n",
       "85  86  They kept trying to sell me more expensive pho...  2024-11-14      {}\n",
       "88  89  I had to call multiple times just to get a res...  2024-11-15      {}\n",
       "89  90  They didn’t explain anything clearly and rushe...  2024-11-15      {}\n",
       "93  94  They didn’t even have the phone I wanted in st...  2024-11-16      {}\n",
       "94  95  Terrible follow-up, they lost my repair order,...  2024-11-17      {}\n",
       "95  96     I felt overcharged for a simple screen repair.  2024-11-17      {}\n",
       "96  97  Bought a refurbished phone that had several is...  2024-11-17      {}\n",
       "98  99  I’m extremely disappointed, will not be coming...  2024-11-17      {}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom handling aspect\n",
    "\n",
    "fail = df_test[df_test.apply(lambda x: len(x['aspects']) == 0, axis=1)]\n",
    "print(len(fail))\n",
    "fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "08017eef-0f25-432a-ab69-4eb3dfd8c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aspect_rules(data, id):\n",
    "    subject_pronouns = ['i', 'you', 'he', 'she', 'it', 'we', 'they', 'this', 'that', 'these', 'those']\n",
    "    \n",
    "    # Data is converted into flatten\n",
    "    data = flatten_data(data)\n",
    "    # Get text and subject of data\n",
    "    if len(data) > 0:\n",
    "        text, subjects, keywords, labels = zip(*[(item[0] + ' ' + item[1] + '.', item[0], item[2], item[3]) for item in data])\n",
    "    else: \n",
    "        text, subjects, keywords, labels = ('', '', '', '')\n",
    "\n",
    "\n",
    "    \n",
    "    # Convert text into string    \n",
    "    doc = nlp('. '.join(text))\n",
    "\n",
    "    # Extract from rules ==> Weighted pattern extraction\n",
    "    result = get_raw_aspects(doc)\n",
    "    result = prunning_aspect(result, doc)\n",
    "    # Get aspects\n",
    "    aspects = list(result.keys())\n",
    "    # Weighted filter\n",
    "    aspects = weighted_filter_aspect(aspects, id, mapper_idf=mapper_1, mapper_tfidf=mapper_2)\n",
    "\n",
    "    # update_storage = {}\n",
    "    storage = {}\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        s, t, k, l = subjects[i].lower(), text[i], keywords[i], labels[i]\n",
    "        \n",
    "        # If subject is pron continue\n",
    "        if s in subject_pronouns:\n",
    "            continue\n",
    "        \n",
    "        # Get matched aspects and Filtering\n",
    "        matched = []\n",
    "        if len(aspects) > 0:\n",
    "            matched += find_matched_patterns(t, aspects)\n",
    "            matched = [a for a in matched if not word_exists(s, a)]\n",
    "        matched.append(s)\n",
    "            \n",
    "        # Storing\n",
    "        for a in matched:\n",
    "            # storage[a] = temp\n",
    "            if not storage.get(a):\n",
    "                storage[a] = {'ADJ': [],\n",
    "                              'VERB': [],\n",
    "                              'OTHER': [],}\n",
    "                storage[a][l].append((k, t))\n",
    "            else:\n",
    "                storage[a][l].append((k, t))\n",
    "                    \n",
    "    return storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "dc88137d-1761-455d-8f1a-6cccc8b111bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The staff were incredibly helpful and patient,...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'staff': {'ADJ': [(('helpful',), 'staff were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I had a great experience purchasing my phone h...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'process': {'ADJ': [(('quick',), 'process was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Their selection of phones is amazing, and the ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'selection': {'ADJ': [(('amazing',), 'selecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I appreciate how the staff walked me through s...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'staff': {'ADJ': [], 'VERB': [(('appreciate',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great customer service, I left with the phone ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{'question': {'ADJ': [], 'VERB': [(('answer',)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review        date  \\\n",
       "0   1  The staff were incredibly helpful and patient,...  2024-11-01   \n",
       "1   2  I had a great experience purchasing my phone h...  2024-11-01   \n",
       "2   3  Their selection of phones is amazing, and the ...  2024-11-01   \n",
       "3   4  I appreciate how the staff walked me through s...  2024-11-01   \n",
       "4   5  Great customer service, I left with the phone ...  2024-11-01   \n",
       "\n",
       "                                             aspects  \n",
       "0  {'staff': {'ADJ': [(('helpful',), 'staff were ...  \n",
       "1  {'process': {'ADJ': [(('quick',), 'process was...  \n",
       "2  {'selection': {'ADJ': [(('amazing',), 'selecti...  \n",
       "3  {'staff': {'ADJ': [], 'VERB': [(('appreciate',...  \n",
       "4  {'question': {'ADJ': [], 'VERB': [(('answer',)...  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FROM ANALYSIS PATTERN MANUAL: SOON NEED TO COREFERENCE RESOLUTION.\n",
    "\n",
    "# SET IT AS EMPTY STRING BY DEFAULT\n",
    "# def process_aspect_custom(text):\n",
    "#     return []\n",
    "    \n",
    "def process_aspect_custom(data):\n",
    "    # Data is converted into flatten\n",
    "    data = flatten_data(data)\n",
    "\n",
    "    # Get text and subject of data\n",
    "    if len(data) > 0:\n",
    "        text, subjects, keywords, labels = zip(*[(item[0] + ' ' + item[1] + '.', item[0], item[2], item[3]) for item in data])\n",
    "    else: \n",
    "        text, subjects, keywords, labels = ('', '', '', '')\n",
    "\n",
    "\n",
    "    storage = {}\n",
    "    for i in range(len(data)):\n",
    "        s, t, k, l = subjects[i].lower(), text[i], keywords[i], labels[i]\n",
    "\n",
    "        \n",
    "        if s in ['i', 'this']:\n",
    "            s = 'staff'\n",
    "            if not storage.get(s):\n",
    "                storage[s] = {'ADJ': [],\n",
    "                              'VERB': [],\n",
    "                              'OTHER': [],}\n",
    "                storage[s][l].append((k, t))\n",
    "            else:\n",
    "                storage[s][l].append((k, t))\n",
    "                \n",
    "        elif s in ['they', 'you']:\n",
    "            s = 'store'\n",
    "            if not storage.get(s):\n",
    "                storage[s] = {'ADJ': [],\n",
    "                              'VERB': [],\n",
    "                              'OTHER': [],}\n",
    "                storage[s][l].append((k, t))\n",
    "            else:\n",
    "                storage[s][l].append((k, t))                    \n",
    "    \n",
    "    return storage\n",
    "\n",
    "def process_aspect(data, id):\n",
    "    result = process_aspect_rules(data, id)\n",
    "    if len(result) == 0:\n",
    "        result = process_aspect_custom(data)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# aspects = [process_aspect(text, id) for id, text in enumerate(corpus)]\n",
    "aspects = [process_aspect(data, id) for id, data in enumerate(df_ability.values)]\n",
    "df_test['aspects'] = aspects\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "715d6f79-d109-43e5-81a4-aaa245ff4c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Upgrading my phone was a breeze thanks to thei...</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>The phone I bought here is working perfectly, ...</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>Always come here for upgrades, they never disa...</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Got a great deal on my new phone and an awesom...</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>Bought a phone here that stopped working withi...</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>The phone I purchased here was overpriced comp...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Bought a refurbished phone that had several is...</td>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>I’m extremely disappointed, will not be coming...</td>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             review        date aspects\n",
       "9   10  Upgrading my phone was a breeze thanks to thei...  2024-11-01      {}\n",
       "31  32  The phone I bought here is working perfectly, ...  2024-11-04      {}\n",
       "33  34  Always come here for upgrades, they never disa...  2024-11-04      {}\n",
       "43  44  Got a great deal on my new phone and an awesom...  2024-11-07      {}\n",
       "60  61  Bought a phone here that stopped working withi...  2024-11-10      {}\n",
       "72  73  The phone I purchased here was overpriced comp...  2024-11-13      {}\n",
       "96  97  Bought a refurbished phone that had several is...  2024-11-17      {}\n",
       "98  99  I’m extremely disappointed, will not be coming...  2024-11-17      {}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail = df_test[df_test.apply(lambda x: len(x['aspects']) == 0, axis=1)]\n",
    "print(len(fail))\n",
    "fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273bff6-8341-4d9f-bc14-874491dfe4a9",
   "metadata": {},
   "source": [
    "**Create Pipeline Meta-Data Aspect based Sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b5db18a6-0118-4cde-9840-5852745225c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 1,\n",
       "  'review': 'The staff were incredibly helpful and patient, helping me find the perfect phone!',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'staff': {'ADJ': [(('helpful',), 'staff were helpful.'),\n",
       "     (('patient',), 'staff were patient.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 1: {'id': 2,\n",
       "  'review': 'I had a great experience purchasing my phone here, the process was smooth and quick.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'process': {'ADJ': [(('quick',), 'process was quick.'),\n",
       "     (('smooth',), 'process was smooth.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 2: {'id': 3,\n",
       "  'review': 'Their selection of phones is amazing, and the prices are very competitive!',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'selection': {'ADJ': [(('amazing',), 'selection is amazing.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'price': {'ADJ': [(('competitive',), 'price are competitive.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 3: {'id': 4,\n",
       "  'review': 'I appreciate how the staff walked me through setting up my new device.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('appreciate', 'walk'), 'I appreciate walked me.'),\n",
       "     (('appreciate', 'walk'),\n",
       "      'I appreciate walked through setting new device.')],\n",
       "    'OTHER': []}}},\n",
       " 4: {'id': 5,\n",
       "  'review': 'Great customer service, I left with the phone I wanted and all my questions answered.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'question': {'ADJ': [],\n",
       "    'VERB': [(('answer',), 'question answered.')],\n",
       "    'OTHER': []}}},\n",
       " 5: {'id': 6,\n",
       "  'review': 'They offer amazing deals on phones, I couldn’t resist upgrading.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('resist', 'offer'),\n",
       "      'I could not resist offer amazing deals on phones.'),\n",
       "     (('resist',), 'I could not resist upgrading.')],\n",
       "    'OTHER': []}}},\n",
       " 6: {'id': 7,\n",
       "  'review': 'The technician fixed my phone’s issue faster than I expected. Highly recommend!',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'technician': {'ADJ': [],\n",
       "    'VERB': [(('fix',), 'technician fixed faster.'),\n",
       "     (('fix',), 'technician fixed phones issue.')],\n",
       "    'OTHER': []},\n",
       "   'phones issue': {'ADJ': [],\n",
       "    'VERB': [(('fix',), 'technician fixed phones issue.')],\n",
       "    'OTHER': []}}},\n",
       " 7: {'id': 8,\n",
       "  'review': 'Fantastic experience, the staff really know their stuff!',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'experience': {'ADJ': [],\n",
       "    'VERB': [(('know',), 'experience really know stuff.')],\n",
       "    'OTHER': []}}},\n",
       " 8: {'id': 9,\n",
       "  'review': 'I found the perfect phone case here, and the variety was impressive.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'variety': {'ADJ': [(('impressive',), 'variety was impressive.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 9: {'id': 10,\n",
       "  'review': 'Upgrading my phone was a breeze thanks to their professional service.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {}},\n",
       " 10: {'id': 11,\n",
       "  'review': 'Staff was knowledgeable and made sure I knew everything about my new phone.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'staff': {'ADJ': [(('knowledgeable',),\n",
       "      'staff was knowledgeable.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 11: {'id': 12,\n",
       "  'review': 'Prices were reasonable and the staff very courteous!',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'price': {'ADJ': [(('reasonable',), 'price were reasonable.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 12: {'id': 13,\n",
       "  'review': 'Very happy with my purchase, the staff really went the extra mile.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('go',), 'staff really went mile.')],\n",
       "    'OTHER': []}}},\n",
       " 13: {'id': 14,\n",
       "  'review': 'Excellent service! They helped me find exactly what I was looking for.',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'service': {'ADJ': [(('excellent',), 'service be excellent.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 14: {'id': 15,\n",
       "  'review': 'Great deals on accessories, and the staff was super friendly!',\n",
       "  'date': '2024-11-01',\n",
       "  'aspect': {'deal': {'ADJ': [(('friendly',), 'deal was friendly.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'staff': {'ADJ': [(('friendly',), 'staff was friendly.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 15: {'id': 16,\n",
       "  'review': 'I love this store! Always a smooth experience buying or fixing my phone.',\n",
       "  'date': '2024-11-02',\n",
       "  'aspect': {'buying': {'ADJ': [],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('experience',), 'buying be experience.')]},\n",
       "   'fixing': {'ADJ': [],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('experience',), 'fixing be experience.')]}}},\n",
       " 16: {'id': 17,\n",
       "  'review': 'I got a really good trade-in deal on my old phone.',\n",
       "  'date': '2024-11-02',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('get',), 'I got good deal on old phone.')],\n",
       "    'OTHER': []}}},\n",
       " 17: {'id': 18,\n",
       "  'review': 'Their repair services are quick and reliable.',\n",
       "  'date': '2024-11-02',\n",
       "  'aspect': {'service': {'ADJ': [(('quick',), 'service are quick.'),\n",
       "     (('reliable',), 'service are reliable.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 18: {'id': 19,\n",
       "  'review': 'The staff was extremely helpful in setting up my phone and transferring all my data.',\n",
       "  'date': '2024-11-02',\n",
       "  'aspect': {'phone': {'ADJ': [(('helpful',),\n",
       "      'staff was helpful in setting phone.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'staff': {'ADJ': [(('helpful',), 'staff was helpful in setting phone.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 19: {'id': 20,\n",
       "  'review': 'Very professional and friendly service, I’m super satisfied!',\n",
       "  'date': '2024-11-02',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('m',), 'I m satisfied.')],\n",
       "    'OTHER': []}}},\n",
       " 20: {'id': 21,\n",
       "  'review': 'Great variety of phones, and the staff was very patient with my questions.',\n",
       "  'date': '2024-11-03',\n",
       "  'aspect': {'staff': {'ADJ': [(('patient',),\n",
       "      'staff was patient with questions.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'variety': {'ADJ': [(('patient',), 'variety was patient with questions.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 21: {'id': 22,\n",
       "  'review': 'The process was super simple, and I’m thrilled with my new phone.',\n",
       "  'date': '2024-11-03',\n",
       "  'aspect': {'process': {'ADJ': [(('simple',), 'process was simple.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 22: {'id': 23,\n",
       "  'review': 'They helped me choose a phone within my budget, which I really appreciated.',\n",
       "  'date': '2024-11-03',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('help', 'choose'), 'they helped choose within budget.'),\n",
       "     (('help', 'choose'), 'they helped choose phone.')],\n",
       "    'OTHER': []}}},\n",
       " 23: {'id': 24,\n",
       "  'review': 'My phone was fixed in less than 30 minutes, such fast service!',\n",
       "  'date': '2024-11-03',\n",
       "  'aspect': {'phone': {'ADJ': [],\n",
       "    'VERB': [(('fix',), 'phone was fixed in minutes.')],\n",
       "    'OTHER': []}}},\n",
       " 24: {'id': 25,\n",
       "  'review': 'I’m a loyal customer because their customer service is always outstanding.',\n",
       "  'date': '2024-11-03',\n",
       "  'aspect': {'service': {'ADJ': [(('outstanding',),\n",
       "      'service is outstanding.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 25: {'id': 26,\n",
       "  'review': 'Best phone store in town, hands down!',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('hand',), 'store hands.')],\n",
       "    'OTHER': []}}},\n",
       " 26: {'id': 27,\n",
       "  'review': 'The staff made sure I was completely comfortable with my purchase.',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('make',), 'staff made.')],\n",
       "    'OTHER': []}}},\n",
       " 27: {'id': 28,\n",
       "  'review': 'I found exactly what I needed, and they helped me get a great deal.',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('find', 'need'), 'I found needed what.')],\n",
       "    'OTHER': []},\n",
       "   'store': {'ADJ': [],\n",
       "    'VERB': [(('help', 'get'), 'they helped get great deal.')],\n",
       "    'OTHER': []}}},\n",
       " 28: {'id': 29,\n",
       "  'review': 'This store has a fantastic warranty service!',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {'warranty service': {'ADJ': [],\n",
       "    'VERB': [(('have',), 'store has fantastic warranty service.')],\n",
       "    'OTHER': []},\n",
       "   'store': {'ADJ': [],\n",
       "    'VERB': [(('have',), 'store has fantastic warranty service.')],\n",
       "    'OTHER': []}}},\n",
       " 29: {'id': 30,\n",
       "  'review': 'The staff was very informative, I learned a lot about phone features I didn’t know about.',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {'staff': {'ADJ': [(('informative',), 'staff was informative.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 30: {'id': 31,\n",
       "  'review': 'Excellent store for buying phone accessories, so much variety!',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {'variety': {'ADJ': [(('excellent',), 'variety be excellent.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'store': {'ADJ': [(('excellent',), 'store be excellent.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 31: {'id': 32,\n",
       "  'review': 'The phone I bought here is working perfectly, couldn’t be happier.',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {}},\n",
       " 32: {'id': 33,\n",
       "  'review': 'They were super quick in setting up my phone, I was out of there in no time.',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {'store': {'ADJ': [(('quick',),\n",
       "      'they were quick in setting phone.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 33: {'id': 34,\n",
       "  'review': 'Always come here for upgrades, they never disappoint!',\n",
       "  'date': '2024-11-04',\n",
       "  'aspect': {}},\n",
       " 34: {'id': 35,\n",
       "  'review': 'The store layout is easy to navigate and staff are always ready to help.',\n",
       "  'date': '2024-11-05',\n",
       "  'aspect': {'layout': {'ADJ': [(('easy',), 'layout is easy.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'staff': {'ADJ': [(('ready',), 'staff are ready.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 35: {'id': 36,\n",
       "  'review': 'Best pricing for phone plans, they helped me save a lot!',\n",
       "  'date': '2024-11-05',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('help', 'save'), 'they helped save lot.')],\n",
       "    'OTHER': []}}},\n",
       " 36: {'id': 37,\n",
       "  'review': 'I’ve been to many phone stores, but this one by far provides the best service.',\n",
       "  'date': '2024-11-05',\n",
       "  'aspect': {'service': {'ADJ': [],\n",
       "    'VERB': [(('provide',), 'one provides best service.')],\n",
       "    'OTHER': []},\n",
       "   'one': {'ADJ': [],\n",
       "    'VERB': [(('provide',), 'one provides best service.')],\n",
       "    'OTHER': []}}},\n",
       " 37: {'id': 38,\n",
       "  'review': 'Customer service here is top-notch, they always resolve my issues quickly.',\n",
       "  'date': '2024-11-05',\n",
       "  'aspect': {'service': {'ADJ': [(('notch',), 'service is notch.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('notch',), 'service is notch.')]}}},\n",
       " 38: {'id': 39,\n",
       "  'review': 'I always recommend this store to friends and family, they never fail to impress.',\n",
       "  'date': '2024-11-06',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('fail', 'recommend'), 'they not fail recommend to family.'),\n",
       "     (('fail', 'recommend'), 'they not fail recommend store.'),\n",
       "     (('fail', 'recommend'), 'they not fail recommend to friends.')],\n",
       "    'OTHER': []}}},\n",
       " 39: {'id': 40,\n",
       "  'review': 'The staff took the time to show me all my options, no pressure sales.',\n",
       "  'date': '2024-11-06',\n",
       "  'aspect': {'time': {'ADJ': [],\n",
       "    'VERB': [(('take',), 'staff took time.')],\n",
       "    'OTHER': []},\n",
       "   'staff': {'ADJ': [],\n",
       "    'VERB': [(('take',), 'staff took time.')],\n",
       "    'OTHER': []}}},\n",
       " 40: {'id': 41,\n",
       "  'review': 'Amazing place to buy the latest phones at great prices!',\n",
       "  'date': '2024-11-06',\n",
       "  'aspect': {'place': {'ADJ': [(('amazing',), 'place be amazing.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 41: {'id': 42,\n",
       "  'review': 'Their warranty plan is worth every penny, such a relief!',\n",
       "  'date': '2024-11-06',\n",
       "  'aspect': {'plan': {'ADJ': [(('worth',), 'plan is worth.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 42: {'id': 43,\n",
       "  'review': 'I appreciate how they were able to fix my phone on the same day.',\n",
       "  'date': '2024-11-06',\n",
       "  'aspect': {'store': {'ADJ': [(('able',), 'they were able.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'staff': {'ADJ': [],\n",
       "    'VERB': [(('appreciate', 'be'), 'I appreciate were able.')],\n",
       "    'OTHER': []}}},\n",
       " 43: {'id': 44,\n",
       "  'review': 'Got a great deal on my new phone and an awesome case as well!',\n",
       "  'date': '2024-11-07',\n",
       "  'aspect': {}},\n",
       " 44: {'id': 45,\n",
       "  'review': 'The staff was very accommodating when I had questions about phone features.',\n",
       "  'date': '2024-11-07',\n",
       "  'aspect': {'staff': {'ADJ': [(('accommodating',),\n",
       "      'staff was accommodating.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 45: {'id': 46,\n",
       "  'review': 'I had a great experience with their trade-in program.',\n",
       "  'date': '2024-11-07',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('have',), 'I had great experience with program.')],\n",
       "    'OTHER': []}}},\n",
       " 46: {'id': 47,\n",
       "  'review': 'Service was quick and efficient, I was in and out within 15 minutes!',\n",
       "  'date': '2024-11-07',\n",
       "  'aspect': {'service': {'ADJ': [(('quick',), 'service was quick.'),\n",
       "     (('efficient',), 'service was efficient.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 47: {'id': 48,\n",
       "  'review': 'They even helped me transfer all my contacts and data without extra charge.',\n",
       "  'date': '2024-11-08',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('help', 'transfer'), 'they even helped transfer contacts.'),\n",
       "     (('help', 'transfer'), 'they even helped transfer without extra charge.'),\n",
       "     (('help', 'transfer'), 'they even helped transfer data.')],\n",
       "    'OTHER': []}}},\n",
       " 48: {'id': 49,\n",
       "  'review': 'My phone has been working flawlessly since I bought it from here.',\n",
       "  'date': '2024-11-08',\n",
       "  'aspect': {'phone': {'ADJ': [],\n",
       "    'VERB': [(('work',), 'phone has working flawlessly.')],\n",
       "    'OTHER': []}}},\n",
       " 49: {'id': 50,\n",
       "  'review': 'They fixed my screen perfectly and even gave me a discount on the repair.',\n",
       "  'date': '2024-11-08',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('give',), 'they even gave discount on repair.'),\n",
       "     (('fix',), 'they fixed perfectly.'),\n",
       "     (('fix',), 'they fixed screen.')],\n",
       "    'OTHER': []}}},\n",
       " 50: {'id': 51,\n",
       "  'review': 'This is my go-to store for any phone issues, always reliable.',\n",
       "  'date': '2024-11-08',\n",
       "  'aspect': {'staff': {'ADJ': [(('reliable',), 'this is reliable.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 51: {'id': 52,\n",
       "  'review': 'They offer fantastic promotions and discounts!',\n",
       "  'date': '2024-11-09',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('offer',), 'they offer fantastic promotions.'),\n",
       "     (('offer',), 'they offer discounts.')],\n",
       "    'OTHER': []}}},\n",
       " 52: {'id': 53,\n",
       "  'review': 'Great phone selection and even better customer service.',\n",
       "  'date': '2024-11-09',\n",
       "  'aspect': {'selection': {'ADJ': [(('great',), 'selection be great.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('phone',), 'selection be phone.')]},\n",
       "   'service': {'ADJ': [(('great',), 'service be great.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('phone',), 'service be phone.')]}}},\n",
       " 53: {'id': 54,\n",
       "  'review': 'They resolved my issue very quickly and professionally.',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('resolve',), 'they resolved professionally.'),\n",
       "     (('resolve',), 'they resolved very quickly.'),\n",
       "     (('resolve',), 'they resolved issue.')],\n",
       "    'OTHER': []}}},\n",
       " 54: {'id': 55,\n",
       "  'review': 'I love how organized the store is and how fast they attend to customers.',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {'store': {'ADJ': [(('organize',), 'store is organized.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 55: {'id': 56,\n",
       "  'review': 'Highly recommend this store if you’re looking for good deals on phones!',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('look',), 'you re looking for good deals.')],\n",
       "    'OTHER': []}}},\n",
       " 56: {'id': 57,\n",
       "  'review': 'I always leave this store feeling like I made the right purchase.',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('leave',), 'I always leave store.'),\n",
       "     (('make',), 'I made right purchase.')],\n",
       "    'OTHER': []}}},\n",
       " 57: {'id': 58,\n",
       "  'review': 'I received excellent advice from the sales team, they really know their products.',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('know', 'receive'),\n",
       "      'they really know received excellent advice from sales team.'),\n",
       "     (('know',), 'they really know products.')],\n",
       "    'OTHER': []}}},\n",
       " 58: {'id': 59,\n",
       "  'review': 'Very happy with the repair service here, my phone looks brand new!',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {'phone': {'ADJ': [],\n",
       "    'VERB': [(('look',), 'phone looks new.')],\n",
       "    'OTHER': []}}},\n",
       " 59: {'id': 60,\n",
       "  'review': 'I had to wait over an hour to be helped, and the staff wasn’t apologetic at all.',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {'staff': {'ADJ': [(('apologetic',), 'staff was not apologetic.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 60: {'id': 61,\n",
       "  'review': 'Bought a phone here that stopped working within a week, very disappointing.',\n",
       "  'date': '2024-11-10',\n",
       "  'aspect': {}},\n",
       " 61: {'id': 62,\n",
       "  'review': 'Their prices are too high, and the selection is limited.',\n",
       "  'date': '2024-11-11',\n",
       "  'aspect': {'price': {'ADJ': [(('high',), 'price are high.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []},\n",
       "   'selection': {'ADJ': [(('limited',), 'selection is limited.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 62: {'id': 63,\n",
       "  'review': 'Customer service is poor, no one seemed interested in helping me.',\n",
       "  'date': '2024-11-11',\n",
       "  'aspect': {'one': {'ADJ': [],\n",
       "    'VERB': [(('seem', 'be'), 'one seemed is poor.')],\n",
       "    'OTHER': []},\n",
       "   'service': {'ADJ': [(('poor',), 'service is poor.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 63: {'id': 64,\n",
       "  'review': 'I had a terrible experience, the phone they sold me was defective.',\n",
       "  'date': '2024-11-11',\n",
       "  'aspect': {'phone': {'ADJ': [(('defective',), 'phone was defective.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 64: {'id': 65,\n",
       "  'review': 'The staff was rude and unhelpful, I’m never coming back.',\n",
       "  'date': '2024-11-11',\n",
       "  'aspect': {'staff': {'ADJ': [(('rude',), 'staff was rude.'),\n",
       "     (('unhelpful',), 'staff was unhelpful.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 65: {'id': 66,\n",
       "  'review': 'They charged me extra for services I didn’t need, felt like a scam.',\n",
       "  'date': '2024-11-11',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('charge',), 'they charged me.'),\n",
       "     (('feel',), 'they felt like scam.'),\n",
       "     (('charge',), 'they charged extra for services.')],\n",
       "    'OTHER': []}}},\n",
       " 66: {'id': 67,\n",
       "  'review': 'Phone repairs took way too long, I had to come back multiple times.',\n",
       "  'date': '2024-11-12',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('have', 'take'), 'I had took too long.'),\n",
       "     (('have', 'take'), 'I had took way.')],\n",
       "    'OTHER': []}}},\n",
       " 67: {'id': 68,\n",
       "  'review': 'I bought a phone, but they didn’t inform me of all the hidden fees.',\n",
       "  'date': '2024-11-12',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('inform',), 'they did not inform me.'),\n",
       "     (('inform',), 'they did not inform of hidden fees.')],\n",
       "    'OTHER': []},\n",
       "   'staff': {'ADJ': [],\n",
       "    'VERB': [(('buy',), 'I bought phone.')],\n",
       "    'OTHER': []}}},\n",
       " 68: {'id': 69,\n",
       "  'review': 'Staff seemed untrained and gave me incorrect information about the phone plan.',\n",
       "  'date': '2024-11-12',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('seem',), 'staff seemed.'),\n",
       "     (('give',), 'staff gave incorrect information about phone plan.')],\n",
       "    'OTHER': []},\n",
       "   'phone plan': {'ADJ': [],\n",
       "    'VERB': [(('give',),\n",
       "      'staff gave incorrect information about phone plan.')],\n",
       "    'OTHER': []}}},\n",
       " 69: {'id': 70,\n",
       "  'review': 'Their warranty is useless, they refused to fix my phone under it.',\n",
       "  'date': '2024-11-12',\n",
       "  'aspect': {'warranty': {'ADJ': [(('useless',), 'warranty is useless.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 70: {'id': 71,\n",
       "  'review': 'I had to return a faulty phone twice before they finally gave me a refund.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('give',), 'they twice gave refund.')],\n",
       "    'OTHER': []},\n",
       "   'staff': {'ADJ': [],\n",
       "    'VERB': [(('have', 'return'), 'I had to return faulty phone.')],\n",
       "    'OTHER': []}}},\n",
       " 71: {'id': 72,\n",
       "  'review': 'Very disorganized, I waited forever just to get a simple issue resolved.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('wait',), 'I very disorganized waited forever.')],\n",
       "    'OTHER': []}}},\n",
       " 72: {'id': 73,\n",
       "  'review': 'The phone I purchased here was overpriced compared to other stores.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {}},\n",
       " 73: {'id': 74,\n",
       "  'review': 'They refused to honor the promotion I came in for, very misleading.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('refuse', 'honor'), 'they refused to honor promotion.')],\n",
       "    'OTHER': []}}},\n",
       " 74: {'id': 75,\n",
       "  'review': 'I felt pressured to buy accessories I didn’t need.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('feel',), 'I felt pressured.')],\n",
       "    'OTHER': []}}},\n",
       " 75: {'id': 76,\n",
       "  'review': 'The repair was done poorly, and my phone broke again within a week.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {'repair': {'ADJ': [],\n",
       "    'VERB': [(('do',), 'repair was done poorly.')],\n",
       "    'OTHER': []},\n",
       "   'phone': {'ADJ': [],\n",
       "    'VERB': [(('break',), 'phone broke again.'),\n",
       "     (('break',), 'phone broke within week.')],\n",
       "    'OTHER': []}}},\n",
       " 76: {'id': 77,\n",
       "  'review': 'Customer service was extremely slow, they need to hire more staff.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {'service': {'ADJ': [(('slow',), 'service was slow.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 77: {'id': 78,\n",
       "  'review': 'They didn’t even check if my phone was working after the repair.',\n",
       "  'date': '2024-11-13',\n",
       "  'aspect': {'phone': {'ADJ': [],\n",
       "    'VERB': [(('work',), 'phone was working after repair.')],\n",
       "    'OTHER': []}}},\n",
       " 78: {'id': 79,\n",
       "  'review': \"Terrible experience, my phone still has the same issue after getting it 'fixed'.\",\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'same issue': {'ADJ': [],\n",
       "    'VERB': [(('have',), 'phone still has same issue after getting.')],\n",
       "    'OTHER': []},\n",
       "   'phone': {'ADJ': [],\n",
       "    'VERB': [(('have',), 'phone still has same issue after getting.')],\n",
       "    'OTHER': []}}},\n",
       " 79: {'id': 80,\n",
       "  'review': 'They upsold me on a phone plan I didn’t need, very deceptive.',\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('upsold',), 'they upsold on phone plan.'),\n",
       "     (('upsold',), 'they upsold me.')],\n",
       "    'OTHER': []}}},\n",
       " 80: {'id': 81,\n",
       "  'review': 'The staff was unprofessional and seemed like they didn’t want to be there.',\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'staff': {'ADJ': [(('unprofessional',),\n",
       "      'staff was unprofessional.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 81: {'id': 82,\n",
       "  'review': 'Their return policy is awful, I couldn’t exchange my phone despite its defects.',\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'policy': {'ADJ': [(('awful',), 'policy is awful.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 82: {'id': 83,\n",
       "  'review': 'They didn’t apply the discount I was promised.',\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('apply',), 'they did not apply discount.')],\n",
       "    'OTHER': []}}},\n",
       " 83: {'id': 84,\n",
       "  'review': 'The store was messy and understaffed.',\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'store': {'ADJ': [(('understaffed',), 'store was understaffed.'),\n",
       "     (('messy',), 'store was messy.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 84: {'id': 85,\n",
       "  'review': 'My phone broke down just after the warranty expired, very frustrating.',\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'warranty': {'ADJ': [],\n",
       "    'VERB': [(('expire',), 'warranty just expired.')],\n",
       "    'OTHER': []},\n",
       "   'phone': {'ADJ': [], 'VERB': [(('break',), 'phone broke.')], 'OTHER': []}}},\n",
       " 85: {'id': 86,\n",
       "  'review': 'They kept trying to sell me more expensive phones when I clearly stated my budget.',\n",
       "  'date': '2024-11-14',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('keep', 'try'), 'they kept trying.')],\n",
       "    'OTHER': []}}},\n",
       " 86: {'id': 87,\n",
       "  'review': 'The repair job was incomplete, and they refused to refund me.',\n",
       "  'date': '2024-11-15',\n",
       "  'aspect': {'job': {'ADJ': [(('incomplete',), 'job was incomplete.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 87: {'id': 88,\n",
       "  'review': 'Their customer service representatives were extremely rude on the phone.',\n",
       "  'date': '2024-11-15',\n",
       "  'aspect': {'representative': {'ADJ': [(('rude',),\n",
       "      'representative were rude on phone.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 88: {'id': 89,\n",
       "  'review': 'I had to call multiple times just to get a response, very unprofessional.',\n",
       "  'date': '2024-11-15',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('have', 'call'), 'I had to call multiple times.')],\n",
       "    'OTHER': []}}},\n",
       " 89: {'id': 90,\n",
       "  'review': 'They didn’t explain anything clearly and rushed me through the purchase.',\n",
       "  'date': '2024-11-15',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('explain',), 'they did not explain anything.'),\n",
       "     (('rush',), 'they rushed me.'),\n",
       "     (('rush',), 'they rushed through purchase.'),\n",
       "     (('explain',), 'they did not explain clearly.')],\n",
       "    'OTHER': []}}},\n",
       " 90: {'id': 91,\n",
       "  'review': 'I regret buying from here, their post-purchase support is non-existent.',\n",
       "  'date': '2024-11-15',\n",
       "  'aspect': {'support': {'ADJ': [(('non',), 'support is non.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': []}}},\n",
       " 91: {'id': 92,\n",
       "  'review': 'Phone stopped working just outside the return window, terrible quality.',\n",
       "  'date': '2024-11-16',\n",
       "  'aspect': {'return window': {'ADJ': [],\n",
       "    'VERB': [(('stop', 'work'),\n",
       "      'phone stopped working outside return window.')],\n",
       "    'OTHER': []},\n",
       "   'phone': {'ADJ': [],\n",
       "    'VERB': [(('stop', 'work'),\n",
       "      'phone stopped working outside return window.'),\n",
       "     (('stop',), 'phone stopped quality.')],\n",
       "    'OTHER': []}}},\n",
       " 92: {'id': 93,\n",
       "  'review': 'The store was chaotic, with long lines and unhelpful staff.',\n",
       "  'date': '2024-11-16',\n",
       "  'aspect': {'store': {'ADJ': [(('chaotic',), 'store was chaotic.')],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('staff',), 'store was with unhelpful staff.'),\n",
       "     (('lines',), 'store was with long lines.')]},\n",
       "   'staff': {'ADJ': [],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('staff',), 'store was with unhelpful staff.')]},\n",
       "   'long lines': {'ADJ': [],\n",
       "    'VERB': [],\n",
       "    'OTHER': [(('lines',), 'store was with long lines.')]}}},\n",
       " 93: {'id': 94,\n",
       "  'review': 'They didn’t even have the phone I wanted in stock after promising me it was available.',\n",
       "  'date': '2024-11-16',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('have',), 'they did not even have after promising me.'),\n",
       "     (('have',), 'they did not even have phone.')],\n",
       "    'OTHER': []}}},\n",
       " 94: {'id': 95,\n",
       "  'review': 'Terrible follow-up, they lost my repair order, and I had to start over.',\n",
       "  'date': '2024-11-17',\n",
       "  'aspect': {'store': {'ADJ': [],\n",
       "    'VERB': [(('lose',), 'they lost repair order.')],\n",
       "    'OTHER': []}}},\n",
       " 95: {'id': 96,\n",
       "  'review': 'I felt overcharged for a simple screen repair.',\n",
       "  'date': '2024-11-17',\n",
       "  'aspect': {'staff': {'ADJ': [],\n",
       "    'VERB': [(('feel',), 'I felt overcharged.')],\n",
       "    'OTHER': []}}},\n",
       " 96: {'id': 97,\n",
       "  'review': 'Bought a refurbished phone that had several issues they didn’t disclose.',\n",
       "  'date': '2024-11-17',\n",
       "  'aspect': {}},\n",
       " 97: {'id': 98,\n",
       "  'review': 'The technician damaged my phone during the repair, and they didn’t take responsibility.',\n",
       "  'date': '2024-11-17',\n",
       "  'aspect': {'technician': {'ADJ': [],\n",
       "    'VERB': [(('damage',), 'technician damaged during repair.'),\n",
       "     (('damage',), 'technician damaged phone.')],\n",
       "    'OTHER': []}}},\n",
       " 98: {'id': 99,\n",
       "  'review': 'I’m extremely disappointed, will not be coming back here again.',\n",
       "  'date': '2024-11-17',\n",
       "  'aspect': {}}}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate code\n",
    "\n",
    "def pipeline_meta_data(input_, data=data_json):\n",
    "    updated_data = data.copy()\n",
    "    # result = {}\n",
    "    for id, data in enumerate(input_):\n",
    "        temp = {}\n",
    "        items = process_aspect(data, id)\n",
    "        if len(items) > 0:\n",
    "            for aspect, data in items.items():\n",
    "                if not temp.get(aspect):\n",
    "                    temp[aspect] = data\n",
    "                else:\n",
    "                    temp[aspect] += data\n",
    "        # result['aspect'] = temp\n",
    "        updated_data[id].update({'aspect': temp})\n",
    "        \n",
    "    return updated_data\n",
    "\n",
    "\n",
    "meta_data = pipeline_meta_data(df_ability.values)\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ee0ae1b8-4b4b-417a-ae72-fb0f32a8b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary to a JSON file\n",
    "with open('data-1.json', 'w') as json_file:\n",
    "    json.dump(meta_data, json_file, indent=4)  # 'indent=4' makes the JSON pretty-printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8475d9-6105-482f-bc59-653576a0ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(\"example.xlsx\", index=False)\n",
    "# df.to_csv(\"example.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
