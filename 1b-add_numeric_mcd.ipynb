{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "0b5dc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('./util/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "1ae6d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "caa37d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.normalization as norm\n",
    "import util.model as models\n",
    "import util.utility as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bc56e",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "6505b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open(\"./mcd_result/map_second_mcd.json\") as json_file:\n",
    "    map_second_keys = json.load(json_file)\n",
    "\n",
    "with open(\"./mcd_result/map_category_mcd.json\") as json_file:\n",
    "    map_category = json.load(json_file)\n",
    "\n",
    "with open(\"./mcd_result/list_first_cycle_mcd.json\") as json_file:\n",
    "    list_first_cycle = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "523591c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open residu\n",
    "\n",
    "# df_residu = pd.read_csv(\"./mcd_result/residu_mcd.csv\").fillna(\"\")\n",
    "# print(df_residu.info())\n",
    "# df_residu['residu'] = df_residu['residu'].apply(lambda x: str(x).split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "2fd9eab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './mcd_result/base_mcd_v1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[671], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_base \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mcd_result/base_mcd_v1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_base[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_base[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m df_base[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_base[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './mcd_result/base_mcd_v1.csv'"
     ]
    }
   ],
   "source": [
    "df_base = pd.read_csv(\"./mcd_result/base_mcd_v1.csv\")\n",
    "\n",
    "df_base['aspect'] = df_base['aspect'].apply(lambda x: x.split(\", \"))\n",
    "df_base['token_sentence'] = df_base['token_sentence'].apply(lambda x: x.split(\".\\n\"))\n",
    "df_base['token_lemma'] = df_base['token_lemma'].apply(lambda x: x.split(\".\\n\"))\n",
    "\n",
    "df_base['residu'] = df_base['residu'].apply(lambda x: str(x).split(', '))\n",
    "\n",
    "print(df_base.info())\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes = pd.read_csv(\"./mcd_result/nodes_mcd.csv\")\n",
    "print(df_nodes.info())\n",
    "df_nodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f040e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9b66c",
   "metadata": {},
   "source": [
    "## A. Sentiment Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = df_base[['reviewer_id', 'token_lemma']].copy().explode('token_lemma')\n",
    "\n",
    "tqdm.pandas()\n",
    "df_sentiment['pattern_prediction'] = df_sentiment['token_lemma']\\\n",
    "                                    .progress_apply(models.pattern_lexicon_model)\\\n",
    "                                    .map({'positive': 1,'negative': -1})\n",
    "\n",
    "df_sentiment = df_sentiment.groupby('reviewer_id')['pattern_prediction'].apply(list).reset_index()\n",
    "print(df_sentiment.info())\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b009b85",
   "metadata": {},
   "source": [
    "## B. Inverse Coding Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dcaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse coding process\n",
    "\n",
    "df_1 = df_base[['reviewer_id', 'aspect', 'token_lemma', 'residu']].copy()\n",
    "df_2 = df_nodes[['reviewer_id', 'node_id', 'first_cycle', 'second_cycle', 'category']].copy()\n",
    "\n",
    "df_temp = df_1.merge(df_2, on='reviewer_id', how='inner')\n",
    "df_temp = df_temp.merge(df_sentiment, on='reviewer_id', how='left')\n",
    "print(df_temp.info())\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16efef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_score(x):\n",
    "    # Define storage\n",
    "\n",
    "    keywords = [] # Keywords for pattern search\n",
    "    keys = [] # Key value for storing\n",
    "    scoring =  {}\n",
    "    \n",
    "    \n",
    "    # Extract all values\n",
    "    first = x['first_cycle']\n",
    "    second = x['second_cycle']\n",
    "    residu = x['residu']\n",
    "    aspect = x['aspect']\n",
    "    tokens = x['token_lemma']\n",
    "    scores = x['pattern_prediction']\n",
    "    category = x['category']\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################### INVERSING PROCESS ##########################################\n",
    "    # Get the aspect of each code\n",
    "    if first == 'other':\n",
    "        for res in residu:\n",
    "            nearest = util.get_nearest_word(res, [second], model, threshold=.35)\n",
    "            if nearest:\n",
    "                keywords.append(res)\n",
    "                keys.append(second)\n",
    "                break\n",
    "    \n",
    "    else:\n",
    "        pattern = re.compile(rf\"{first}\")\n",
    "        for element in aspect:\n",
    "            if pattern.search(element):\n",
    "                keywords.append(element)\n",
    "                keys.append(first)\n",
    "                \n",
    "\n",
    "    # If keys and keywords empty, return None\n",
    "    if (len(keys) == 0) and (len(keywords) == 0):\n",
    "        return\n",
    "    \n",
    "    ################################# SCORING ##################################################\n",
    "    # Get the index sentence\n",
    "    for keyword in keywords:\n",
    "        pattern = re.compile(rf\"{keyword}\")\n",
    "        \n",
    "        for idx, element in enumerate(tokens):\n",
    "            if pattern.search(element):\n",
    "                if keyword not in scoring:\n",
    "                    scoring[keyword] = scores[idx]\n",
    "                else:\n",
    "                    scoring[keyword] = scoring[keyword] + scores[idx]\n",
    "\n",
    "        if keyword not in scoring:\n",
    "            # If it's not detected we have to split it and choose the token that contains all element.\n",
    "            temp_split_result = {}\n",
    "            for e in keyword.split(' '):\n",
    "                pattern = re.compile(rf\"{e}\")\n",
    "                \n",
    "                for idx, element in enumerate(tokens):\n",
    "                    if pattern.search(element):\n",
    "                        if keyword not in scoring:\n",
    "                            scoring[keyword] = scores[idx]\n",
    "                        else:\n",
    "                            scoring[keyword] = scoring[keyword] + scores[idx]\n",
    "\n",
    "    # Scoring    \n",
    "    total_scores = sum(list(scoring.values()))\n",
    "    tags = '/'.join(keywords)\n",
    "    \n",
    "    if total_scores < 0:\n",
    "        return (second, tags, 'negative')\n",
    "    else:\n",
    "        return (second, tags, 'positive')\n",
    "#     return (second, tags, total_scores)\n",
    "\n",
    "df_temp['key_score_aspect'] = [inverse_score(x[-1]) for x in df_temp.iterrows()]\n",
    "# If positive => sentiment 1, if negative => sentiment 0, if empty => sentiment 1 \n",
    "df_temp['sentiment'] = df_temp['key_score_aspect'].apply(lambda x: 1 if not x else 1 if x[-1] == 'positive' else 0)\n",
    "\n",
    "# print(inverse_score(df_temp.iloc[495]))\n",
    "# print(inverse_score(df_temp.iloc[497]))\n",
    "\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811fddf",
   "metadata": {},
   "source": [
    "# Sentiment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df_temp[['node_id', 'reviewer_id', \n",
    "                  'first_cycle', 'second_cycle', \n",
    "                  'category', 'sentiment']].copy()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentiment = result.groupby('first_cycle')\\\n",
    "                    .agg({'sentiment': lambda x: round(np.sum(x) / len(x), 3)})\\\n",
    "                    .reset_index()\\\n",
    "                    .rename(columns={'sentiment': 'first_cycle_sentiment_positive_rate'})\n",
    "\n",
    "second_sentiment = result.groupby('second_cycle')\\\n",
    "                    .agg({'sentiment': lambda x: round(np.sum(x) / len(x), 3)})\\\n",
    "                    .reset_index()\\\n",
    "                    .rename(columns={'sentiment': 'second_cycle_sentiment_positive_rate'})\n",
    "\n",
    "category_sentiment = result.groupby('category')\\\n",
    "                    .agg({'sentiment': lambda x: round(np.sum(x) / len(x), 3)})\\\n",
    "                    .reset_index()\\\n",
    "                    .rename(columns={'sentiment': 'category_sentiment_positive_rate'})\n",
    "\n",
    "\n",
    "result = result.merge(first_sentiment, on='first_cycle', how='left')\n",
    "result = result.merge(second_sentiment, on='second_cycle', how='left')\n",
    "result = result.merge(category_sentiment, on='category', how='left')\n",
    "result['overall_sentiment_positive_rate'] = round(np.sum(result['sentiment']) / result.shape[0], 3) * np.ones(result.shape[0])\n",
    "\n",
    "\n",
    "result = result.drop('sentiment', axis=1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566e6f1",
   "metadata": {},
   "source": [
    "# Add Review Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e884d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = df_base[['reviewer_id', 'rating']]\n",
    "\n",
    "result = result.merge(df_rating, on='reviewer_id', how='left')\n",
    "\n",
    "first_rating = result.groupby('first_cycle')\\\n",
    "                .agg({'rating': 'mean'})\\\n",
    "                .apply(lambda x: round(x, 3))\\\n",
    "                .reset_index()\\\n",
    "                .rename(columns={'rating': 'first_cycle_rating'})\n",
    "second_rating = result.groupby('second_cycle')\\\n",
    "                .agg({'rating': 'mean'})\\\n",
    "                .apply(lambda x: round(x, 3))\\\n",
    "                .reset_index()\\\n",
    "                .rename(columns={'rating': 'second_cycle_rating'})\n",
    "category_rating = result.groupby('category')\\\n",
    "                .agg({'rating': 'mean'})\\\n",
    "                .apply(lambda x: round(x, 3))\\\n",
    "                .reset_index()\\\n",
    "                .rename(columns={'rating': 'category_rating'})\n",
    "\n",
    "result = result.merge(first_rating, on='first_cycle', how='left')\n",
    "result = result.merge(second_rating, on='second_cycle', how='left')\n",
    "result = result.merge(overall_rating, on='category', how='left')\n",
    "result['overall_rating'] = round(np.sum(result['rating']) / result.shape[0], 3) * np.ones(result.shape[0])\n",
    "\n",
    "result = result.drop('rating', axis=1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update base\n",
    "\n",
    "df_temp['key_score_aspect'] = df_temp['key_score_aspect'].apply(lambda x: \", \".join(list(x)) if x else '')\n",
    "df_int = df_temp[['reviewer_id', 'key_score_aspect']]\\\n",
    "            .groupby('reviewer_id')\\\n",
    "            .agg({'key_score_aspect': lambda x: \"; \".join(x)})\\\n",
    "            .reset_index()\n",
    "df_base = df_base.merge(df_int, on='reviewer_id', how='left')\n",
    "\n",
    "df_base['aspect'] = df_base['aspect'].apply(lambda x: \", \".join(x))\n",
    "df_base['token_sentence'] = df_base['token_sentence'].apply(lambda x: \", \".join(x))\n",
    "df_base['token_lemma'] = df_base['token_lemma'].apply(lambda x: \", \".join(x))\n",
    "df_base['residu'] = df_base['residu'].apply(lambda x: \", \".join(x))\n",
    "\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc95ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"./mcd_result/final_nodes.csv\", index=False)\n",
    "df_base.to_csv(\"./mcd_result/base_mcd_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6b602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
